{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import PyPDF2\n",
    "import os\n",
    "\n",
    "def clean_academic_text(text):\n",
    "    \"\"\"\n",
    "    Clean academic text by removing unwanted patterns and normalizing the content.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): Raw text from academic paper\n",
    "    \n",
    "    Returns:\n",
    "    str: Cleaned text ready for summarization\n",
    "    \"\"\"\n",
    "    # Remove paper header information\n",
    "    text = re.sub(r'Jurnal.*?DOI:.*?\\d{4}', '', text, flags=re.DOTALL)\n",
    "    \n",
    "    # Remove page numbers and headers\n",
    "    text = re.sub(r'\\d+\\s*Jurnal.*?\\d{4}.*?hlm\\.\\d+-\\d+', '', text)\n",
    "    \n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove references to tables and figures\n",
    "    text = re.sub(r'(Tabel|Gambar)\\s+\\d+\\..*?\\n', '', text)\n",
    "    \n",
    "    # Remove citations\n",
    "    text = re.sub(r'\\([^)]*\\d{4}[^)]*\\)', '', text)\n",
    "    \n",
    "    # Remove multiple spaces and newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove square brackets with numbers\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "    \n",
    "    # Remove non-standard quotation marks and replace with standard ones\n",
    "    text = re.sub(r'[\"\"'']', '\"', text)\n",
    "    \n",
    "    # Remove special characters except periods, commas, and standard punctuation\n",
    "    text = re.sub(r'[^\\w\\s.,!?()-]', ' ', text)\n",
    "    \n",
    "    # Normalize unicode characters\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    \n",
    "    # Remove multiple periods\n",
    "    text = re.sub(r'\\.{2,}', '.', text)\n",
    "    \n",
    "    # Remove spaces before punctuation\n",
    "    text = re.sub(r'\\s+([.,!?])', r'\\1', text)\n",
    "    \n",
    "    # Remove multiple spaces again (cleanup)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Strip extra whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_main_content(text):\n",
    "    \"\"\"\n",
    "    Extract the main content from the academic paper, removing metadata and references.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): Raw text from academic paper\n",
    "    \n",
    "    Returns:\n",
    "    str: Main content of the paper\n",
    "    \"\"\"\n",
    "    # Extract text between abstract and references/conclusion\n",
    "    main_text = ''\n",
    "    \n",
    "    # Find the start (after abstract)\n",
    "    abstract_match = re.search(r'Abstract.*?\\n\\n', text, re.IGNORECASE | re.DOTALL)\n",
    "    if abstract_match:\n",
    "        start_idx = abstract_match.end()\n",
    "    else:\n",
    "        # If no abstract found, try to find introduction\n",
    "        intro_match = re.search(r'1\\.\\s*PENDAHULUAN', text)\n",
    "        start_idx = intro_match.start() if intro_match else 0\n",
    "    \n",
    "    # Find the end (before references)\n",
    "    end_markers = ['DAFTAR PUSTAKA', 'REFERENCES', 'KESIMPULAN', '5\\.\\s*KESIMPULAN']\n",
    "    end_idx = len(text)\n",
    "    \n",
    "    for marker in end_markers:\n",
    "        match = re.search(marker, text)\n",
    "        if match:\n",
    "            end_idx = min(end_idx, match.start())\n",
    "    \n",
    "    # Extract the main content\n",
    "    main_text = text[start_idx:end_idx]\n",
    "    \n",
    "    return main_text\n",
    "\n",
    "def prepare_text_for_summarization(text):\n",
    "    \"\"\"\n",
    "    Prepare text for summarization by cleaning and extracting main content.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): Raw text from academic paper\n",
    "    \n",
    "    Returns:\n",
    "    str: Cleaned and prepared text ready for summarization\n",
    "    \"\"\"\n",
    "    # Extract main content first\n",
    "    main_content = extract_main_content(text)\n",
    "    \n",
    "    # Clean the extracted content\n",
    "    cleaned_text = clean_academic_text(main_content)\n",
    "    \n",
    "    return cleaned_text\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def import_pdf(file_path):\n",
    "        \"\"\"\n",
    "        Import text from a single PDF file.\n",
    "        \n",
    "        Parameters:\n",
    "        file_path (str): Path to the PDF file\n",
    "        \n",
    "        Returns:\n",
    "        str: Extracted text from PDF\n",
    "        \"\"\"\n",
    "        \n",
    "        text = ''\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "    def import_multiple_pdfs(directory_path):\n",
    "        \"\"\"\n",
    "        Import text from multiple PDF files in a directory.\n",
    "        \n",
    "        Parameters:\n",
    "        directory_path (str): Path to directory containing PDF files\n",
    "        \n",
    "        Returns:\n",
    "        dict: Dictionary with filenames as keys and extracted text as values\n",
    "        \"\"\"\n",
    "        \n",
    "        pdf_texts = {}\n",
    "        for filename in os.listdir(directory_path):\n",
    "            if filename.endswith('.pdf'):\n",
    "                file_path = os.path.join(directory_path, filename)\n",
    "                pdf_texts[filename] = import_pdf(file_path)\n",
    "        return pdf_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of cleaned text: 30959\n",
      "--------------------------------------------------\n",
      "Cleaned text:\n",
      "1. PENDAHULUAN Bahasa isyarat merupakan hal yang sangat penting bagi suatu kelompok masyarakat, yaitu masyarakat bisu atau tuli. Untuk masyarakat yang bisu atau tuli, bahasa isyarat adalah metode terpenting untuk berkomunikasi. Tanpa adanya bahasa isyarat, akan sulit bagi mereka yang bisu atau tuli untuk dapat menyatakan maksud atau pikiran mereka. Untuk dapat berkomunik asi dengan masyarakat bisu atau tuli, orang yang tidak bisu atau tuli memerlukan bahasa isyarat tersebut untuk dapat mengerti maksud atau pikiran mereka yang bisu atau tuli. Setiap orang harus memiliki kemampuan menggunakan bahasa isyarat, agar dapat berko munikasi dengan mereka yang bisu atau tuli. Bahasa isyarat diekspresikan menggunakan tangan, lengan, serta wajah dan dimengerti menggunakan mata. Pembuatan sistem klasifikasi bahasa isyarat sebelumnya pernah dilakukan oleh yang membuat asisten virtual untuk bahasa isyarat menggunakan deep learning dan tensorflow. Kesimpulan dari penelitian ini adalah untuk dapat mendeteksi bahasa isyarat, diperlukan dataset tertentu untuk setiap bentuk bahasa isyarat. Hal ini dikarenakan terdapat banyak bentuk bahasa isyarat di dunia, sehingga untuk dapat mendeteksi bahasa isyarat yang ada pada regional tertentu, diperlukan dataset bahasa isyarat dari lokasi tersebut. Selain itu, diperlukan pula latar belakang yang mendukun g ketika mengambil gambar, sehingga tidak dapat digunakan di sembarang tempat. Penelitian ini lebih memfokuskan terhadap pembuatan aplikasinya, sehingga tidak terlalu menunjukkan terhadap akurasi atau performa yang lebih mendalam. Penelitian lain yang mend alami performa dari model deep learning -nya yaitu oleh tentang klasifikasi wajah dan penelitian oleh tentang deteksi citra Covid - 19. Kedua penelitian ini tidak melakukan klasifikasi terhadap bahasa isyarat, teta pi metode untuk mendapatkan performa yang terbaik dijadikan penulis sebagai referensi. Kesimpulan dari penelitian kedua adalah untuk dapat mendeteksi wajah, ada sangat banyak elemen yang perlu diperhatikan seperti cahaya, pose, angle atau posisi kamera, da n lainnya. Tidak akan mudah untuk dapat mendapatkan hasil yang sempurna, tetapi CNN mampu mendapatkan hasil yang baik dikarenakan pembelajaran fiturnya yang kuat, sehingga mampu bertahan pada lingkungan yang kompleks. Hal yang sama juga dapat diaplikasikan terhadap bahasa isyarat, sebagaimana disebutkan pada kesimpulan penelitian pertama. Kesimpulan dari penelitian ketiga adalah X -Ray serta CT-Scan yang termasuk kepada radiografi dada sangatlah membantu untuk mendeteksi penyakit - penyakit, dan penelitian men ggunakan Transfer Learning dari PyTorch tadi mendapatkan hasil yang memuaskan, dengan akurasi sebesar 97,78. Hasil ini sangat memuaskan dan menjadikan penulis tertarik pada metode yang digunakan untuk dicoba diberikan pada aplikasi rekognisi bahasa isyara t. Penelitian terakhir adalah tentang penggunaan metode Spatial Transformer dan optimisasi stokastik pada rekognisi rambu lalu lintas oleh. Penelitian ini menggunakan metode Spatial Transformer dan mampu mendapatkan akurasi sebe sar 99,71 pada dataset dengan jumlah data uji sebanyak 12.630. Hasil ini menunjukkan kalau metode Spatial Transformer pantas untuk digunakan untuk mencoba meningkatkan akurasi dari penelitian. Oleh karena itu, penulis mengusulkan dikembangkan sistem reko gnisi citra digital untuk dapat mengenali bahasa isyarat tersebut. Dengan menggunakan metode Convolutional Neural Network (CNN) yang merupakan bagian dari Deep Learning atau Machine Learning dan dengan metode Spatial Transformer, sistem akan mengenali pose atau bentuk dari citra bahasa isyarat yang dimasukkan, dan memberikan luaran yang sesuai dengan maksud dari pose atau bentuk dari citra bahasa isyarat tersebut. 2. METODE PENELITIAN 2.1 Data Penelitian Data yang digunakan untuk training model adalah data sekunder yang didapat secara open - source dari berbagai halaman web tertentu yang menyediakan dataset -dataset secara gratis dan legal. Untuk penelitian ini, digunakan dataset -dataset dengan tema bahasa isyarat. Adapun situs yang menyediakan set data tersebut bernama Kaggle. Data sekunder yang akan digunakan ada dua macam, yaitu data bahasa isyarat dengan background hitam dan data bahasa isyarat dengan background putih. Data dengan background hitam merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada data dengan background putih juga merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada hitam memiliki jumlah sebanyak 70 gambar, sedangkan dataset background putih memiliki jumlah sebanyak 21 gambar. Selain data sekunder dari internet, digunakan pula data yang diambil oleh penulis secara pribadi. Pengambilan data pribadi ini dilakukan untuk Mahardika, dkk, Sistem Rekognisi Citra Digital 1161 menguji adanya perbedaan hasil pada pengujian apabila menggunakan data dengan background yang berbeda dan mengetahui seberapa besar pengaruh yang dimiliki oleh background tersebut terhadap keseluruhan percobaan, sebagaimana permasalahan ini disebutkan sebelumnya oleh. Data gamb ar yang diambil akan memiliki pose dan bentuk bahasa isyarat yang sama dengan data sekunder dari internet tersebut, tetapi akan memiliki background yang bervariasi. Data yang diambil memiliki dua macam background, yaitu data dengan background karpet bermot if ditunjukkan pada Gambar 3 dan data dengan background pemandangan pagi ditunjukkan pada background karpet memiliki jumlah sebanyak 54 gambar, sedangkan dataset background pemandangan memiliki jumlah sebanyak 40 gambar. Data uji yang akan digunakan adalah dataset yang menggabungkan keempat dataset yang digunakan untuk training dan validation. Selain itu, ditambahkan pula tiga set gambar yang tidak berada dalam data training maupun validation, yaitu dataset dengan background bunga, dataset dengan background langit merah, dan dataset dengan background gunung. Penyusunan dataset uji per alfabet adalah satu gambar dari setiap dataset background hitam, putih, karpet, dan pemandangan ditambah tiga gambar dari setiap dataset background bunga, langit merah, dan gunung sebagaimana ditunjukkan pada gambar unt uk setiap alfabet, menjadikan 338 total gambar data uji. Pada perancangan model Convolutional Neural Network dari sistem rekognisi citra digital bahasa isyarat diawali dengan adanya pemrosesan awal dengan mengubah di mensi dari data dan juga mengkonversi data menjadi berbentuk Tensor agar dapat diberikan sebagai input kepada model CNN. Setelah dilakukan pemrosesan awal, dibuatlah arsitektur dari model CNN yang akan melakukan pembelajaran mendalam atau Deep Learning. Penentuan Arsitektur dari model CNN ini dilakukan dengan memasukan lapisan -lapisan neural network yang terbaik untuk data yang digunakan. Dalam arsitektur model akan ditambahkan modul Spatial Transformer, yang di tambahkan sebelum bagian utama dari neural network. Data akan melewati lapisan -lapisan Spatial Transformer terlebih dahulu sebelum memasuki bagian neural network utama. Setelah arsitektur dari model CNN telah ditentukan, dilakukan proses pelatihan atau Training pada dataset. Training atau pelatihan dilakukan dengan tujuan memberikan model pengetahuan yang dibutuhkannya untuk dapat mengklasifikasikan dan merekognisi data digital. Terakhir, dilakukan pengujian dengan data uji untuk menentukan seberapa baik ki nerja model dalam pekerjaan mengklasifikasi dan merekognisi dataset digital tersebut. Apabila kinerja model masih kurang baik, maka perlu dilakukan perbaikan atau Tweaking pada model dengan tujuan mendapatkan hasil yang lebih baik. Pada penelitian ini, tar get yang dicari adalah nilai akurasi yang tinggi. Alur perancangan model ini dilakukan sebagaimana pada 1162 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 Arsitektur yang akan digunakan dalam penelitian sistem rekognisi citra digital bahasa isyarat menggunakan Convolutional Neural Network akan menggunakan berbagai pretrained weights yang telah disediakan oleh library PyTorch. Contoh model dan weights -nya yang disediakan oleh library PyTorch yaitu ResNet, AlexNet, atau EfficientNet. Model dan weights -nya sudah dilatih sebelumnya menggunakan dataset ImageNet -1k dengan tujuan membantu meningkatkan akurasi dari model. Selain menggunakan pretrained weights, arsitektur model yang akan digunakan juga akan memiliki penambahan Spatial Transformer berupa lapis an Localization, fully connected, dan sampler. Penambahan Spatial Transformer diposisikan sebelum bagian utama arsitektur, tepatnya di awal arsitektur. Data akan melewati lapisan Spatial Transformer terlebih dahulu untuk ditransformasi sebelum memasuki lap isan utama dari Convolutional Neural Network. 3. DASAR TEORI 3.1 Bahasa Isyarat Bahasa isyarat diekspresikan menggunakan tangan, lengan, serta wajah dan dimengerti menggunakan mata. Bahasa isyarat juga memiliki struktur dan peraturan untuk berbagai kata, kalimat, atau percakapan, sebagaimana bahasa lain pada umumnya. Sebagian besar percakapan pada bahasa isyarat dilakukan dengan menggunakan tangan, dimana tangan beserta jari-jarinya digunakan untuk membentuk pose atau bentuk yang unik, s ehingga dapat dikenali sebagai maksud tertentu. Pada negara tertentu, bahasa isyarat yang dikembangkan dapat berbeda dengan bahasa isyarat dari negara lain. Contoh dari bahasa isyarat yang ada pada suatu negara tertentu yaitu American Sign Language (ASL) y ang merupakan bahasa isyarat populer yang berasal dari Amerika Serikat. Selain itu, terdapat pula bahasa isyarat dari Inggris yaitu British Sign Language (BSL). Selain kedua negara tersebut, terdapat Australian Sign Language (Auslan), Italian Sign Language (LIS), Japanese Sign Language (JSL), dan lainnya. 3.2 Convolutional Neural Network Convolutional Neural Network (CNN) adalah jaringan saraf neuron lapisan banyak yang tidak sepenuhnya tersambung. CNN berisi lapisan convolutional, lapisan sampling atau sub-sampling, dan lapisan tersembunyi yang masih berupa lapisan convolutional atau sampling. Setiap lapisan convolution pada CNN diikuti dengan lapisan penghitung untuk dilakukan pemerataan dan ekstraksi. Adapun perhitungan yang dilakukan pada lapisan convolutional adalah sebagai berikut H(x,y) b F(x,y) G(x,y) b F(j,k) k ( ) j ( ) G(x j,y k) (1) Keterangan F Filter Lapisan G Input feature map H Output feature map b Bias x Sumbu X pada data dan filter y Sumbu Y pada data dan filter j Increment untuk sumbu X k Increment untuk sumbu Y Suatu input feature map G dengan nilai G(x,y) akan dimasukkan ke dalam lapisan konvolusi. Kernel F yang berada di dalam lapisan konvolusi memiliki nilai F(x,y) untuk menjadi pengali dari input tersebut. Untuk setiap j pada sumbu x dan setiap k pada sumbu y, nilai input G(x j,y k) akan dikalikan dengan nilai kernel F(j,k) dan hasilnya akan dijumlahkan sesuai dengan ukuran data input pada nilai j dan k. Hasil dari total penjumlahan tersebut akan dijumlahkan dengan nilai bias b untuk menjadi nilai output H(x,y). Perhitungan akan dilanjutkan ke pixel selanjutnya pada input G hingga seluruh pixel pada output feature map H mendapatkan hasil. 3.3 Transfer Learning Transfer Learning merupakan salah satu teknik dari penggunaan Deep Learning, dimana model yang sebelumnya telah melewati tahap training digunakan kembali untuk mengekstrak dan tuning lebih lanjut pada model lain untuk memperbaiki akurasi. Keuntungan dari penggunaan teknik Transfer Learning terletak pada penghematan waktu penjalanan proses training serta penghematan resource dikarenakan me nggunakan data yang lebih sedikit. Teknik ini dapat digunakan untuk mendeteksi berbagai macam objek. 3.4 Spatial Transformer Spatial Transformer merupakan modul yang bisa ditambahkan ke dalam Convolutional Neural Network yang memungkinkan manipulasi spasial data di dalam jaringan. Modul yang dapat dibedakan ini dapat dimasukkan ke dalam arsitektur Convolutional Neural Network yang sudah ada, memberikan neural network kemampuan untuk secara aktif mentransformasikan feature map secara spasial, tergantung pada feature map itu sendiri tanpa pengawasan pelatihan tambahan atau modifikasi pada proses pengoptimalan. Tahapan dari Spatial Transformer digambarkan pada Mahardika, dkk, Sistem Rekognisi Citra Digital 1163 Pada Gambar 7, mekanisme Spatial Transformer dibagi menjadi tiga bagian, yaitu jaringan Localization, Sampling Grid, dan Sampler. Jaringan Localization mengambil feature map input dan mengeluarkan parameter transformasi Teta (θ) yang harus diterapkan pada feature map melalui sejumlah hidden layer. Hasil output jaringan Localization berupa parameter transformasi Teta ( θ) akan digunakan untuk membuat Sampling Grid, yang merupakan sekumpulan titik di mana map input harus diambil sampelnya untuk menghasilkan output yang telah diubah. Hal ini dilakukan oleh generator grid, yang merupakan komponen Spatial Transformer yang memiliki fungsi eksklusif untuk melakukan transformasi invers dari output. Terakhir, feature map dan Sampling Grid yang dihasilkan oleh Grid Generator diambil sebagai input untuk Sampler, komponen lain dari Spatial Transformer selain Grid generator. Tujuan dari Sampler adalah untuk menghasilkan output map yang di -sampling dari input pada titik -titik grid. Sampler mengulangi entri grid pengambilan sampel dan mengekstrak nilai pixel yang sesuai dari input map menggunakan interpolasi bilinear. Output dari ketiga tahapan Spatial Transformer tersebut kemudian akan diteruskan ke jaringan konvolusi setelahnya. xis yis τθ(Gi) Aθ(xit yit 1) θ1,1θ1,2θ1,3 θ2,1θ2,3θ2,3 (xit yit 1) (2) Keterangan τθ Transformasi Afin 2D Aθ Gi Grid dari Output Feature Map Aθ Matriks Transformasi Afin θ xis Sumber Kordinat Sumbu X yis Sumber Kordinat Sumbu Y xit Target Kordinat Sumbu X yit Target Kordinat Sumbu Y θ Luaran Localization Kordinat ( xit,yit) adalah target kordinat pada titik -titik grid (Gi) dan berasal dari output feature map. Kordinat ( xis,yis) adalah sumber kordinat dari input feature map yang menentukan titik sampel. Output dari lapisan Localization yaitu θ menjadi penentu transformasi target, dan mungkin saja mengambil berbagai transformasi. Aθ adalah matriks transformasi afin θ. Transformasi yang didefinisikan adalah seperti cropping, translation, rotation, scale, dan skew untuk diterapkan pada input feature map, dan hanya membutuhkan 6 parameter (6 elemen Aθ) yang diproduksi oleh lapisan Localization. 3.5. Confusion Matrix Confusion Matrix adalah salah satu metode pengukuran kinerja untuk masalah klasifikasi dalam machine learning, di mana output -nya dapat berupa dua kelas atau lebih. Confusion Matrix dapat berupa tabel dengan empat macam kombinasi berbeda dari nilai prediksi dan nilai sebenarnya. Keempat macam kombinasi tersebut adalah True Positive (TP), False Positive (FP), True Negative (TN), dan False Negative (FP). Positif Sebenarnya Negatif Sebenarnya Positif Prediksi True Positive False Positive Negatif Prediksi False Negative True Negative Keempat kombinasi yang ditunjukkan pada Tabel 1 dapat digunakan untuk melakukan perhitungan metrik -metrik untuk mengevaluasi hasil prediksi sistem. Metrik yang digunakan untuk mengevaluasi yaitu Accuracy atau akurasi, Precision, Recall, dan F1-Score. Adapun rumus dari setiap metrik tersebut ditunjukkan pada persamaan - persamaan berikut Accuracy TP TN TP FP TN FN (3) Precision TP TP FP (4) Recall TP TP FN (5) F1 Score 2 Precision Recall Precision Recall (6) Keterangan TP True Positive TN True Negative FP False Positive FN False Negative Perhitungan akurasi dilakukan dengan membagi seluruh prediksi yang benar ( TP TN) oleh keseluruhan data ( TP FP TN FN) dan digunakan untuk mengetahui keefektifan secara menyeluruh dari sistem. Perhitungan Precision digunakan untuk mengetahui kesepakatan kelas label data dengan label positif yang diberikan o leh sistem, dengan cara membagi nilai True Positive (TP) dan penjumlahan True Positive dan False Positive (TP FP). Perhitungan Recall digunakan untuk 1164 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 mengetahui keefektifan dari sistem untuk mengidentifikasi label yang positif, dilakukan dengan membagi nilai True Positive (TP) dengan penjumlahan True Positive dan False Negative (TP FN). Perhitungan F1-Score digunakan untuk mengeta hui hubungan antara data dengan label positif dan data yang dilabelkan positif oleh sistem. 3.5 Flask Flask adalah sebuah kerangka kerja aplikasi web yang memberikan alat, pustaka, dan teknologi untuk membuat aplikasi web. Flask meru pakan modul python untuk membuat aplikasi berbasis web yang cukup mudah untuk digunakan. Dengan menggunakan flask, suatu model deep learning dapat diintegrasikan ke dalam aplikasi web untuk dapat digunakan. 4. HASIL DAN PEMBAHASAN Pengujian pertama yang akan diuji adalah pengaturan arsitektur CNN dengan model -model yang memiliki pretrained weights. Adapun model - model yang akan diuji yaitu ResNet18 dan ResNet50, AlexNet, dan EfficientNet B4. Selain arsitektur CNN, hal lain yang akan diuji adalah Hyperparameter dari proses pelatihan. Parameter yang akan diuji adalah optimizer dan learning rate. Berbagai optimizer yang akan diuji seperti SGD, RMSPr op, dan Adam. Sedangkan untuk learning rate, pengujian hanya akan menguji penggunaan learning rate scheduler untuk menilai keefektifan scheduler dalam membantu proses training. Setelah didapat model dan pengaturan hyperparameter yang terbaik, dilakukan pen gujian penggunaan pretrained weights dari arsitektur model untuk mencoba menaikkan hasil akurasi. Spatial Transformer juga akan diuji coba untuk melihat apakah penggunaannya mampu membuat akurasi meningkat. Terakhir, setelah didapatkan hasil yang maksimum dari kombinasi pengaturan yang terbaik, dilakukan uji coba secara real-time. Pengujian secara real-time dilakukan dengan melakukan export terhadap model dengan hasil yang terbaik, lalu diuji dengan gambar nyata yang diambil menggunakan kamera atau webcam. Pengujian secara real-time juga akan memiliki variasi terhadap pengujiannya, dimana masing -masing dari keempat dataset akan diuji coba melakukan klasifikasi secara real-time terhadap tiga macam latar belakang, yaitu latar belakang putih polos, latar belak ang hitam polos, dan latar belakang abstrak atau bermacam -macam warna. Uji coba latar belakang abstrak dilakukan untuk melihat pengaruh dari variasi warna pada latar belakang. Setelah melihat performa dari masing - masing dataset, dilakukan uji coba mengguna kan dataset gabungan dari keempat dataset untuk mencoba mendapatkan hasil yang terbaik. Pengujian model, hyperparameter, pretrained weights, dan Spatial Transformer akan menggunakan akurasi sebagai metrik utama dengan mencatat juga waktu jalannya proses tr aining. Khusus untuk learning rate, ditambahkan metrik berupa epoch hingga konvergen untuk menilai seberapa cepat model mampu mencapai titik konvergen pada proses pelatihan. 4.1 Pengujian Arsitektur Model Dalam pengujian ini digunakan empat tipe model. ResNet1 8 cukup populer di kalangan dataset kecil, tetapi juga layak digunakan pada dataset besar. Selain ResNet18, model populer lain yang juga digunakan adalah AlexNet. ResNet50 juga digunakan untuk membandingkan dengan tipe sebelumnya. Terakhir, EfficientNet B4 digunakan karena jumlah trainable parameter -nya yang tinggi, tetapi tidak terlalu besar untuk mencegah overfitting. Pengujian dilakukan dengan menggunakan Hyperparameter yang sama, yaitu optimizer Adam, learning rate 0.001, dan loss Cross Entropy. Pengujian ini tidak menggunakan Spatial Transformer. Hasil dari pengujian ditunjukkan pada Model Akurasi Waktu Training Train Valid ation Test ResNet18 99,89 100 54,73 3585s AlexNet 99,93 100 57,39 3350s ResNet50 99,83 100 57,10 4167s Efficient Net B4 99,96 100 78,10 4924s Hasil pengujian pada Tabel 2 menunjukkan bahwa model dengan arsitektur EfficientNet B4 memiliki akurasi testing yang tertinggi sebesar 78,10. Hasil ini menunjukkan bahwa model EfficientNet B4 mampu mendeteksi alfabet dalam data uji hingga didapatkan 78,10 kebenarannya. Selain memiliki akurasi testing yang tertinggi, akurasi training dan validation dari model Effi cientNet B4 juga yang terbesar, yaitu sebesar 99,96 untuk training dan 100 untuk validation. Seluruh model mendapatkan akurasi training yang tidak begitu jauh dari satu sama lain, dengan perbedaan antara hasil terendah dan tertinggi hanya sebesar 0,13. Akurasi validation tampak merata untuk keempat arsitektur yang diuji. Waktu pelatihan tercepat jatuh kepada model AlexNet dengan waktu 3350 detik atau hanya 55 menit dan terlama pada model EfficientNet B4 dengan waktu 4924 detik atau 1 jam 22 menit. Hasil ini menunjukkan bahwa model EfficientNet B4 memiliki kemampuan terbaik dalam prediksi data uji dibanding model lainnya, walau waktu pelatihannya memakan waktu paling lama. 4.2 Pengujian Hyperparameter Pengujian Hyperparameter dilakukan dengan menentukan pengat uran Hyperparameter yang dapat Mahardika, dkk, Sistem Rekognisi Citra Digital 1165 memberikan hasil yang terbaik, dan pengaturan Hyperparameter yang akan diuji yaitu optimizer dan penggunaan learning rate scheduler. Untuk model pengujian digunakan model EfficientNet B4 untuk mencari kombinasi Hyperparameter yang terbaik. Jumlah epoch yang digunakan adalah 20, dan Learning Rate yang digunakan yaitu 0.001. Pengujian optimizer dilakukan dengan mencoba satu per satu optimizer yang dapat digunakan. Opsi optimizer yang akan dicoba yaitu Adam, SGD, dan RMSProp. Pengujian ini juga tidak menggunakan Spatial Transformer. Hasil dari pengujian ditunjukkan pada Optimizer Akurasi Waktu Training Train Validation Test Adam 99,96 100 78,10 4924s SGD 4,79 3,85 3,84 4707s RMSProp 99,98 100 57,39 4767s Berdasarkan hasil pengujian Tabel 3, dapat dilihat bahwa model yang menggunakan optimizer SGD terlihat tidak berkembang. Akurasi yang didapat terlihat tidak mampu mencapai 5, baik akurasi training, validation, maupun testing. Hal ini diduga karena optimizer SGD memiliki sifat yang stokastik atau random dalam memilih data latih untuk setiap step, sehingga membutuhkan lebih banyak epoch dibandingkan dengan optimizer lain. Model dengan optimizer RMSProp terlihat cukup baik, akan tetapi akurasi testing -nya tidak sebaik dengan model yang menggunakan optimizer Adam. Hasil ini diduga dikarenakan optimizer Adam merupakan hasil perkembangan gabungan dari kedua optimizer. Setelah optimizer, pengujian Hyperparameter selanjutnya adalah penggunaan learning rate scheduler. Learning Rate Akurasi Epoch mencapai Konvergen Train Test LR 0.001 98,83 76,33 Belum Konvergen LR 0.001 Scheduler 99,96 78,10 Epoch ke-8 Pengujian learning rate scheduler dilakukan dengan menguji performa dari pelatihan apabila penggunaan scheduler diberikan. Metrik utama yang akan diperhatikan adalah jumlah epoch yang diperlukan dari model hingga mencapai titik konvergen, atau titik dimana akurasi pelatihan tidak lagi fluktuatif. Untuk nilai learning rate yang akan digunakan yaitu 0.001, dan learning rate scheduler yang digunakan adalah Exponential Learning Rate Scheduler dari library torch optim. Sebagaimana ditunjukkan pada Tabel 4, Gambar 8, dan Gambar 9, pe ngujian penggunaan Learning Rate Scheduler pada model CNN tampak memiliki pengaruh terhadap proses pelatihan maupun hasil dari output model tersebut. Dengan adanya Learning Rate Scheduler, proses pelatihan model terlihat menjadi lebih stabil. Perubahan ter hadap nilai learning rate menjadikan proses pelatihan menjadi lebih teratur dan tidak fluktuatif, sebagaimana dapat dilihat pada model yang dilatih masih belum mampu memberikan hasil yang konsisten. Hal ini memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler. Gambar 8 menunjukkan bahwa pengujian yang tidak menggunakan scheduler tampak fluktuatif dan tidak teratur. Sel ain itu, hal ini juga memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler sebagaimana ditunjukkan pada maupun testing, peng gunaan scheduler terlihat mampu menaikkan akurasi pada model yang dilatih 4.3. Pen gujian Penggunaan Pretrained Weights Pengujian penggunaan pretrained weights dilakukan dengan menggunakan parameter pretrained True ketika memanggil model menggunakan library torch untuk menggunakan weights yang sebelumnya telah dilatih dan disediakan pada pemanggilan model. Model yang akan digunakan sama seperti pengujian sebelumnya, yaitu ResNet18, AlexNet, ResNet50 dan EfficientNet B4. 1166 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 Tujuan pengujian adalah untuk m engetahui seberapa besar pengaruh pretrained weights pada proses pelatihan dan hasilnya. Pengujian menggunakan optimizer Adam dan learning rate 0.001 serta scheduler -nya. Pengujian ini tidak menggunakan Spatial Transformer. Model Akurasi Waktu Training Train Validation Test ResNet18 99,89 100 54,73 3585s ResNet18 Pretrained 100 100 84,91 3566s AlexNet 99,93 100 57,39 3350s AlexNet Pretrained 99,96 99,04 75,44 3345s ResNet50 99,83 100 57,10 4167s ResNet50 Pretrained 99,89 99,52 65,09 4119s EfficientNet B4 99,96 100 78,10 4924s EfficientNet B4 Pretrained 99,96 100 100 4870s Berdasarkan hasil pengujian yang ditunjukkan pada Tabel 5, dapat dilihat bahwa terdapat peningkatan pada akurasi testing untuk seluruh model. Peningkatan tersebut berbeda -beda pada setiap model, berkisar antara angka 8 hingga 30. Model ResNet18 mendapatkan peningkatan akurasi testing yang paling besar, yaitu 30,18. Model AlexNet juga mendapatkan peningkatan, yaitu sebesa r 18,05. Model ResNet50 mendapatkan peningkatan paling kecil, yaitu hanya sebesar 7,99. Terakhir, model EfficientNet B4 mendapatkan peningkatan sebesar 21,9 dan mampu mencapai akurasi maksimum, yaitu 100. Hasil ini menunjukkan bahwa model EfficientNet B4 sudah mampu mendeteksi seluruh data uji secara sempurna diduga karena tingkat kesulitan untuk mendeteksi data uji tidak begitu tinggi. Dari keempat model, dapat dilihat bahwa model EfficientNet B4 masih memiliki akurasi terbesar, bahkan mampu mencapai angka maksimum. Hal ini menunjukkan bahwa model EfficientNet B4 merupakan model yang terbaik dari keempat model yang diuji dalam mengklasifikasikan dataset yang diberikan. 4.4. Pen gujian Penggunaan Spatial Transformer Pengujian ini dilakukan dengan menambah kan lapisan localization dan lapisan Fully Connected yang merupakan bagian dari Spatial Transformer Network. Lapisan -lapisan ini ditambahkan tepat sebelum dimasukkan ke model EfficientNet B4 yang menjadi arsitektur utama. Pengujian akan menggunakan optimiz er Adam dan learning rate 0.001 serta scheduler -nya. Model Akurasi Train Akurasi Test Waktu Training EfficientNet B4 99,96 78,10 4924s EfficientNet B4 dengan Spatial Transformer 100 86,09 5950s EfficientNet B4 Pretrained dengan Spatial Transformer 100 100 6537s Dari hasil pengujian yang ditunjukkan pada Tabel 6, terlihat terdapat peningkatan akurasi Test pada model EfficientNet B4 dengan Spatial Transformer, yaitu sebesar 8. Akurasi yang didapat apabila EfficientNet B4 Pretrained menggunakan Spatial Transformer mampu mencapai akurasi maksimum pada data Test, yaitu sebesar 100. Adanya peningkatan akurasi menunjukkan bahwa Spatial Transformer memiliki kemampuan untuk meningkatkan kemampuan dari model dalam klasifikasi, sehingga pantas untuk digunakan untuk model akhir. Model akhir ini mampu mendapatkan nilai maksimum dari data testing, sehingga siap untuk diuji coba secara real-time. 4.5. Pen gujian Secara Real -Time Pengujian secara real-time dilakukan dengan mencoba dataset satu per satu terhadap suatu kondisi atau tampilan latar belakang tertentu dan menilai ke - efektifan masing -masing data terhadap masing - masing tampilan latar belakang, yaitu latar belakang putih, hitam, dan abstrak. Setelah itu, keempat dataset akan digabungkan menjadi satu untuk dicoba melihat keefektifannya terhadap masing -masing tampilan latar belakang. Model yang digunakan adalah model dengan pengaturan serta arsitektur ya ng terbaik, yaitu EfficientNet B4 Pretrained dengan Spatial Transformer. Data gambar akan di -convert menjadi single channel agar mempermudah prediksi melalui aplikasi. Dataset Total Benar Akurasi Latar Belakang Pengujian Putih Hitam Abstrak Latar Belakang Putih Total Benar 22 23 13 Akurasi 85 88 50 Latar Belakang Hitam Total Benar 13 16 6 Akurasi 50 62 23 Latar Belakang Karpet Total Benar 9 12 3 Akurasi 35 46 12 Latar Belakang Pemandangan Total Benar 9 4 3 Akurasi 35 15 12 Gabungan Total Benar 26 26 23 Akurasi 100 100 88 Tabel 7 menunjukkan bahwa akurasi yang didapat menggunakan dataset latar belakang hitam terlihat masih kurang baik. Dataset masih mampu melakukan klasifikasi pada latar belakang pengujian Mahardika, dkk, Sistem Rekognisi Citra Digital 1167 yang polos, seperti latar belakang putih dan hitam. Total prediksi yang benar masih mampu mencapai 50 dari seluruh alfabet pada latar belakang putih dan sebesar 62 pada latar belakang hitam. Hasil pengujian pada latar belakang abstrak terlihat hanya sebesar 23. Dapat juga dilihat pada Tabel 7 bahwa dataset dengan latar belakang putih mampu melakukan klasifikasi dengan baik pada latar belakang pengujian putih dan hitam polos, tetapi tidak te rlalu buruk pada klasifikasi dengan background abstrak. Total benar yang didapat pada latar belakang putih sebesar 85 dan latar belakang hitam 88 dari seluruh alfabet. Hasil pengujian pada latar belakang abstrak hanya sebesar 50, tetapi hasil ini masih lebih baik jika dibandingkan dengan dataset berlatar belakang hitam. Hasil pengujian dataset berlatar belakang pemandangan terlihat kurang baik. Pada latar belakang putih, total benar yang didapat hanya sebesar 35 dari seluruh alfabet, hasil yang lebih buruk jika dibandingkan dengan kedua dataset di pengujian sebelumnya. Tetapi, pengujian pada latar belakang hitam terlihat lebih buruk, hanya sebesar 15. Pengujian pada latar belakang abstrak terlihat tidak jauh, yaitu hanya sebesar 12. Dataset berlatar be lakang karpet yang ditunjukkan pada Tabel 7 terlihat lebih baik daripada pengujian pada dataset berlatar belakang pemandangan, tetapi masih kurang jika dibandingkan dengan dataset berlatar belakang hitam dan putih. Pengujian pada latar belakang putih terli hat mendapatkan total benar sebesar 35, dan pengujian pada latar belakang hitam terlihat mendapatkan total benar sebesar 46 dari seluruh alfabet. Tetapi, pengujian pada latar belakang abstrak masih terlihat buruk, yaitu hanya 12. Setelah keempat dataset diatas digabungkan, terlihat hasil pengujian secara real-time yang didapat cukup memuaskan. Sebagaimana ditunjukkan pada Tabel 7, hasil pengujian dataset gabungan pada latar belakang putih terlihat mencapai 100 total benar. Pengujian pada latar belakang hitam juga mencapai 100 total benar. Terakhir, pengujian pada latar belakang abstrak juga terlihat baik, yaitu sebesar 88.\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path of the PDF\n",
    "pdf_file = \"datasets/ID+8098.pdf\"\n",
    "\n",
    "# Import and process the PDF\n",
    "pdf_text = import_pdf(pdf_file)\n",
    "\n",
    "# Clean and prepare the document\n",
    "cleaned_text = prepare_text_for_summarization(pdf_text)\n",
    "print(\"Length of cleaned text:\", len(cleaned_text))\n",
    "print(\"-\" * 50)\n",
    "print(\"Cleaned text:\")\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID+8098.pdf': '1. PENDAHULUAN Bahasa isyarat merupakan hal yang sangat penting bagi suatu kelompok masyarakat, yaitu masyarakat bisu atau tuli. Untuk masyarakat yang bisu atau tuli, bahasa isyarat adalah metode terpenting untuk berkomunikasi. Tanpa adanya bahasa isyarat, akan sulit bagi mereka yang bisu atau tuli untuk dapat menyatakan maksud atau pikiran mereka. Untuk dapat berkomunik asi dengan masyarakat bisu atau tuli, orang yang tidak bisu atau tuli memerlukan bahasa isyarat tersebut untuk dapat mengerti maksud atau pikiran mereka yang bisu atau tuli. Setiap orang harus memiliki kemampuan menggunakan bahasa isyarat, agar dapat berko munikasi dengan mereka yang bisu atau tuli. Bahasa isyarat diekspresikan menggunakan tangan, lengan, serta wajah dan dimengerti menggunakan mata. Pembuatan sistem klasifikasi bahasa isyarat sebelumnya pernah dilakukan oleh yang membuat asisten virtual untuk bahasa isyarat menggunakan deep learning dan tensorflow. Kesimpulan dari penelitian ini adalah untuk dapat mendeteksi bahasa isyarat, diperlukan dataset tertentu untuk setiap bentuk bahasa isyarat. Hal ini dikarenakan terdapat banyak bentuk bahasa isyarat di dunia, sehingga untuk dapat mendeteksi bahasa isyarat yang ada pada regional tertentu, diperlukan dataset bahasa isyarat dari lokasi tersebut. Selain itu, diperlukan pula latar belakang yang mendukun g ketika mengambil gambar, sehingga tidak dapat digunakan di sembarang tempat. Penelitian ini lebih memfokuskan terhadap pembuatan aplikasinya, sehingga tidak terlalu menunjukkan terhadap akurasi atau performa yang lebih mendalam. Penelitian lain yang mend alami performa dari model deep learning -nya yaitu oleh tentang klasifikasi wajah dan penelitian oleh tentang deteksi citra Covid - 19. Kedua penelitian ini tidak melakukan klasifikasi terhadap bahasa isyarat, teta pi metode untuk mendapatkan performa yang terbaik dijadikan penulis sebagai referensi. Kesimpulan dari penelitian kedua adalah untuk dapat mendeteksi wajah, ada sangat banyak elemen yang perlu diperhatikan seperti cahaya, pose, angle atau posisi kamera, da n lainnya. Tidak akan mudah untuk dapat mendapatkan hasil yang sempurna, tetapi CNN mampu mendapatkan hasil yang baik dikarenakan pembelajaran fiturnya yang kuat, sehingga mampu bertahan pada lingkungan yang kompleks. Hal yang sama juga dapat diaplikasikan terhadap bahasa isyarat, sebagaimana disebutkan pada kesimpulan penelitian pertama. Kesimpulan dari penelitian ketiga adalah X -Ray serta CT-Scan yang termasuk kepada radiografi dada sangatlah membantu untuk mendeteksi penyakit - penyakit, dan penelitian men ggunakan Transfer Learning dari PyTorch tadi mendapatkan hasil yang memuaskan, dengan akurasi sebesar 97,78. Hasil ini sangat memuaskan dan menjadikan penulis tertarik pada metode yang digunakan untuk dicoba diberikan pada aplikasi rekognisi bahasa isyara t. Penelitian terakhir adalah tentang penggunaan metode Spatial Transformer dan optimisasi stokastik pada rekognisi rambu lalu lintas oleh. Penelitian ini menggunakan metode Spatial Transformer dan mampu mendapatkan akurasi sebe sar 99,71 pada dataset dengan jumlah data uji sebanyak 12.630. Hasil ini menunjukkan kalau metode Spatial Transformer pantas untuk digunakan untuk mencoba meningkatkan akurasi dari penelitian. Oleh karena itu, penulis mengusulkan dikembangkan sistem reko gnisi citra digital untuk dapat mengenali bahasa isyarat tersebut. Dengan menggunakan metode Convolutional Neural Network (CNN) yang merupakan bagian dari Deep Learning atau Machine Learning dan dengan metode Spatial Transformer, sistem akan mengenali pose atau bentuk dari citra bahasa isyarat yang dimasukkan, dan memberikan luaran yang sesuai dengan maksud dari pose atau bentuk dari citra bahasa isyarat tersebut. 2. METODE PENELITIAN 2.1 Data Penelitian Data yang digunakan untuk training model adalah data sekunder yang didapat secara open - source dari berbagai halaman web tertentu yang menyediakan dataset -dataset secara gratis dan legal. Untuk penelitian ini, digunakan dataset -dataset dengan tema bahasa isyarat. Adapun situs yang menyediakan set data tersebut bernama Kaggle. Data sekunder yang akan digunakan ada dua macam, yaitu data bahasa isyarat dengan background hitam dan data bahasa isyarat dengan background putih. Data dengan background hitam merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada data dengan background putih juga merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada hitam memiliki jumlah sebanyak 70 gambar, sedangkan dataset background putih memiliki jumlah sebanyak 21 gambar. Selain data sekunder dari internet, digunakan pula data yang diambil oleh penulis secara pribadi. Pengambilan data pribadi ini dilakukan untuk Mahardika, dkk, Sistem Rekognisi Citra Digital 1161 menguji adanya perbedaan hasil pada pengujian apabila menggunakan data dengan background yang berbeda dan mengetahui seberapa besar pengaruh yang dimiliki oleh background tersebut terhadap keseluruhan percobaan, sebagaimana permasalahan ini disebutkan sebelumnya oleh. Data gamb ar yang diambil akan memiliki pose dan bentuk bahasa isyarat yang sama dengan data sekunder dari internet tersebut, tetapi akan memiliki background yang bervariasi. Data yang diambil memiliki dua macam background, yaitu data dengan background karpet bermot if ditunjukkan pada Gambar 3 dan data dengan background pemandangan pagi ditunjukkan pada background karpet memiliki jumlah sebanyak 54 gambar, sedangkan dataset background pemandangan memiliki jumlah sebanyak 40 gambar. Data uji yang akan digunakan adalah dataset yang menggabungkan keempat dataset yang digunakan untuk training dan validation. Selain itu, ditambahkan pula tiga set gambar yang tidak berada dalam data training maupun validation, yaitu dataset dengan background bunga, dataset dengan background langit merah, dan dataset dengan background gunung. Penyusunan dataset uji per alfabet adalah satu gambar dari setiap dataset background hitam, putih, karpet, dan pemandangan ditambah tiga gambar dari setiap dataset background bunga, langit merah, dan gunung sebagaimana ditunjukkan pada gambar unt uk setiap alfabet, menjadikan 338 total gambar data uji. Pada perancangan model Convolutional Neural Network dari sistem rekognisi citra digital bahasa isyarat diawali dengan adanya pemrosesan awal dengan mengubah di mensi dari data dan juga mengkonversi data menjadi berbentuk Tensor agar dapat diberikan sebagai input kepada model CNN. Setelah dilakukan pemrosesan awal, dibuatlah arsitektur dari model CNN yang akan melakukan pembelajaran mendalam atau Deep Learning. Penentuan Arsitektur dari model CNN ini dilakukan dengan memasukan lapisan -lapisan neural network yang terbaik untuk data yang digunakan. Dalam arsitektur model akan ditambahkan modul Spatial Transformer, yang di tambahkan sebelum bagian utama dari neural network. Data akan melewati lapisan -lapisan Spatial Transformer terlebih dahulu sebelum memasuki bagian neural network utama. Setelah arsitektur dari model CNN telah ditentukan, dilakukan proses pelatihan atau Training pada dataset. Training atau pelatihan dilakukan dengan tujuan memberikan model pengetahuan yang dibutuhkannya untuk dapat mengklasifikasikan dan merekognisi data digital. Terakhir, dilakukan pengujian dengan data uji untuk menentukan seberapa baik ki nerja model dalam pekerjaan mengklasifikasi dan merekognisi dataset digital tersebut. Apabila kinerja model masih kurang baik, maka perlu dilakukan perbaikan atau Tweaking pada model dengan tujuan mendapatkan hasil yang lebih baik. Pada penelitian ini, tar get yang dicari adalah nilai akurasi yang tinggi. Alur perancangan model ini dilakukan sebagaimana pada 1162 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 Arsitektur yang akan digunakan dalam penelitian sistem rekognisi citra digital bahasa isyarat menggunakan Convolutional Neural Network akan menggunakan berbagai pretrained weights yang telah disediakan oleh library PyTorch. Contoh model dan weights -nya yang disediakan oleh library PyTorch yaitu ResNet, AlexNet, atau EfficientNet. Model dan weights -nya sudah dilatih sebelumnya menggunakan dataset ImageNet -1k dengan tujuan membantu meningkatkan akurasi dari model. Selain menggunakan pretrained weights, arsitektur model yang akan digunakan juga akan memiliki penambahan Spatial Transformer berupa lapis an Localization, fully connected, dan sampler. Penambahan Spatial Transformer diposisikan sebelum bagian utama arsitektur, tepatnya di awal arsitektur. Data akan melewati lapisan Spatial Transformer terlebih dahulu untuk ditransformasi sebelum memasuki lap isan utama dari Convolutional Neural Network. 3. DASAR TEORI 3.1 Bahasa Isyarat Bahasa isyarat diekspresikan menggunakan tangan, lengan, serta wajah dan dimengerti menggunakan mata. Bahasa isyarat juga memiliki struktur dan peraturan untuk berbagai kata, kalimat, atau percakapan, sebagaimana bahasa lain pada umumnya. Sebagian besar percakapan pada bahasa isyarat dilakukan dengan menggunakan tangan, dimana tangan beserta jari-jarinya digunakan untuk membentuk pose atau bentuk yang unik, s ehingga dapat dikenali sebagai maksud tertentu. Pada negara tertentu, bahasa isyarat yang dikembangkan dapat berbeda dengan bahasa isyarat dari negara lain. Contoh dari bahasa isyarat yang ada pada suatu negara tertentu yaitu American Sign Language (ASL) y ang merupakan bahasa isyarat populer yang berasal dari Amerika Serikat. Selain itu, terdapat pula bahasa isyarat dari Inggris yaitu British Sign Language (BSL). Selain kedua negara tersebut, terdapat Australian Sign Language (Auslan), Italian Sign Language (LIS), Japanese Sign Language (JSL), dan lainnya. 3.2 Convolutional Neural Network Convolutional Neural Network (CNN) adalah jaringan saraf neuron lapisan banyak yang tidak sepenuhnya tersambung. CNN berisi lapisan convolutional, lapisan sampling atau sub-sampling, dan lapisan tersembunyi yang masih berupa lapisan convolutional atau sampling. Setiap lapisan convolution pada CNN diikuti dengan lapisan penghitung untuk dilakukan pemerataan dan ekstraksi. Adapun perhitungan yang dilakukan pada lapisan convolutional adalah sebagai berikut H(x,y) b F(x,y) G(x,y) b F(j,k) k ( ) j ( ) G(x j,y k) (1) Keterangan F Filter Lapisan G Input feature map H Output feature map b Bias x Sumbu X pada data dan filter y Sumbu Y pada data dan filter j Increment untuk sumbu X k Increment untuk sumbu Y Suatu input feature map G dengan nilai G(x,y) akan dimasukkan ke dalam lapisan konvolusi. Kernel F yang berada di dalam lapisan konvolusi memiliki nilai F(x,y) untuk menjadi pengali dari input tersebut. Untuk setiap j pada sumbu x dan setiap k pada sumbu y, nilai input G(x j,y k) akan dikalikan dengan nilai kernel F(j,k) dan hasilnya akan dijumlahkan sesuai dengan ukuran data input pada nilai j dan k. Hasil dari total penjumlahan tersebut akan dijumlahkan dengan nilai bias b untuk menjadi nilai output H(x,y). Perhitungan akan dilanjutkan ke pixel selanjutnya pada input G hingga seluruh pixel pada output feature map H mendapatkan hasil. 3.3 Transfer Learning Transfer Learning merupakan salah satu teknik dari penggunaan Deep Learning, dimana model yang sebelumnya telah melewati tahap training digunakan kembali untuk mengekstrak dan tuning lebih lanjut pada model lain untuk memperbaiki akurasi. Keuntungan dari penggunaan teknik Transfer Learning terletak pada penghematan waktu penjalanan proses training serta penghematan resource dikarenakan me nggunakan data yang lebih sedikit. Teknik ini dapat digunakan untuk mendeteksi berbagai macam objek. 3.4 Spatial Transformer Spatial Transformer merupakan modul yang bisa ditambahkan ke dalam Convolutional Neural Network yang memungkinkan manipulasi spasial data di dalam jaringan. Modul yang dapat dibedakan ini dapat dimasukkan ke dalam arsitektur Convolutional Neural Network yang sudah ada, memberikan neural network kemampuan untuk secara aktif mentransformasikan feature map secara spasial, tergantung pada feature map itu sendiri tanpa pengawasan pelatihan tambahan atau modifikasi pada proses pengoptimalan. Tahapan dari Spatial Transformer digambarkan pada Mahardika, dkk, Sistem Rekognisi Citra Digital 1163 Pada Gambar 7, mekanisme Spatial Transformer dibagi menjadi tiga bagian, yaitu jaringan Localization, Sampling Grid, dan Sampler. Jaringan Localization mengambil feature map input dan mengeluarkan parameter transformasi Teta (θ) yang harus diterapkan pada feature map melalui sejumlah hidden layer. Hasil output jaringan Localization berupa parameter transformasi Teta ( θ) akan digunakan untuk membuat Sampling Grid, yang merupakan sekumpulan titik di mana map input harus diambil sampelnya untuk menghasilkan output yang telah diubah. Hal ini dilakukan oleh generator grid, yang merupakan komponen Spatial Transformer yang memiliki fungsi eksklusif untuk melakukan transformasi invers dari output. Terakhir, feature map dan Sampling Grid yang dihasilkan oleh Grid Generator diambil sebagai input untuk Sampler, komponen lain dari Spatial Transformer selain Grid generator. Tujuan dari Sampler adalah untuk menghasilkan output map yang di -sampling dari input pada titik -titik grid. Sampler mengulangi entri grid pengambilan sampel dan mengekstrak nilai pixel yang sesuai dari input map menggunakan interpolasi bilinear. Output dari ketiga tahapan Spatial Transformer tersebut kemudian akan diteruskan ke jaringan konvolusi setelahnya. xis yis τθ(Gi) Aθ(xit yit 1) θ1,1θ1,2θ1,3 θ2,1θ2,3θ2,3 (xit yit 1) (2) Keterangan τθ Transformasi Afin 2D Aθ Gi Grid dari Output Feature Map Aθ Matriks Transformasi Afin θ xis Sumber Kordinat Sumbu X yis Sumber Kordinat Sumbu Y xit Target Kordinat Sumbu X yit Target Kordinat Sumbu Y θ Luaran Localization Kordinat ( xit,yit) adalah target kordinat pada titik -titik grid (Gi) dan berasal dari output feature map. Kordinat ( xis,yis) adalah sumber kordinat dari input feature map yang menentukan titik sampel. Output dari lapisan Localization yaitu θ menjadi penentu transformasi target, dan mungkin saja mengambil berbagai transformasi. Aθ adalah matriks transformasi afin θ. Transformasi yang didefinisikan adalah seperti cropping, translation, rotation, scale, dan skew untuk diterapkan pada input feature map, dan hanya membutuhkan 6 parameter (6 elemen Aθ) yang diproduksi oleh lapisan Localization. 3.5. Confusion Matrix Confusion Matrix adalah salah satu metode pengukuran kinerja untuk masalah klasifikasi dalam machine learning, di mana output -nya dapat berupa dua kelas atau lebih. Confusion Matrix dapat berupa tabel dengan empat macam kombinasi berbeda dari nilai prediksi dan nilai sebenarnya. Keempat macam kombinasi tersebut adalah True Positive (TP), False Positive (FP), True Negative (TN), dan False Negative (FP). Positif Sebenarnya Negatif Sebenarnya Positif Prediksi True Positive False Positive Negatif Prediksi False Negative True Negative Keempat kombinasi yang ditunjukkan pada Tabel 1 dapat digunakan untuk melakukan perhitungan metrik -metrik untuk mengevaluasi hasil prediksi sistem. Metrik yang digunakan untuk mengevaluasi yaitu Accuracy atau akurasi, Precision, Recall, dan F1-Score. Adapun rumus dari setiap metrik tersebut ditunjukkan pada persamaan - persamaan berikut Accuracy TP TN TP FP TN FN (3) Precision TP TP FP (4) Recall TP TP FN (5) F1 Score 2 Precision Recall Precision Recall (6) Keterangan TP True Positive TN True Negative FP False Positive FN False Negative Perhitungan akurasi dilakukan dengan membagi seluruh prediksi yang benar ( TP TN) oleh keseluruhan data ( TP FP TN FN) dan digunakan untuk mengetahui keefektifan secara menyeluruh dari sistem. Perhitungan Precision digunakan untuk mengetahui kesepakatan kelas label data dengan label positif yang diberikan o leh sistem, dengan cara membagi nilai True Positive (TP) dan penjumlahan True Positive dan False Positive (TP FP). Perhitungan Recall digunakan untuk 1164 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 mengetahui keefektifan dari sistem untuk mengidentifikasi label yang positif, dilakukan dengan membagi nilai True Positive (TP) dengan penjumlahan True Positive dan False Negative (TP FN). Perhitungan F1-Score digunakan untuk mengeta hui hubungan antara data dengan label positif dan data yang dilabelkan positif oleh sistem. 3.5 Flask Flask adalah sebuah kerangka kerja aplikasi web yang memberikan alat, pustaka, dan teknologi untuk membuat aplikasi web. Flask meru pakan modul python untuk membuat aplikasi berbasis web yang cukup mudah untuk digunakan. Dengan menggunakan flask, suatu model deep learning dapat diintegrasikan ke dalam aplikasi web untuk dapat digunakan. 4. HASIL DAN PEMBAHASAN Pengujian pertama yang akan diuji adalah pengaturan arsitektur CNN dengan model -model yang memiliki pretrained weights. Adapun model - model yang akan diuji yaitu ResNet18 dan ResNet50, AlexNet, dan EfficientNet B4. Selain arsitektur CNN, hal lain yang akan diuji adalah Hyperparameter dari proses pelatihan. Parameter yang akan diuji adalah optimizer dan learning rate. Berbagai optimizer yang akan diuji seperti SGD, RMSPr op, dan Adam. Sedangkan untuk learning rate, pengujian hanya akan menguji penggunaan learning rate scheduler untuk menilai keefektifan scheduler dalam membantu proses training. Setelah didapat model dan pengaturan hyperparameter yang terbaik, dilakukan pen gujian penggunaan pretrained weights dari arsitektur model untuk mencoba menaikkan hasil akurasi. Spatial Transformer juga akan diuji coba untuk melihat apakah penggunaannya mampu membuat akurasi meningkat. Terakhir, setelah didapatkan hasil yang maksimum dari kombinasi pengaturan yang terbaik, dilakukan uji coba secara real-time. Pengujian secara real-time dilakukan dengan melakukan export terhadap model dengan hasil yang terbaik, lalu diuji dengan gambar nyata yang diambil menggunakan kamera atau webcam. Pengujian secara real-time juga akan memiliki variasi terhadap pengujiannya, dimana masing -masing dari keempat dataset akan diuji coba melakukan klasifikasi secara real-time terhadap tiga macam latar belakang, yaitu latar belakang putih polos, latar belak ang hitam polos, dan latar belakang abstrak atau bermacam -macam warna. Uji coba latar belakang abstrak dilakukan untuk melihat pengaruh dari variasi warna pada latar belakang. Setelah melihat performa dari masing - masing dataset, dilakukan uji coba mengguna kan dataset gabungan dari keempat dataset untuk mencoba mendapatkan hasil yang terbaik. Pengujian model, hyperparameter, pretrained weights, dan Spatial Transformer akan menggunakan akurasi sebagai metrik utama dengan mencatat juga waktu jalannya proses tr aining. Khusus untuk learning rate, ditambahkan metrik berupa epoch hingga konvergen untuk menilai seberapa cepat model mampu mencapai titik konvergen pada proses pelatihan. 4.1 Pengujian Arsitektur Model Dalam pengujian ini digunakan empat tipe model. ResNet1 8 cukup populer di kalangan dataset kecil, tetapi juga layak digunakan pada dataset besar. Selain ResNet18, model populer lain yang juga digunakan adalah AlexNet. ResNet50 juga digunakan untuk membandingkan dengan tipe sebelumnya. Terakhir, EfficientNet B4 digunakan karena jumlah trainable parameter -nya yang tinggi, tetapi tidak terlalu besar untuk mencegah overfitting. Pengujian dilakukan dengan menggunakan Hyperparameter yang sama, yaitu optimizer Adam, learning rate 0.001, dan loss Cross Entropy. Pengujian ini tidak menggunakan Spatial Transformer. Hasil dari pengujian ditunjukkan pada Model Akurasi Waktu Training Train Valid ation Test ResNet18 99,89 100 54,73 3585s AlexNet 99,93 100 57,39 3350s ResNet50 99,83 100 57,10 4167s Efficient Net B4 99,96 100 78,10 4924s Hasil pengujian pada Tabel 2 menunjukkan bahwa model dengan arsitektur EfficientNet B4 memiliki akurasi testing yang tertinggi sebesar 78,10. Hasil ini menunjukkan bahwa model EfficientNet B4 mampu mendeteksi alfabet dalam data uji hingga didapatkan 78,10 kebenarannya. Selain memiliki akurasi testing yang tertinggi, akurasi training dan validation dari model Effi cientNet B4 juga yang terbesar, yaitu sebesar 99,96 untuk training dan 100 untuk validation. Seluruh model mendapatkan akurasi training yang tidak begitu jauh dari satu sama lain, dengan perbedaan antara hasil terendah dan tertinggi hanya sebesar 0,13. Akurasi validation tampak merata untuk keempat arsitektur yang diuji. Waktu pelatihan tercepat jatuh kepada model AlexNet dengan waktu 3350 detik atau hanya 55 menit dan terlama pada model EfficientNet B4 dengan waktu 4924 detik atau 1 jam 22 menit. Hasil ini menunjukkan bahwa model EfficientNet B4 memiliki kemampuan terbaik dalam prediksi data uji dibanding model lainnya, walau waktu pelatihannya memakan waktu paling lama. 4.2 Pengujian Hyperparameter Pengujian Hyperparameter dilakukan dengan menentukan pengat uran Hyperparameter yang dapat Mahardika, dkk, Sistem Rekognisi Citra Digital 1165 memberikan hasil yang terbaik, dan pengaturan Hyperparameter yang akan diuji yaitu optimizer dan penggunaan learning rate scheduler. Untuk model pengujian digunakan model EfficientNet B4 untuk mencari kombinasi Hyperparameter yang terbaik. Jumlah epoch yang digunakan adalah 20, dan Learning Rate yang digunakan yaitu 0.001. Pengujian optimizer dilakukan dengan mencoba satu per satu optimizer yang dapat digunakan. Opsi optimizer yang akan dicoba yaitu Adam, SGD, dan RMSProp. Pengujian ini juga tidak menggunakan Spatial Transformer. Hasil dari pengujian ditunjukkan pada Optimizer Akurasi Waktu Training Train Validation Test Adam 99,96 100 78,10 4924s SGD 4,79 3,85 3,84 4707s RMSProp 99,98 100 57,39 4767s Berdasarkan hasil pengujian Tabel 3, dapat dilihat bahwa model yang menggunakan optimizer SGD terlihat tidak berkembang. Akurasi yang didapat terlihat tidak mampu mencapai 5, baik akurasi training, validation, maupun testing. Hal ini diduga karena optimizer SGD memiliki sifat yang stokastik atau random dalam memilih data latih untuk setiap step, sehingga membutuhkan lebih banyak epoch dibandingkan dengan optimizer lain. Model dengan optimizer RMSProp terlihat cukup baik, akan tetapi akurasi testing -nya tidak sebaik dengan model yang menggunakan optimizer Adam. Hasil ini diduga dikarenakan optimizer Adam merupakan hasil perkembangan gabungan dari kedua optimizer. Setelah optimizer, pengujian Hyperparameter selanjutnya adalah penggunaan learning rate scheduler. Learning Rate Akurasi Epoch mencapai Konvergen Train Test LR 0.001 98,83 76,33 Belum Konvergen LR 0.001 Scheduler 99,96 78,10 Epoch ke-8 Pengujian learning rate scheduler dilakukan dengan menguji performa dari pelatihan apabila penggunaan scheduler diberikan. Metrik utama yang akan diperhatikan adalah jumlah epoch yang diperlukan dari model hingga mencapai titik konvergen, atau titik dimana akurasi pelatihan tidak lagi fluktuatif. Untuk nilai learning rate yang akan digunakan yaitu 0.001, dan learning rate scheduler yang digunakan adalah Exponential Learning Rate Scheduler dari library torch optim. Sebagaimana ditunjukkan pada Tabel 4, Gambar 8, dan Gambar 9, pe ngujian penggunaan Learning Rate Scheduler pada model CNN tampak memiliki pengaruh terhadap proses pelatihan maupun hasil dari output model tersebut. Dengan adanya Learning Rate Scheduler, proses pelatihan model terlihat menjadi lebih stabil. Perubahan ter hadap nilai learning rate menjadikan proses pelatihan menjadi lebih teratur dan tidak fluktuatif, sebagaimana dapat dilihat pada model yang dilatih masih belum mampu memberikan hasil yang konsisten. Hal ini memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler. Gambar 8 menunjukkan bahwa pengujian yang tidak menggunakan scheduler tampak fluktuatif dan tidak teratur. Sel ain itu, hal ini juga memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler sebagaimana ditunjukkan pada maupun testing, peng gunaan scheduler terlihat mampu menaikkan akurasi pada model yang dilatih 4.3. Pen gujian Penggunaan Pretrained Weights Pengujian penggunaan pretrained weights dilakukan dengan menggunakan parameter pretrained True ketika memanggil model menggunakan library torch untuk menggunakan weights yang sebelumnya telah dilatih dan disediakan pada pemanggilan model. Model yang akan digunakan sama seperti pengujian sebelumnya, yaitu ResNet18, AlexNet, ResNet50 dan EfficientNet B4. 1166 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 Tujuan pengujian adalah untuk m engetahui seberapa besar pengaruh pretrained weights pada proses pelatihan dan hasilnya. Pengujian menggunakan optimizer Adam dan learning rate 0.001 serta scheduler -nya. Pengujian ini tidak menggunakan Spatial Transformer. Model Akurasi Waktu Training Train Validation Test ResNet18 99,89 100 54,73 3585s ResNet18 Pretrained 100 100 84,91 3566s AlexNet 99,93 100 57,39 3350s AlexNet Pretrained 99,96 99,04 75,44 3345s ResNet50 99,83 100 57,10 4167s ResNet50 Pretrained 99,89 99,52 65,09 4119s EfficientNet B4 99,96 100 78,10 4924s EfficientNet B4 Pretrained 99,96 100 100 4870s Berdasarkan hasil pengujian yang ditunjukkan pada Tabel 5, dapat dilihat bahwa terdapat peningkatan pada akurasi testing untuk seluruh model. Peningkatan tersebut berbeda -beda pada setiap model, berkisar antara angka 8 hingga 30. Model ResNet18 mendapatkan peningkatan akurasi testing yang paling besar, yaitu 30,18. Model AlexNet juga mendapatkan peningkatan, yaitu sebesa r 18,05. Model ResNet50 mendapatkan peningkatan paling kecil, yaitu hanya sebesar 7,99. Terakhir, model EfficientNet B4 mendapatkan peningkatan sebesar 21,9 dan mampu mencapai akurasi maksimum, yaitu 100. Hasil ini menunjukkan bahwa model EfficientNet B4 sudah mampu mendeteksi seluruh data uji secara sempurna diduga karena tingkat kesulitan untuk mendeteksi data uji tidak begitu tinggi. Dari keempat model, dapat dilihat bahwa model EfficientNet B4 masih memiliki akurasi terbesar, bahkan mampu mencapai angka maksimum. Hal ini menunjukkan bahwa model EfficientNet B4 merupakan model yang terbaik dari keempat model yang diuji dalam mengklasifikasikan dataset yang diberikan. 4.4. Pen gujian Penggunaan Spatial Transformer Pengujian ini dilakukan dengan menambah kan lapisan localization dan lapisan Fully Connected yang merupakan bagian dari Spatial Transformer Network. Lapisan -lapisan ini ditambahkan tepat sebelum dimasukkan ke model EfficientNet B4 yang menjadi arsitektur utama. Pengujian akan menggunakan optimiz er Adam dan learning rate 0.001 serta scheduler -nya. Model Akurasi Train Akurasi Test Waktu Training EfficientNet B4 99,96 78,10 4924s EfficientNet B4 dengan Spatial Transformer 100 86,09 5950s EfficientNet B4 Pretrained dengan Spatial Transformer 100 100 6537s Dari hasil pengujian yang ditunjukkan pada Tabel 6, terlihat terdapat peningkatan akurasi Test pada model EfficientNet B4 dengan Spatial Transformer, yaitu sebesar 8. Akurasi yang didapat apabila EfficientNet B4 Pretrained menggunakan Spatial Transformer mampu mencapai akurasi maksimum pada data Test, yaitu sebesar 100. Adanya peningkatan akurasi menunjukkan bahwa Spatial Transformer memiliki kemampuan untuk meningkatkan kemampuan dari model dalam klasifikasi, sehingga pantas untuk digunakan untuk model akhir. Model akhir ini mampu mendapatkan nilai maksimum dari data testing, sehingga siap untuk diuji coba secara real-time. 4.5. Pen gujian Secara Real -Time Pengujian secara real-time dilakukan dengan mencoba dataset satu per satu terhadap suatu kondisi atau tampilan latar belakang tertentu dan menilai ke - efektifan masing -masing data terhadap masing - masing tampilan latar belakang, yaitu latar belakang putih, hitam, dan abstrak. Setelah itu, keempat dataset akan digabungkan menjadi satu untuk dicoba melihat keefektifannya terhadap masing -masing tampilan latar belakang. Model yang digunakan adalah model dengan pengaturan serta arsitektur ya ng terbaik, yaitu EfficientNet B4 Pretrained dengan Spatial Transformer. Data gambar akan di -convert menjadi single channel agar mempermudah prediksi melalui aplikasi. Dataset Total Benar Akurasi Latar Belakang Pengujian Putih Hitam Abstrak Latar Belakang Putih Total Benar 22 23 13 Akurasi 85 88 50 Latar Belakang Hitam Total Benar 13 16 6 Akurasi 50 62 23 Latar Belakang Karpet Total Benar 9 12 3 Akurasi 35 46 12 Latar Belakang Pemandangan Total Benar 9 4 3 Akurasi 35 15 12 Gabungan Total Benar 26 26 23 Akurasi 100 100 88 Tabel 7 menunjukkan bahwa akurasi yang didapat menggunakan dataset latar belakang hitam terlihat masih kurang baik. Dataset masih mampu melakukan klasifikasi pada latar belakang pengujian Mahardika, dkk, Sistem Rekognisi Citra Digital 1167 yang polos, seperti latar belakang putih dan hitam. Total prediksi yang benar masih mampu mencapai 50 dari seluruh alfabet pada latar belakang putih dan sebesar 62 pada latar belakang hitam. Hasil pengujian pada latar belakang abstrak terlihat hanya sebesar 23. Dapat juga dilihat pada Tabel 7 bahwa dataset dengan latar belakang putih mampu melakukan klasifikasi dengan baik pada latar belakang pengujian putih dan hitam polos, tetapi tidak te rlalu buruk pada klasifikasi dengan background abstrak. Total benar yang didapat pada latar belakang putih sebesar 85 dan latar belakang hitam 88 dari seluruh alfabet. Hasil pengujian pada latar belakang abstrak hanya sebesar 50, tetapi hasil ini masih lebih baik jika dibandingkan dengan dataset berlatar belakang hitam. Hasil pengujian dataset berlatar belakang pemandangan terlihat kurang baik. Pada latar belakang putih, total benar yang didapat hanya sebesar 35 dari seluruh alfabet, hasil yang lebih buruk jika dibandingkan dengan kedua dataset di pengujian sebelumnya. Tetapi, pengujian pada latar belakang hitam terlihat lebih buruk, hanya sebesar 15. Pengujian pada latar belakang abstrak terlihat tidak jauh, yaitu hanya sebesar 12. Dataset berlatar be lakang karpet yang ditunjukkan pada Tabel 7 terlihat lebih baik daripada pengujian pada dataset berlatar belakang pemandangan, tetapi masih kurang jika dibandingkan dengan dataset berlatar belakang hitam dan putih. Pengujian pada latar belakang putih terli hat mendapatkan total benar sebesar 35, dan pengujian pada latar belakang hitam terlihat mendapatkan total benar sebesar 46 dari seluruh alfabet. Tetapi, pengujian pada latar belakang abstrak masih terlihat buruk, yaitu hanya 12. Setelah keempat dataset diatas digabungkan, terlihat hasil pengujian secara real-time yang didapat cukup memuaskan. Sebagaimana ditunjukkan pada Tabel 7, hasil pengujian dataset gabungan pada latar belakang putih terlihat mencapai 100 total benar. Pengujian pada latar belakang hitam juga mencapai 100 total benar. Terakhir, pengujian pada latar belakang abstrak juga terlihat baik, yaitu sebesar 88.', 'ID+8102.pdf': '6 jtiik.20231 18102 Vol. 1 1, No. 6, Desember 202 4, hlm. 1169 -1176 p-ISSN 2355 -7699 Akreditasi KEMENRISTEKDIKTI, No. 3 6 E KPT 201 9 e-ISSN 2528 -6579 1169 PERANCANGAN USER EXPERIENCE APLIKASI PENGHEMAT LISTRIK MYECO DENGAN OTOMATISASI DAN MANAJEMEN LISTRIK UNTUK RUMAH TANGGA Maulana Derifato Achmad 1, Herman Tolle2, Buce Trias Hanggara3 1,2,3Universitas Brawijaya, Malang Email,, Penulis Korespondensi Abstrak Tingginya masalah pemborosan listrik di Indonesia yang menjadi budaya buruk masyarakat. Maka dapat dihadirkan suatu solusi yaitu aplikasi berbasis Internet of Things (IoT), Artificial Intelligence dan Machine Learning yang dapat menganalisis pemborosan dan memudahkan manajemen perangkat listrik. Dalam perancangan aplikasi myECO menggunakan metode Design Thinking dan Lean Startup yang setiap metodenya dibagi dalam beberapa tahapan diantaranya untuk metode Design Thinkin g untuk memahami kebutuhan pengguna, merangkum kebutuhan dari pengguna, dan untuk merancang ide solusi dari masalah. Selanjutnya untuk metode Lean Startup diantaranya terdapat Build Prototype dimana untuk membuat dan mengembangkan produk sederhana atau MVP (Minimum Viable Product ), Test and Measure untuk mengamati dan mengukur feedback yang diberikan oleh pengguna saat mencoba menggunakan MVP guna melakukan validasi solusi. Dalam mengembangkan aplikasi yang memiliki pengalaman pengguna yang baik dan desain yang sesuai dengan kebutuhan user maka aplikasi myECO melakukan pengujian menggunakan 2 metode yaitu usability test dan UEQ test. Dimana pada metode usability test menggunakan alat ukur maze design dengan hasil menunjukan bahwa pada 42 responden, terdapat 38 responden direct success dan 4 responden indirect success. Selanjutnya, untuk UEQ test dilakukan melalui metode open source dan tools excel yang disediakan pada website resmi UEQ dengan hasil menunjukan bahwa pada scale stimulasi dan kebaruan memiliki p erbandingan tolok ukur good, pada scale daya tarik, kejelasan, dan ketepatan memiliki perbandingan tolok ukur above average, serta yang terakhir pada scale ketepatan memiliki perbandingan tolok ukur below average. Dengan adanya aplikasi ini diharapkan dapa t menekan angka pemborosan penggunaan listrik dan tingginya biaya tanggungan listrik yang harus dibayarkan. Kata kunci design thinking, lean startup, aplikasi mobile DESIGNING USER EXPERIENCE FOR ELECTRICITY SAVING APPLICATIONS OF MYECO WITH AUTOMATION AND ELECTRICITY MANAGEMENT FOR HOUSEHOLDS Abstract The high problem of wasting electricity in Indonesia has become a bad culture for society. Then a solution can be presented, namely an application based on the Internet of Things (IoT), Artificial Intel ligence and Machine Learning that can analyze waste and facilitate the management of electrical devices. In designing the myECO application using the Design Thinking and Lean Startup methods, each method is divided into several stages including the Design Thinking method to understand user needs, summarize the needs of users, and to design ideas for solutions to problems. Furthermore, for the Lean Startup method, there is a Build Prototype where to create and develop a simple product or MVP (Minimum Viable Product), Test and Measure to observe and measure the feedback given by users when trying to use MVP to validate solutions. In developing applications that have good user experience and designs that suit user needs, the myECO application tests using 2 meth ods, namely the usability test and the UEQ test. Where in the usability test method using a maze design measuring instrument with the results showing that of the 42 respondents there were 38 direct success respondents and 4 indirect success respondents. Fu rthermore, the UEQ test was carried out using the open source method and excel tools provided on the official UEQ website with the results showing that on the stimulation and novelty scales it has a good comparison of benchmarks, on the scale of attractive ness, clarity and accuracy it has a comparison of the benchmarks above average, as well as the last on the precision scale having below average benchmark 1170 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm. 1169 -1176 comparisons. With this application, it is hoped that it can reduce the waste of electricity usage and the high responsibility for electricity costs which must be limited. Keywords design thinking, lean startup, application mobile 1. PENDAHUL UAN Listrik menjadi salah satu kebutuhan yang sangat penting di era saat ini dan menjadi k ebutuhan yang dicari serta diperhatikan keberadaannya oleh semua orang. Indonesia sendiri peringkat ke 17 dengan konsumsi energi listrik tertinggi di dunia. Daftar tersebut dikeluarkan oleh Organisasi riset internasional Statista. Pemakaian listrik terus terjadi peningkatan yang mencapai 4,45 dari tahun sebelumnya yang sebesar 1.123 kWh di tahun 2021 menjadi 1.173 kWh ditahun 2022 yang diungkapkan oleh Kementerian Energi dan Sumber Daya Mineral Republik Indonesia. Kebutuhan listrik telah menjadi hal yang penting. Nam un masih banyak orang yang tidak peduli akan pemborosan listrik yang terjadi. Energi yang di gunakan saat ini di indonesia yaitu menggunakan energi fosil dan non fosil, energi fosil yang di gunakan bisa habis dalam waktu cepat atau lambat sistem distlbusi listrik di Indonesia sekarang ini dan umumnya menggunakan sistem sentralisasi listrik. Porsi konsumsi listrik dari air conditioner (AC) serta lampu tergolong besar yaitu di atas 45 dan 30 di perkantoran. Konsumsi energi listrik semakin h ari terus meningkat dengan rata -rata pertumbuhan konsumsi energi listrik dari tahun 2012 sebesar 2,3 -2,5 dan diperkirakan hingga akhir tahun 2030 kebutuhan energi listrik akan menjadi dua kali lebih besar berisar sekitar 16.000 TWh per tahunnya Menurut Kementerian Energi dan Sumber Daya Mineral Republik Indonesia tahun 2011, bahwa masalah pemborosan energi listrik ini sebesar 80 disebabkan oleh faktor manusia dan 20 -nya disebabkan oleh faktor teknis. Faktor manusia sebesar 80 yang menjad i sumber pemborosan sehingga dibutuhkan inovasi teknologi yang dapat mengurangi persentase tersebut Di pasaran banyak beredar alat penghemat listrik untuk cakupan rumah tangga yang ternyata setelah diteliti oleh PLN dan telah disampaikan oleh Kementeria n Energi dan Sumber Daya Mineral dalam Diskusi Energi MNC Trijaya berdasarkan hasil penelitiannya yang menunjukkan hasil bahwa tidak ada dampak langsung alat tersebut terhadap penurunan beban biaya listrik. Alat penghemat listrik yang telah banyak beredar di masyarakat adalah capacitor bank yang hanya penstabil daya semu dan terbukti tidak melakukan penghematan tagihan pemakaian listrik. Alat lainnya berupa Kartu Ajaib yang juga tidak berdampak. Berdasarkan masalah tersebut, maka dilakuk an perancangan UI UX aplikasi teknologi inovasi baru bernama myECO merupakan aplikasi untuk manajemen perangkat elektronik agar dapat mati dan nyala otomatis menurut kondisi ruangan menuju penghematan listrik. Tidak hanya mampu memonitor kondisi perangkat dan biaya listrik, tetapi juga dapat memanajemen perangkat listrik secara otomatis. Hal ini dapat dilakukan dengan bantuan informasi yang diberikan pengguna serta algoritma yang dapat memproses data secara real-time dengan basis micro - machine learning dan dibantu dengan IoT ( Internet of Things ). myECO dapat dijadikan sebagai one stop solution dari permasalahan yang sering terjadi terkait penghematan listrik. Aplikasi ini mampu menganalisis kondisi setiap ruangan, memberikan rekomendasi produk dan hasil analisis yang relevan, serta dapat membantu untuk mengontrol perangkat elektronik secara mud ah. Melalui bantuan rancangan User Interface dan User Experience (UI UX) dalam merancang solusi aplikasi myECO agar sesuai permasalahan dan kebutuhan user. UI UX yang dikerjakan, dihasilkan dari framework design thinking dengan pendekatan validasi ide, be rdasarkan kebutuhan atau permasalahan user melalui pengujian prototyping design khususnya UI dan pengujian ide kepada calon user. Melalui 2 kombinasi metode untuk mendapat problem -solution fit dengan design thinking dan develop product fit dengan lean star tup diharapkan setelah hadirnya myECO dari hasil validasi dan iterasi tidak ada kembali perangkat listrik yang menyala saat tidak. Sehingga dapat menekan pemborosan dan tingginya biaya tanggungan listrik. 2. METODE PENELITIAN Metode yang digunakan pada peneli tian ini yaitu metode Choose Playing Field untuk awal perancangan dan dilanjutkan oleh metode gabungan dari Design Thinking Lean Startup yang dapat melakukan iterasi secara berkelanjutan dan tak terhingga untuk memvalidasi kebutuhan pengguna dan kecocokan antara masalah serta solusi hingga menjadi Product Problem -Solution Fit. Choose playing field akan digunakan untuk mencari segmen yang te pat untuk divalidasi. Sedangkan, Design thinking digunakan untuk menemukan masalah dan menghasilkan ide solusi dan Lean Startup digunakan untuk validasi dan iterasi pengembangan solusi atau prototyping. Proses iterasi berkelanjutan akan memastikan setiap p erkembangan dan perubahan produk selalu berdasar pada kebutuhan user. Achmad, dkk, Perancangan User Experience 1171 Tahapan ini diawali dengan metode Choose Playing Field dalam menentukan m enentukan asumsi masalah dan solusi serta berfokus menemukan segmen yang akan dituju berupa niche market. Untuk menentukan segment matrix, dilakukan pengumpulan data mengenai hal -hal yang berkaitan dengan customer secara langsung guna mengetahui terkait tingkat depth of pain, budget dari customer, market size yang ingin dijangkau, dan seberapa cepat customer dapat memperoleh solusi terhadap masalah yang dialami serta value yang akan mereka rasakan setelah menggunakannya. Selanjutnya dilakukan voting berda sar beberapa pertimbangan dan diperolehnya asumsi rumah tangga perkotaan yang sudah berkeluarga sebagai niche market atau beachhead market dari customer development yang telah dilakukan. Dikarenakan rumah tangga dengan banyak keperluan di rumah dan bekerja membuat kelupaan untuk mematikan listrik. Selanjutnya, akan masuk ke tahap interview untuk memvalidasi secara langsung ke customer. a. Design Thinking 1) Empathize Fase empathize merupakan fase awal dalam metode design thinking. Pada tahapan ini, terdapat proses wawancara, observasi, tanya jawab dengan skenario yang sudah ditentukan ke niche market, yaitu rumah tangga perkotaan. Berdasarkan tahapan ini, masalah dan solusi yang didapatkan diantaranya yaitu pengguna membut uhkan penghematan biaya listrik dan memudahkan dalam manajemen listrik. 2) Define Pada fase define akan menganalisis serta menentukan topik yang paling utama untuk dapat diselesaikan dengan Menyusun How Might We Question yang terdiri dari 3 tema yaitu tema fungsionalitas, navigasi dan fitur. 3) Ideate Pada fase ideate ini dimana merupakan tahapan penentuan solusi terhadap permasalahan yang didapat pada tahapan sebelumnya. b. Lean Startup 1) Build Prototype Berdasarkan asumsi solusi yang telah didefinisikan pada tahap sebelumnya, selanjutnya dilakukan pembuatan user journey untuk mengetahui alur yang akan dilalui oleh user untuk mencapai solusinya. Dilanjutkan dengan pembuatan produk desain yang diawali membu at low fidelity sketch. Selanjutnya, pada tahap iterasi lean startup, ketika solusi sudah dianggap fit, maka dilakukan pembuatan MVP ( Minimum Viable Product ) berupa high fidelity design. 2) Test and Measure Pada proses ini, dilakukan validasi sketch atau Mini mum Viable Product yang sudah dibuat untuk mendapat feedback. Pada tahap ini juga dilakukan usability testing dengan metode wawancara untuk mendapatkan feedback dari pengguna secara langsung. 3) Learn and Iterate Setelah melakukan usability testing terhadap prototype aplikasi, selanjutnya dilakukan review dan analisis hasil measurement dan validasi sehingga dapat dihasilkan kesimpulan dalam mengambil langkah keputusan iterasi dan perbaikan di tahap selanjutnya. 3. HASIL DAN PEMBAHASAN Perancangan User Experience pada aplikasi myECO ini menggunakan website figma. Pada target pengguna ini yang akan kami tuju adalah rumah tangga produktif sesuai dengan hasil tahap Choose Playing field. Niche market tersebut merupakan alasan utama sebagai p enggerak dari berkembangnya aplikasi ini dan kebutuhan yang akan disediakan pada aplikasi ini. Berdasarkan dari hasil wawancara maka dibuatlah sebuah empathy map untuk memetakan tanggapan dari hasil wawancara kepada rumah tangga produktif. Empathy map dibuat untuk mengetahui 1172 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm. 1169 -1176 kebutuhan dari penggunanya. Berikut adalah empathy map yang dibuat berdasarkan wawancara. Selanjutnya untuk pembuatan persona dilakukan berdasarkan abstraksi dari wawancara dengan menyesuaikan kebutuhan yang terdapat pada pengguna. Penulis membagi persona yang terdiri dari data diri persona, tujuan ( goals ), kesulitan (frustration ), dan fitur. Didapatkannya pain poin dan kebutuhan pokok dari aplikasi sehingga didapatkan Value Proposition sebagai berikut Value Proposition menjadi tujuan fokus utama dalam pembentukan aplikasi yang alur dari salah satu fungsi manage berjalan dengan user journey sebagai berikut Berdasarkan analisa yang telah dilakukan sebelumnya maka perlu dilakukan perancangan penghematan listrik berupa aplikasi myECO dengan berbagai fitur penghematan menggunakan bantuan platform figma, sedangkan clickable -prototype dilakukan dengan bantuan plat form Marvelapp. Berikut hasil dari perancangan UI UX pada aplikasi myECO 3.1. Design System Font yang digunakan pada perancangan ini yakni free for personal commercial use, tingkat keterbacaan (legibility readability) yang baik, ukuran jarak antar karakter (kerning) yang baik, menggunakan konsep modern and friendly, menggunakan warna hijau sebagai warna utama, warna kuning sebagai warna yang berdekatan dengan warna utama, warna gradien antara warna hijau tu a dan hijau muda serta penggunaan warna hitam pada desain aplikasi. 3.2. Micro Interaction Micro interaction adalah unsur atau detail kecil respon visual yang dilihat pengguna saat melakukan tindakan atau interaksi pada produk diluar tombol biasanya. Ada b anyak hal micro interaction yang disematkan pada UI UX myECO, beberapa diantaranya adala h a. Delete Slider and Progress Pie delete dengan slide kiri dan ketahui progres capaian dengan pie chart dinamis. b. Timer countdown animasi dinamis hitungan mundur pada fitur timer. Achmad, dkk, Perancangan User Experience 1173 c. Smart Pop Up (bounce and smooth) pantulan saat mengeluarkan atau memasukkan sebuah tampilan. (sesudah dan sebelum di klik) d. Done Task Animation sebuah animasi perayaan menandakan pekerjaan telah selesai 3.3. Hasil Perancangan Adapun hasil perancangan aplikasi myECO terdiri dari beberapa fitur yang ditunjukkan pada gambar berikut Aplikasi myECO hasil memberikan 3 layanan utama dan layanan tambahan lainnya antara lain Control, Manage, Monitor untuk menunjang penekanan penggunaan listrik. Berikut detail dari hasil perubahan pada perancangan UI UX pada aplikasi myECO a. Tampilan Dashboard Aplikasi Pada halaman dashboard ini menampilkan berbagai menu dan fitur -fitur yang lebih lengkap terdiri profil pengguna, menu smart advisor, informasi pengingat, menu dari fitur -fitur yang ditawarkan, hasil monitoring perangkat listrik, menu utama aplikasi dan beberapa menu menarik lainnya. b. Tampilan Menu Kontrol IoT Automation Fitur kontrol merupakan fitur dimana user dapat melakukan kontrol dari jarak jauh nyala mati perangkat yang terhubung dengan aplikasi dengan berbagai pilihan (manual otomatis jadwal timer). c. Tampilan Menu Manage 1174 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm. 1169 -1176 Menu manage merupakan menu yang digunakan oleh user dalam melakukan manajemen perangkat listrik yang terdiri dari beberapa pilihan yaitu manage perangkat, manage ruangan, manage pengingat, manage payment dan manage sharing device. d. Tampilan Monitoring Layan an Pada tampilan monitoring layanan terdapat beberapa monitoring diantaranya yaitu monitoring forecast, monitoring biaya, monitoring kWH dan monitoring status. e. Fitur Menarik Lainnya Adapun fitur -fitur menarik lainnya yang terdaapat pada aplikasi myECO berdasarkan hasil perancangan user experience diantaranya yaitu fitur smart advisor, fitur kalkulator listrik, fitur layanan challenge, fitur konsultasi, fitur pembayaran listrik PLN, fi tur komunitas, fitur keranjang, dan fitur analisa. Untuk menciptakan aplikasi yang memiliki pengalaman pengguna yang baik dan desain yang sesuai dengan kebutuhan user maka, aplikasi myECO melakukan pengujian menggunakan 2 metode a. Usability Test Digunakannya Usability Testing dengan bantuan maze design melalui beberapa pertanyaan untuk menggali kemudahan dari fitur yang telah dibuat. Lalu dilanjutkan UEQ Test melalui metode open source dan tools excel yang disediakan pada website resmi UEQ untuk menguji tingkat kesan terhadap 5 parameter yaitu daya tarik, kejelasan, ketepatan, stimulasi dan kebaruan. Dari uji yang telah dilakukan di hasilkan ringkasan sebagai berikut Berdasarkan hasil dari dilakukanya maze design, dapat disimpulkan bahwa dalam 59 responden yang melakukan testing, diperolehnya 40 responden dengan hasil direct succes dimana artinya responden langsung berhasil menyelesaikan skenario pengujian sesuai dengan tahapan dan ekspektasi yang telah ditentukan. Sedangkan untuk 19 responden lainnya memperoleh hasil indirect success dimana artinya responden menyelesaikan skenario pengujian belum seluruhnya sesuai dengan tahapan dan ekspektasi yang telah ditentukan. b. UEQ Test Sebanyak 40 responden menjawab semua item yang telah ditentukan dengan memberikan nilai di setiap item dengan skala 1 -7. Berdasarkan hasil dari dilakukanya UEQ test, dapat disimpulkan bahwa pada scale stimulasi dan kebaruan menyatakan perbandingan tolok ukur adalah good, sedangkan pada scale daya tarik dan kejelasan menyatakan perbandingan tolok ukur above average, dan yang terakhir untuk scale efisiensi menyatakan tolok ukur perbandingannya adalah below average. 4.', 'ID+8108.pdf': '1. PENDAHULUAN Pesatnya pertumbuhan ilmu pengetahuan dan teknologi saat ini ini bisa dialami serta memengaruhi kehidupan manusia. Dalam dunia pembelajaran, teknologi mempunyai akiba t positif yang nyata untuk pendidikan. Siswa bisa mengakses data lebih banyak serta lebih cepat dari bermacam sumber. Tidak hanya itu, banyak aplikasi yang bisa digunakan guru semacam power point, youtube, maupun sistem berbasis e -learning selaku media pen didikan. Pemanfaatan teknologi dapat membantu proses belajar mengajar jadi lebih mengasyikkan dan inovatif. Tidak semua sekolah mampu untuk memanfaatkan beberapa teknologi tersebut karena beberapa faktor seperti keterbatasan alat dan jangkauan sinyal. Oleh karena itu guru sebagai seorang pendidik juga betugas sebagai fasilitator untuk memusatkan perhatian siswa terhadap kegiatan belajar. Dalam memusatkan perhatian siswa, terdapat berbagai cara yang dapat diterapkan oleh pendidik. Salah satunya adalah media, media merupakan cara yang efektif untuk memusatkan perhatian siswa. Penggunaan media pembelajaran di SMK Negeri 10 Malang memang diserahkan keputusan penggunaannya kepada guru di kelas saat mengajar dengan acuan modul ajar sesuai kurikulum yang berlaku. Ada guru yang menyampaikan langsung seperti ceramah atau memberikan tugas langsung seperti tugas kelompok pada muridnya untuk memenuhi capaian pembelajaran saat di kelas. Saat menyampaikan pembelajaran tanpa menggunakan media seperti ini siswa banyak sekal i yang tidak memahami langsung materi apa yang sedang dikerjakan. Siswa yang mengerjakan tugas secara kelompok akhirnya membagi pengerjaan soal secara bergantian yang membuat siswa tidak memahami materi secara menyeluruh dan berdampak ketika melakukan peng erjaan soal secara individu. Informatika sebagai mata pelajaran wajib di kelas X DKV SMK Negeri 10 Malang mempunyai kekhasannya tersendiri yang dirasakan oleh para siswa dalam menyerap materi yang diterangkan guru. Dibutuhkannya penjelasan ekstra dan terta ta dari guru dalam menjelaskan materi, namun karena penggunaan media pembelajaran yang dirasa kurang selaras serta siswa yang sudah mulai merasa bosan dengan pembelajaran konvesional yang membuat siswa tidak dapat mengerjakan tugasnya dengan baik. Terbukti di hasil UTS kelas X DKV 3 SMK Negeri 10 Malang rata -rata dari nilai siswa ini mendapatkan hasil dibawah KKM dengan nilai 66,12 dari nilai KKM yang sudah ditetapkan oleh sekolah yaitu 80. Untuk mengatasi permasalahan ini, peneliti memberikan solusi yang d apat diterapkan yaitu seperti menggunakan media pembelajaran interaktif Quizizz. Menurut Solikah, Quizizz merupakan platform berbasis kuis yang dikombinasikan dalam bentuk permainan dan dapat digunakan sebagai media dalam pembelajaran. Mulanya aplikasi ini hanya untuk permainan dan hiburan pada anak -anak yang gemar permainan tantangan. Namun akhir -akhir ini, aplikasi game Quizizz ini beralih fungsi oleh beberapa guru sebagai media dalam proses pembelajaran. Bertambahnya fungsi dari aplik asi game Quizizz ini juga sangat membantu bagi para guru dalam mengevaluasi siswa dari proses pembelajaran yang sudah dilakukan kelas, seperti fitur penampil materi seperti power point yang di tampilkan secara menarik pada media pembelajaran Quizizz ini la lu juga ada fitur baru seperti paper mode di mana fitur ini memungkinkan siswa untuk menggunakan Quizizz tanpa harus terhubung secara langsung ke internet, dan guru bisa melihat nilai yang diperoleh oleh setiap siswa pada papan peringkat sehingga proses ev aluasi dapat dilaksankan secara optimal. Penerapan solusi ini, bertujuan untuk menjelasakan ada tidaknya pengaruh dari penggunaan media pembelajaran interaktif Quizizz terhadap hasil belajar siswa kelas X DKV SMK Negeri 10 Malang terutama di aspek kognitif dan untuk menjelaskan efektifitas media pembelajaran interaktif Quizizz pada pembelajaran di kelas X DKV SMK Negeri 10 Malang Penggunaan media pembelajaran interaktif Quizizz memberikan pengaruh pada hasil belajar siswa hal ini sejalan dengan penelitian y ang telah dilakukan oleh Solikah dengan judul Pengaruh Penggunaan Media Pembelajaran Interaktif Quizizz Terhadap Motivasi Dan Hasil Belajar Siswa Pada Materi Teks Persuasif Kelas Viii Di SMP Negeri 5 Sidoarjo Tahun Pelajaran 2019 2020. Didapatkan hasil bahwa ada pengaruh terhadap penggunaan media interaktif Quizizz terhadap motivasi dan hasil belajar siswa pada materi teks persuasif kelas VIII di SMPN 5 Sidoarjo tahun pelajaran 2019 2020. Dari penelitian Agustina, setelah penggunaan aplikasi q uiziz sebagai alat evaluasi pembelajaran. 100 persen yang menyatakan bahwa quiziz membuat tes lebih menarik, 94,4 persen yang menyatakan bahwa aplikasi quiziz dapat meningkatkan keinginan belajar, 83,3 persen yang menyatakan aplikasi quiziz merupakan aplik asi terbaik untuk tes, 66,7 persen yang menyatakan bahwa aplikasi quiziz cocok untuk setiap melakukan tes, 83,3 persen yang menyatakan bahwa aplikasi quiziz membuat siswa lebih rileks mengerjakan ujian. Penelitian yang akan dilaksanakan oleh penuli s sendiri berlokasi di SMK Negeri 10 Saputra, dkk, Pengaruh Penggunaan Media Pembelajaran 1179 Malang dengan menggunakan dua macam kelas penelitian, yaitu kelas kontrol yang menggunakan media pembelajaran secara konvensional dan kelas eksperimen yang diberikan treatment berupa penggunaan med ia pembelajaran interaktif Quizizz. Penelitian ini sendiri menggunakan model penelitian Quasy Experimental dengan jenis penelitian Non-Equivalent Control Group Design, dikarenakan penelitian yang dilakukan menggunakan hasil dari pre-test dan post-test. 2. KAJIAN PUSTAKA Dibandingkan dengan penelitian sebelumnya penelitian ini memliki fokus tersendiri yaitu pada aspek kognitif terutama di hasil belajar siswa setelah menggunakan media pembelajaran inter aktif Quizizz. berbeda seperti penelitian yang dilakukan oleh Ratnasarianti, E., ditemukan bahwa penggunaan media pembelajaran interaktif berbasis aplikasi Quizizz dapat meningkatkan minat belajar siswa. Dan penelitian yang dilakukan oleh Joubert M Dame pada tahun 2022 didapatkan hasil bahwa ada pengaruh penggunaan media interaktif Quizizz terhadap motivasi siswa smk negeri 2 Tondano., Menurut Taofano, media pembelajaran adalah alat bantu dalam proses belajar mengajar untuk merangsang pikiran, perasaan, perhatian dan kemampuan atau keterampilan pembelajar sehingga dapat mendorong terjadinya proses belajar. Menurut Daryanto, media interaktif adalah suatu media yang dapat dioperasikan oleh pengguna, sehingga pengguna dapat memilih apa yang dikehend aki untuk proses selanjutnya. Berdasarkan definisi yang telah dikemukakan tersebut, dapat disimpulkan bahwa media pembelajaran interaktif adalah alat bantu maupun benda yang bertujuan dapat memudahkan dalam proses pembelajaran untuk menyampaikan pesan atau informasi mengenai materi yang disampaikan dan memiliki interaktifitas dengan penggunanya. Dari buku evaluasi hasil belajar karya Zulkifi, hasil belajar merupakan suatu perubahan perilaku yang terjadi bagi seseorang setelah selesai melakukan penyel enggaraan pembelajaran. Hasil belajar dapat dilihat dari peningkatan kemampuan siswa dalam memahami materi pembelajaran, mengerjakan tugas, dan ujian. Aspek kognitif dalam capaian hasil belajar merujuk pada kemampuan siswa dalam memperoleh pengetahuan, pem ahaman, aplikasi, analisis, sintesis, evaluasi, dan kreativitas. Dalam konteks pembelajaran, aspek kognitif berfokus pada perkembangan pengetahuan dan pemahaman siswa terhadap materi pembelajaran. Pembelajaran yang efektif adalah kombinasi yang tersusun meliputi unsur -unsur manusiawi, material, fasilitas, perlengkapan, dan prosedur untuk mengubah perilaku siswa ke arah yang positif dan lebih baik dengan potensi dan perbedaan yang dimiliki siswa untu k mencapai tujuan pembelajaran yang telah ditetapkan. Agar pembelajaran menjadi efektif beberapa komponen, fasilitas, dan sumber -sumber pembelajaran harus dikelola dengan baik. Penggunaan media dalam pembelajaran dapat membangkitkan motivasi, mina t dan keinginan baru dalam diri pembelajar. Dapat disimpulkan bahwa efektivitas adalah pengaruh untuk mencapai tujuan yang diterapkan. Pada penelitian ini, efektivitas yang akan digunakan adalah media pembelajaran interaktif Quizizz hasil belajar siswa kelas X DKV SMK Negeri Malang. Penggunaan media pembe lajaran interaktif Quizizz diharapkan dapat membantu meningkatkan efektivitas pembelajaran dan penyampaian pesan serta isi pelajaran pada saat itu. Pada penelitian ini, indikator efektivitas yang akan digunakan berfokus pada hasil dari penggunaan media yan g digunakan yaitu Quizizz. Hal ini diharapkan penggunaan media pembelajaran interaktif Quizizz dapat menyampaikan materi secara rinci, membuat proses pelajaran menjadi lebih menarik dan meningkatkan kualitas hasil belajar dari peserta didik. 3. METODOLOGI PEN ELITIAN Pada penelitian ini, peneliti akan melakukan eksperimen terhadap pengaruh dan efektivitas penggunaan media pembelajaran interaktif Quizizz terhadap hasil belajar siswa dengan menggunakan metode penelitian eksperimen, dengan rancangan quasi experime ntal design Pretest treatment Posttest 01 X 02 03 - 04 Keterangan 01 Pretest yang diberikan kepada kelas eksperimen 02 Posttest yang diberikan kepada kelas eksperimen 03 Pretest yang diberikan kepada kelas kontrol 04 Postest yang diberikan kepada kelas kontrol X Perlakuan pada kelas eksperimen dengan menggunakan media pembelajaran interaktif Quizizz - Perlakuan pada kelas kontrol dengan menggunakan media pembelajaran konvensional 1180 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1177 -1184 Gambar 1 Diagram Alir Untuk langkah -langkah penelitian yang akan dilakukan oleh peneliti ditunjukan dalam bentuk gambar diagram alir seperti pada gambar di atas ini yang dimulai dari proses analisis permasalahan, dilanjutkan denga n studi literatur, kemudian menentukan sampel, materi, dan waktu pelaksanaan penelitian, penyusunan perangkat dan instrumen penelitian, kemudian divalidasi oleh para ahli, selanjutnya pelaksanaan penelitian dan pengumpulan data, dari data yang telah didapa t diolah, setelah itu data yang telah diolah dianalisis, yang kemudian diambil sebuah kesimpulan dari hasil analisis yang telah dilakukan. Proses pelaksanaan kegiatan penelitian yang dilakukan nantinya akan dilaksanakan pada kelas kontrol hanya menggunaka n metode pembelajaran secara konvensional saja, sedangkan untuk kelas eksperimen menggunakan media pembelajaran interaktif Quizizz, kemudian untuk masing -masing kelas diberikan pre -test dan post -test untuk mengetahui hasil belajar siswa. 4. ANALISIS DAN HASIL PEMBAHASAN 4.1 Hasil Validasi Untuk proses validasi instrumen melibatkan 3 orang ahli yang terbagi ke dalam 2 orang pihak dosen dan 1 orang pihak guru sekolah. Yang mana dari hasil validasi dari ketiga ahli tersebut dapat dijabarkan dalam Tabel 2 dan Ta bel 3. Kode validator Hasil rerata skor KET V1 3,83 Valid V2 3,16 Valid V3 3,83 valid Tabel 3 Hasil validasi instrumen modul ajar Kode validator Hasil rerata skor KET V3 3,73 Valid Setelah mendapatkan validasi oleh ahlinya dilanjut dengan melakukan uji validitas dan uji reliabilitas kepada instrumen soal pretest dan posttest kepada siswa dan didapatkan hasil untuk uji validitas bahwa nilai rhitung soal nomor 1 adalah 0.671, rhitung soal nomor 2 adalah 0.447, dan rhitung soal nomor 3 adalah 0.731, soal nomor 4 adalah 0.453, soal nomor 5 adalah 0.676, soal nomor 6 adalah 0.484, soal nomor 7 adalah 0.397, soal nomor 8 adalah 0.406, soal nomor 9 adalah 0.556, soal nomor 10 adalah 0.550. Semua item soal menghasilkan nilai rhitung lebih dari rtabel dengan N 30 dan taraf signifikansi 5 yaitu rtabel 0. 0.361 sehingga semua item s oal dapat dikatakan valid. Setelah dinyatatakan valid selanjutnya data diujikan untuk uji reliabilitas dan diketahui nilai reliabilitas tes secara keseluruhan adalah 0.728 dan rtabel pada taraf signifikansi 5 dengan N 10, dk 10 1 9 diperoleh rtab el 0.666. Oleh karena rhitung rtabel atau 0.728 0.666 maka dapat disimpulkan bahwa soal pretest dan posttest yang merupakan instrumen penelitian tersebut dinyatakan reliabel. 4.2 Hasil Penelitian Dari pelaksanaan kegiatan siswa yang terlibat dalam penelitian berasal dari kelas X Desain Komunikasi Visual 3 sebagai kelas eksperimen dan X Desain Komunikasi Visual 4 sebagai kelas kontrol. Total kelas berjumlah 67 siswa. Untuk kelas X DKV 3 berjumlah 31 siswa dan untuk kelas X DKV 4 berjumlah 36 siswa, n amun ketika pengambilan data berlangsung terdapat beberapa siswa yang tidak menghadiri proses pembelajaran dikarenakan izin dan sakit sehingga jumlah siswa yang terlibat dalam proses penelitian adalah 60 siswa, 30 dari kelas X DKV 3 dan 30 dari kelas X DKV 4. Setelah dilakukan analisis deskriptif didapati mean untuk pre -test pada kelas eksperimen yaitu 62,67. Untuk nilai rata -rata post -test pada kelas eksperimen setelah dilakukan analisis deskriptif adalah 91,67, dan untuk mean untuk pre -test pada kelas kon trol yaitu 66,67. Selanjutnya untuk nilai rata-rata post -test pada kelas kontrol setelah dilakukan analisis deskriptif adalah 82,33. 4.2.1 Uji Homogenitas Uji homogenitas bertujuan untuk menguji apakah data dari dua kelompok sampel penelitian mempunyai va rians sama atau tidak. Data yang digunakan untuk menguji homogenitas kelas adalah nilai UTS kelas X DKV 3 dan X DKV 4. Dari hasil perhitungan uji homogenitas menunjukkan nilai signifikansi sebesar 0,658 yang berarti nilai tersebut 0,05 sehingga dapat dia mbil kesimpulan bahwa data tersebut homogen. Saputra, dkk, Pengaruh Penggunaan Media Pembelajaran 1181 4.2.2 Uji Normalitas Selanjutnya dilakukan uji normalitas dari pretest dan posttest yang sudah diberikan ke siswa. Uji normalitas bertujuan untuk mengetahui apakah data yang diperoleh dari hasil tes berdistribus i normal atau tidak. Hasil output dari uji normalitas menunjukkan nilai signifikansi hasil pretest untuk kelas eksperimen yaitu kelas X DKV 3 sebesar 0,057 0,05 yang berati data tersebut dapat dikatakan normal, untuk nilai signifikansi hasil posttest untuk kelas eksperimen yaitu kelas X DKV 3 sebesar 0,000 0,05 yang berati data tersebut dapat dikatakan tidak normal dan nilai signifikansi pretest untuk kelas kontrol yaitu kelas X DKV 4 sebesar 0,017 0,05 yang berati data tersebut dapat dikatakan tidak normal, selanjutnya untuk nilai signifikansi hasil posttest untuk kelas kontrol yaitu kelas X DKV 4 sebesar 0,000 0,05 yang berati data tersebut dapat dikatakan tidak normal. 4.2.3 Uji Hipotesis Setelah melakukan uji prasyarat, dilakukan pengujian hipote sis. Uji hipotesis diterapkan guna melihat apakah ada pengaruh penggunaan media pembelajaran interaktif Quizizz terhadap hasil belajar siswa kelas DKV 10 SMK Negeri 10 Malang pada mata pelajaran informatika. Setelah dilakukan uji normalitas, menghasilkan k esimpulan bahwa data tidak terdistribusi secara normal. Output tes normaliltas menujukkan nilai (.sig) 0,05. Dikarenakan dalam tes normalitas data tidak berdistribusi secara normal, maka peneliti menggunakan pengujian non -parametik sebagai alternatifnya. Guna menguji perbedaan dari kedua kelas dilakukan Uji Man -Whitney sebagai alternatif dari Uji Independent sampel t -tes, serta untuk melihat peningkatan nilai dari kelas yang sama menggunakan uji Wilcoxon sebagai alternatif dari two paired sampel t -tes. Tabel 4 Output uji Man -Whitney Soal Mean rank Nilai Sig. Pre kontrol eksperimen 30,95 30,05 0,839 Post kontrol eksperimen 20,98 40,02 0,000 Untuk uji hipotesis pertama melakukan uji Man - Whitney untuk mencari beda nilai pretest kelas experimen dan kelas kontrol. Didapati perbedaan pangkat rata -rata atau mean rank dari kedua kelas yang tidak jauh beda untuk keduanya di mana untuk kelas kontrol mendapatkan mean rank sebesar 30,95 dan kelas eksperimen mendapatakan mean rank sebesar 30,05. Mean rank kelas kontrol lebih tinggi dari pada kelas eksperimen. Output yang dihasilkan menyatakan nilai asymp. Sig. adalah 0,893. Hasil nilai (sig.) adalah lebih besar dari 0,05 maka dari itu H0 dapat diterima dan H1 ditolak. Kesimpulannya adalah tidak ada perbedaan nilai pretest kelas eksperimen dengan kelas kontrol. Lalu untuk mencari beda nilai posttest kelas experimen dan kelas kontrol terdapat perbedaan pangkat rata -rata atau mean rank dari kedua kelas. Di mana mean rank kelas kontrol lebih rendah dari pada kelas eksperimen yang menghasilkan output yang dihasilkan menyatakan nilai asymp. Sig. adalah 0,000. Hasil nilai (sig.) adalah lebih kecil dari 0,05 maka dari itu H1 diterima dan H0 ditolak. Kesimpulannya adalah ada perbedaan nilai posttest kelas eksperimen dengan kelas kontrol. Tabel 5 Output uji Wilcoxon Soal Rerata Nilai Sig. Pre post eksperimen 62,67 91,67 0,000 Pre post kontrol 66,67 82,33 0,000 Selanjutnya untuk mengetahui hipotesis beda nilai yang sama dimasing -masing kelas mendapatkan hasil dari uji Wilcoxon di mana untuk nilai pretest dan posttest di kelas kontrol mendapatkan hasil bahwa ada perbedaan nilai pretest dan posttest kelas kontrol s etelah menggunakan media pembelajara secara konvensional terhadap hasil belajar siswa kelas10 DKV SMK Negeri 10 Malang pada mata pelajaran informatika. Lalu untuk nilai pretest dan posttest di kelas eksperimen mendapatkan hasil bahwa ada perbedaan nilai pretest dan posttest kelas Eksperimen setelah menggunakan media pembelajaran interaktif Quizizz terhadap hasil belajar siswa kelas DKV 10 SMK Negeri 10 Malang pada mata pelajaran informatika. Setelah dilakukan pengujian didapati rata -rata untuk nilai prete st kelas kontrol yaitu 66,67 dan untuk posttest kelas kontrol yaitu 82,33. Untuk rata -rata nilai pretest kelas eksperimen yaitu 62,67 dan untuk posttest kelas eksperimen yaitu 91,67. Didapati untuk jarak nilai pretest dan posttest kelas kontrol yaitu 15,66 dan untuk jarak nilai pretest dan posttest kelas eksperimen yaitu 29. Dari hasil tersebut didapati nilai pretest dan posttest kelas ekperimen memiliki jarak yang tinggi dari jarak nilai pretest dan posttest kelas kontrol sebesar 13,34 Hasil penelitian ini menunjukkan bahwa pengaruh penggunaan media pembelajaran interaktif Quizizz terhadap hasil belajar siswa kelas 10 program keahlian DKV SMK Negeri 10 Malang lebih baik dalam meningkatkan hasil belajar siswa dari pada dengan pendekatan pembelajaran konvensi onal. Hasil belajar pada kelas eksperimen juga lebih baik dari pada hasil belajar kelas kontrol, sehingga dapat dikatakan media pembelajaran interaktif Quizizz dalam pembelajaran informatika dapat meningkatkan hasil belajar siswa. 4.2.3 Pengujian N -Gain Kemudian setelah mengetahui adanya perbedaan hasil belaja yang diperoleh oleh siswa dari kedua kelas penelitian, maka dilanjutkan untuk menghitung Gain Effect menggunakan persamaan Uji N -Gain yang mana pengujian ini digunakan untuk 1182 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1177 -1184 mengetahui arah perbeda an hasil belajar yang didapatkan oleh siswa bisa dikatakan efektif atau tidak terhadap masing -masing kelas penelitian. Didapatkan hasil pengujian dari kelas eksperimen sebesar 79 dinyatakan efektif dan hasil pengujian dari kelas kontrol sebesar 36 diny atakan tidak efektif. Berdasarkan hasil penelitian di atas, penggunaan media pembelajaran interaktif Quizizz sangat tepat dan efektif digunakan dalam kegiatan pembelajaran di kelas sehingga sesuai dan bisa dijadikan solusi dari permasalahan yang timbul pada siswa. Siswa banyak sekali yang tidak memahami langsung materi apa yang sedang dikerjakan. Karena pengerjaan secara kelompok siswa akhirnya membagi pengerjaan soal secara bergantian di mana siswa tidak memahami materi secara menyeluruh yang be rdampak Ketika melakukan pengerjaan soal secara individu. Hal tersebut dirasakan oleh siswa di kelas kontrol yang mendapatkan hasil score tidak efektif. Hal ini pun sejalan dengan penelitian yang dilakukan oleh Issrina Dwika Hidayati tentang Efektivi tas Media Pembelajaran Aplikasi Quizizz Secara Daring Terhadap Perkembangan Kognitif Siswa yang mendapatkan hasil n -gain score menyatakan nilai mean kelas eksperimen sejumlah 56,3363 atau 56 yang termasuk dalam kategori cukup efektif. Untuk n -gain score nilai mean kelas kontrol berjumlah 42,3541 atau 42 yang berarti kurang efektif. Dengan adanya hasil tersebut dapat disimpulkan bahwa media pembelajaran aplikasi Quizizz secara daring cukup efektif dipergunakan untuk perkembangan kognitif siswa dalam ma ta pelajaran Bahasa Indonesia kelas 3. 4.2.4 Hasil Pembahasan Dari hasil pengujian yang telah dilakukan oleh peneliti didapati rata -rata untuk nilai pretest kelas kontrol yaitu 66,67 dan untuk posttest kelas kontrol yaitu 82,33. Untuk rata -rata nilai pretest kelas eksperimen yaitu 62,67 dan untuk posttest kelas eksperimen yaitu 91,67. Didapati untuk jarak nilai pretest dan posttest kelas kontrol yaitu 15,66 d an untuk jarak nilai pretest dan posttest kelas eksperimen yaitu 29. Dari hasil tersebut didapati nilai pretest dan posttest kelas ekperimen memiliki jarak yang tinggi dari jarak nilai pretest dan posttest kelas kontrol sebesar 13,34 Hasil penelitian ini m enunjukkan bahwa pengaruh penggunaan media pembelajaran interaktif Quizizz terhadap hasil belajar siswa kelas 10 program keahlian DKV SMK Negeri 10 Malang lebih baik dalam meningkatkan hasil belajar siswa dari pada dengan menggunakan media pembelajaran konvensional. Hasil belajar pada kelas eksperimen juga lebih baik dari pada hasil belajar kelas kontrol, sehingga dapat dikatakan media pembelajaran interaktif Quizizz dalam pembelajaran informatika dapat meningkatkan hasil belajar siswa. Hal ini pun sejalan dengan penelitian serupa yang telah dilakukan oleh penulis lain Solikah, di mana didapatkan hasil bahwa ada pengaruh terhadap penggunaan media interaktif Quizizz terhadap hasil belajar siswa pada materi teks persuasif kelas VIII di SMPN 5 Sidoarjo t ahun pelajaran 2019 2020. Nilai rata -rata hasil belajar siswa sebelum diberikan perlakuan diperoleh nilai thitung sebesar 1,97, dan setelah diberikan perlakuan diperoleh nilai thitung sebesar 4,04. Hasil analisis data yang mengacu pada db 50, t0 5, menunj ukkan adanya perbedaan signifikan pada motivasi dan hasil belajar pada siswa kelas eksperimen dan kontrol, sehingga dapat disimpulkan bahwa terdapat pengaruh positif penggunaan media interaktif Quizizz terhadap hasil belajar siswa pada materi teks persuasi f. Dari penelitian yang dilakukan oleh Issrina Dwika Hidayati tentang Efektivitas Media Pembelajaran Aplikasi Quizizz Secara Daring Terhadap Perkembangan Kognitif Siswa yang mendapatkan hasil n -gain score menyatakan nilai mean kelas eksperimen sejum lah 56,3363 atau 56 yang termasuk dalam kategori cukup efektif. Untuk n -gain score nilai mean kelas kontrol berjumlah 42,3541 atau 42 yang berarti kurang efektif. Dengan adanya hasil tersebut dapat disimpulkan bahwa media pembelajaran aplikasi Quizizz secara daring cukup efektif dipergunakan untuk perkembangan kognitif siswa dalam mata pelajaran Bahasa Indonesia kelas 3. Penulis juga melakukan pengujian efektivitas dari N -gain score didapatkan hasil pengujian dari kelas eksperimen sebesar 79 dinyatakan efektif dan hasil pengujian dari kelas kontrol sebesar 36 dinyatakan tidak efektif. Berdasarkan hasil penelitian di atas, penggunaan media pembelajaran interaktif Quizizz sangat tepat dan efektif digunakan dalam kegiatan pembelajaran di kelas sehingga sesuai dan bisa dijadikan solusi dari permasalahan yang timbul pada siswa. siswa banyak sekali yang tidak memahami langsung materi apa yang sedang dikerjakan. Karena pengerjaan secara kelompok siswa akhirnya membagi pengerjaan soal secara bergantian di mana siswa tidak memahami materi secara menyeluruh yang berdampak ketika melakukan pengerjaan soal secara individu. Hal tersebut dirasak an oleh siswa di kelas kontrol yang mendapatkan hasil score tidak efektif.', 'ID+8117.pdf': '1. PENDAHULUAN Penyakit Alzheimer adalah penyakit gangguan otak yang umumnya mempengaruhi orang di atas 65 tahun. Penyakit ini pertama kali didefinisikan oleh Alois Alzheimer pada tahun 1906 di Kongres Psyatrist Jerman Selatan ke -37. Dalam kongres tersebut, Alzheimer mengungkapkan penemuannya tentang unusual disease of the cerebral cortex yang mengindikasikan adanya sebuah penyakit aneh pada seorang pasien bernama Auguste D. Penyakit ini menyebabkan gejala kehilangan ingatan, disorientasi, dan halusinasi hingga kematian pasien Jumlah penderita penyakit Alzheimer d i seluruh dunia meningkat dengan cepat. Hal ini dibuktikan dengan adanya 55 juta orang yang didiagnosis dengan demensia pada tahun 2020. Diprediksi, angka ini akan terus bertambah dari tahun ke tahun hingga menyentuh 78 juta pada tahun 2030 dan 139 juta p ada tahun 2050. Di Indonesia, diperkirakan ada sekitar 1224 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm. 1223 -1232 1,2 juta orang dengan demensia pada tahun 2016, yang akan meningkat menjadi 2 juta orang pada tahun 2030 dan 4 juta orang pada tahun 2050. Estimasi total kerugian ekonomi yang disebabkan oleh demensia pada tahun 2015 menyentuh US 818 juta dan diperkirakan akan meningkat menjadi US 2,8 triliun pada tahun 2030. Oleh karena banyaknya dampak yang disebabkan oleh penyakit ini, maka diperlukan pendekatan medis secara tradisional atau -pun modern. Sejarah pendekatan medis secara tradisional terus berkembang seiring berjalannya waktu. Pada awalnya, melalui pengetahuan yang terbatas, fokus utama praktisi medis adalah meredakan gejala kehilangan ingatan dan disorien tasi melalui obat - obatan dengan harapan untuk memperlambat perkembangan penyakit dan meningkatkan kualitas hidup pasien. Perkembangan pendekatan medis lebih lanjut dapat dilihat pada penemuan dan penelitian mengenai hasil pemindai an otak melalui MRI yang dapat memberikan penglihatan mendalam terhadap perubahan struktural otak. Melalui hasil pemindaian MRI, praktisi medis dapat menganalisis, mengidentifikasi dan mendiagnosis pasien agar mendapatkan perawatan yang sesuai. Namun, seringkali terjadi ketidakakuratan dalam penilaian praktisi medis yang menyebabkan keterlambatan diagnosis pasien sehingga gejala penyakit Alzheimer semakin memburuk. Pendekatan medis secara modern dapat diwujudkan dengan adanya perkemb angan teknologi informasi dan kecerdasan buatan. Perkembangan teknologi ini memungkinkan machine learning untuk digunakan pada hasil pemindaian otak menggunakan MRI. Dengan machine learning, komputer dapat mempelajari pola -pola kompleks yang sebelumnya sulit untuk dipelajari oleh manusia. Melalui pendekatan ini, pendeteksian penyakit Alzheimer akan lebih akurat dan memberikan kesempatan bagi pasien untuk mendapatkan perawatan yang lebih baik. Meskipun machine learning telah membantu prakt isi medis mendeteksi penyakit Alzheimer, terdapat banyak metode machine learning yang tersedia. Setiap metode tersebut akan memiliki kemampuan yang berbeda -beda. Seperti yang disebutkan oleh teorema No Free lunch, jika semua algoritma optimisasi dirata -ratakan pada semua masalah, maka semua algoritma akan memiliki kemampuan yang sama. Hal ini menunjukan bahwa, seberapa efektif suatu algoritma bergantung dengan situasinya. Oleh karena itu, perlu penelitian lebih lanjut mengenai hal ini. Salah satu metode machine learning yang dapat digunakan dalam sebuah klasifikasi adalah Convolutional Neural Network (CNN). CNN adalah sebuah jenis jaringan saraf tiruan yang menggunakan beberapa lapisan konvolusi untuk memproses inform asi berdasarkan pola -pola inputnya. Algoritma CNN ini menjadi dasar bagi beberapa algoritma lainnya, seperti AlexN et, VGG, dan ResNet. Seiring berjalannya waktu, algoritma ResNet yang menggunakan konsep CNN juga menjadi dasar dari algoritma ConvNext. Algoritma ConvNext memiliki akurasi yang tinggi dan layak untuk dijadikan sebagai sebuah metode da lam kasus penelitian. Penelitian ini akan mengoptimalkan model ConvNeXt melalui transfer learning dari ImageNet dan fine -tuning pada data MRI otak, dengan tujuan untuk menghasilkan model klasifikasi yang lebih akurat untuk empat tingkatan keparahan penyaki t Alzheimer. Model h5 sebagai hasil penelitian ini diharapkan dapat membuka jalan bagi pengembangan sistem pendukung keputusan yang dapat digunakan oleh praktisi medis dalam diagnosis lebih dini dan penanganan yang lebih efektif terhadap penyakit ini. 2. METODE PENELITIAN Penelitian ini dilaksanakan dengan pendekatan metodologi yang sistematis untuk melatih dan mengevaluasi model arsitektur ConvNeXt. Penelitian akan diawali dengan persiapan dataset, pelatihan model, dan evaluasi model. Diagram alur penelit ian dapat terlihat pada gambar 1. Gambar 1 Diagram Alur Penelitian 2.1. Persiapan Dataset Dataset yang digunakan pada penelitian Klasifikasi Penyakit Alzheimer dari Scan MRI Otak Menggunakan ConvNeXt adalah Alzheimer s Dataset (4 class of images). Dataset ini diunduh dari https www.kaggle.com datasets tourist55 alzheime rs-dataset -4-class -of-images dengan lisensi dari Alzheimer s Disease Neuroimaging I nitiative (ADNI). Dataset ini adalah dataset dengan gambar dari scan MRI otak manusia yang memiliki empat klasifikasi tingkat penyakit Alzheimer, yaitu Mild Demented, Moderate Demented, Non Demented, dan Very Mild Demented. Austin, dkk, Klasifikasi Penyakit Alzheimer 1225 Dataset ini memiliki 6400 gambar yang dipisah menjadi empat folder klasifikasi. yaitu 3200 gambar Non Demented, 2240 gambar Very Mild Demented, 896 gambar Mild Demented, dan 64 gambar Moderate Demented. Sampel gambar dari keempat kelas alzheimer ini dapat dilihat pada gambar 2 sampai 5. Pembagian dataset ini dilakukan dengan rasio 60 20 20 untuk data latih (training), data evaluasi (validation), dan data uji (test). Berdasarkan jumlah rasio tersebut, maka jumlah gambar untuk masing -masing data adalah 3840 gambar data latih, 1289 gambar da ta evaluasi, dan 1280 gambar data uji. Dataset juga akan dimasukkan ke dalam sebuah image data generator yang akan memproses gambar serta melakukan augmentasi agar model dapat belajar lebih efektif. Augmentasi yang akan dilakukan meliputi rotasi 90 derajat, flip kiri-kanan dan atas - bawah, penyesuaian kecerahan, serta kontras. Langkah -langkah ini diharapkan dapat membantu meningkatkan performa model dengan memperkaya variasi data yang tersedia. Gambar 2 Non Demented Gambar 3 Very Mild Demented Gambar 4 Mild Demented Gambar 5 Moderate Demented 2.2. Pelatihan Model dan Fine Tuning Gambar 6 Model ConvNeXt dengan Fine Tuning Setelah persiapan dataset seles ai, model ConvNeXt pada gambar 6 akan diinisiasi untuk dilatih dengan dataset tersebut. Model akan diinisiasi dengan bantuan tensorflow keras yang menggunakan base mode l ConvNeXt dengan bobot dari imagenet, pengaturan gambar dengan ukuran 300x300 dan max pooling. Layer base model ini akan ditambahkan dengan layer dense class_count dengan fungsi aktivasi softmax. Model juga akan menggunakan Adam optimizer dengan hyperparamater learning rate yang ditentukan untuk mengurangi error saat proses pelatihan. Selain inisiasi model, fungsi callback juga akan dibuat dengan hyperparameter batch size sebagai jumlah ukuran kelompok data untuk proses pelatihan, hyperparameter epoch sebagai satuan masuknya dataset ke dalam model, hyperparameter patience sebagai ambang batas epoch untuk menentukan learning rate, hyperparameter stop patience sebagai ambang batas epoch untuk memberhentikan proses pelatihan, hyperparameter threshold sebagai ambang batas akurasi, hyperparameter factor sebagai angka yang digunakan untuk mengurangi l earning rate, hyperparameter ask epoch sebagai ambang batas epoch penentu d iberhentikan nya proses pelatihan, serta hyperparameter batch size sebagai jumlah batch yang dilakukan selama proses pelatihan untuk setiap epoch. Model yang sudah diinisiasi akan dilatih dengan hyperparameter x sebagai data latih, parameter epoch sebagai satuan masuknya dataset kedalam model, hyperparameter verbose sebagai penanda dicetaknya proses pelatihan tiap iterasi, hyperparameter callbacks sebagai fungsi tambahan yang akan dijalankan selama proses pelatihan, hyperparameter validation_data sebagai da ta validasi, hyperparameter validation_steps sebagai jumlah langkah validasi yang dilakukan, dan hyperparameter shuffle sebagai penanda diacaknya data pelatihan untuk setiap epoch -nya. Hyperparamater Nilai Learning rate 0.0001 Batch Size 10 Batches 513 Epoch 30 Ask Epoch 10 Patience 1 Stop Patience 5 Threshold 0.9 Factor 0.5 2.3. Evaluasi Model Proses evaluasi yang digunakan dalam penelitian ini akan menggunakan nilai True Positive (TP), True Negativ e (TN), False Positive (FP), dan False Negative (FN) yang didapatkan dari Confusion Matrix. Confusion Matrix adalah sebuah matriks performa model yang menunjukkan jumlah data aktual yang diprediksi benar dan jumlah data aktual yang diprediksi salah untuk setiap ke lasnya. TP adalah jumlah data aktual positif yang diprediksi positif oleh model, sedangkan TN adalah jumlah data 1226 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm. 1223 -1232 aktual negatif yang diprediksi negatif oleh model. FP adalah jumlah data aktual negatif yang diprediksi positif oleh model, sedangkan FN adalah jumlah data aktual positif yang diprediksi negatif oleh model. Keempat nilai ini akan digunakan untuk menghitung nilai Precision, Recall, F1-Score dan Accuracy dari model melalui rumus pada persamaan 1 sampai 4. Precision TP TP FP Persam aan 1 Rumus Precision Recall TP TP FN Persamaan 2 Rumus Recall F1 Score 2 Precision Recall Precision Recall Persamaan 3 Rumus F1 Score Accuracy TP TN TP FP TN FN Persamaan 4 Rumus Accuracy Nilai Precision adalah nilai yang mengukur proporsi TP dari semua kasus yang diprediksi positif, sedangkan nilai Recall adalah nilai yang mengukur proporsi TP dari semua kasus aktual positif. Selain itu, model akan memiliki nila i F1 Score sebagai nilai yang mengukur harmoni diantara Precision dan Recall. Model juga akan memiliki nilai accuracy sebagai nilai jumlah prediksi benar model dari seluruh prediksi model. 2.4. Perangkat Lunak dan Perangkat Keras Bahasa pemrograman yang di gunakan dalam penelitian ini adalah bahasa pemrograman python. Penelitian ini juga akan menggunakan library os, time, itertools, numpy, pandas, matplotlib, sklearn, dan tensorflow. Library os digunakan untuk mengakses direktori fail dataset. Selanjutnya, library time digunakan untuk menghitung waktu proses pelatihan model. Selain itu, library itertools digunakan untuk membantu proses iterasi data. Library numpy, pandas, matplotlib, dan sklearn juga akan digunakan dalam proses perhitungan evaluasi dari model yang sudah dilatih. Terakhir, library tensorflow akan digunakan untuk proses pembuatan, pelatihan, dan evaluasi model. Proses penelitian akan dijalankan dengan menggunakan layanan komputasi awan dari Kaggle. Layanan ini memiliki kapasitas memori sebesar 73.1GB. Layanan ini juga akan menggunakan akselerasi GPU P100 yang memiliki RAM CPU sebesar 13GB dan memori GPU sebesar 15.9GB. Dengan menggunakan layanan dan perangkat keras tersebut, proses pelatihan dan validasi model terjadi selama 2 jam, 7 menit, dan 41.48 detik. 3. TINJAUAN PUSTAKA 3.1. Klasifikasi Alzheimer Pemilihan metode klasifikasi dengan machine learning memiliki peranan penting dalam menangani permasalahan keterlambatan deteksi tingkat keparahan Alzheimer. Data dan metode klasifikasi yang tepat akan membantu praktisi medis mengidentifikasi pola -pola khas dari penyakit Alzheimer. Metode klasifikasi ini da pat digunakan terhadap data MRI, data Neuropsikologis, dan data Genetik. 3.1.1. Klasifikasi berdasarkan Data MRI Data MRI (Magnetic Resonance Imaging) merupakan data yang paling umum yang digunakan dalam klasifikasi Alzheimer. Convolutional Neural Network s (CNN) adalah salah satu varian jaringan saraf tiruan yang sesuai untuk analisis citra medis seperti MRI otak. Hal ini berkaitan dengan cara CNN beroperasi, yakni cara yang menyerupai kemampuan manusia dalam mengenali pola dalam citra, melalui konvolusi p ada citra masukan dengan menggunakan filter kecil yang bergeser secara bertahap melintasi citra. Proses ini memungkinkan CNN untuk mengekstrak fitur -fitur yang penting dalam konteks klasifikasi. Langkah awal dalam proses klasifikasi ini melibatkan pengguna an gambar MRI otak sebagai data masukan. Gambar ini kemudian mengalami tahap pra -pemrosesan. Tahapan pra -pemrosesan mencakup normalisasi intensitas, pemangkasan, serta pengurangan noise. Gambar - gambar yang telah melalui tahap pra -pemrosesan berikutnya digunakan untuk melatih model CNN. Model ini terdiri dari beberapa lapisan konvolusi, lapisan penggabungan (pooling) untuk mengurangi dimensi gambar, dan lapisan -lapisan sepenuhnya terhubung untuk membuat keputusan. Selama proses pelat ihan, CNN mempelajari untuk mengenali ciri -ciri patologis atau perubahan struktural yang terkait dengan Alzheimer pada gambar MRI tersebut. Proses pembelajaran ini melibatkan penyesuaian bobot -bobot jaringan untuk meminimalkan kesalahan dalam klasifikasi t erhadap data pelatihan. CNN mengenali pola -pola seperti plak amyloid, atrofi otak, atau perubahan volume pada wilayah tertentu yang berhubungan dengan Alzheimer. Setelah model CNN dilatih dengan cukup baik, model tersebut dapat digunakan untuk menganalisis gambar MRI otak yang belum pernah dilihat sebelumnya. Proses ini melibatkan pengambilan gambar masukan, dan model CNN akan menghasilkan output yang mengindikasikan apakah gambar tersebut menampilkan tanda -tanda penyakit Alzheimer. Hasil ini dapat berguna untuk diagnosis dini atau peningkatan evaluasi kesehatan pada pasien. 3.1.2. Klasifikasi berdasarkan Data Neuropsikologis Klasifikasi Alzheimer berdasarkan data neuropsikologi dengan memanfaatkan algoritma Austin, dkk, Klasifikasi Penyakit Alzheimer 1227 Machine Learning seperti Random Forest adalah pend ekatan yang efektif dalam mengidentifikasi potensi risiko Alzheimer. Random Forest adalah algoritma Machine Learning yang terbukti efektif dalam mengklasifikasikan data yang kompleks, termasuk data neuropsikologi. Cara kerja algoritma ini melibatkan pembag ian data menjadi sejumlah pohon keputusan atau decision tree. Setiap pohon dibuat dengan metode bootstrapping, yang mengambil sampel acak dari data pelatihan dengan penggantian. Selanjutnya, algoritma ini memilih subset acak dari fitur -fitur yang tersedia di setiap node keputusan dalam masing - masing pohon. Ketika data tes neuropsikologi baru diperkenalkan sebagai input ke model Random Forest, model ini akan memproses data melalui setiap pohon keputusan secara terpisah. Setiap pohon memberikan prediksi kelas yang berbeda. Hasil dari seluruh pohon keputusan digabungkan, dan kelas dengan dukungan mayoritas akan menjadi hasil prediksi akhir dari model. Langkah awal dalam prosedur ini melibatkan pengumpulan data dari tes neuropsiko logi, yang melibatkan berbagai jenis tes kognitif, seperti tes kecerdasan, tes memori, serta evaluasi kemampuan bahasa dan fungsi kognitif lainnya. Data ini umumnya mencakup hasil skor tes dari individu yang telah menjalani tes tersebut. Setelah data neuro psikologi terkumpul, langkah berikutnya adalah tahap pra -pemrosesan data. Pra -pemrosesan melibatkan normalisasi data untuk mengatasi potensi bias atau ketidaksetaraan dalam rentang hasil tes. Data yang telah melalui pra -pemrosesan kemudian digunakan sebaga i input dalam model machine learning berbasis Random Forest. Selama proses pelatihan, Random Forest belajar untuk mengenali pola dan korelasi yang terdapat dalam data neuropsikologi yang berkaitan dengan risiko Alzheimer. Dengan demikian, algoritma ini dap at memberikan prediksi yang akurat terkait dengan apakah individu tersebut memiliki risiko terkena Alzheimer atau tidak. 3.1.2. Klasifikasi berdasarkan Data Genetik Klasifikasi berdasarkan data genetik dengan memanfaatkan algoritma Machine Learning Support Vector Machines (SVM) adalah pendekatan yang juga umum digunakan. Langkah awal dalam proses ini adalah pengumpulan data genetik, yang mungkin termasuk Single Nucleotide Polymorphism (SNP) dan variasi genetik lainnya yang telah diidentifikasi sebagai poten si penyebab Alzheimer. Setelah data genetik terkumpul, langkah selanjutnya adalah pra -pemrosesan data genetik. Pra -pemrosesan ini mencakup normalisasi data untuk memastikan bahwa berbagai variabel genetik memiliki tingkat kont ribusi yang setara dalam analisis klasifikasi. Data yang telah di -preproses ini kemudian digunakan sebagai input dalam model Machine Learning berbasis SVM. SVM adalah algoritma Machine Learning yang unggul dalam memisahkan kelas pada data yang kompleks sep erti data genetik. Cara kerja algoritma SVM melibatkan penciptaan hyperplane yang memisahkan dua kelas dengan jarak maksimal antara mereka. Hyperplane ini dipilih untuk memaksimalkan margin antara dua kelas, yang menghasilkan predik si yang sangat akurat. Selama proses pelatihan, SVM belajar untuk mengidentifikasi pola genetik yang berkorelasi dengan risiko Alzheimer. Ini melibatkan penyesuaian parameter SVM agar hyperplane yang digunakan dapat secara efektif memisahkan kelas yang mew akili individu yang berisiko tinggi dan individu yang berisiko rendah terhadap Alzheimer berdasarkan data genetik mereka. Ketika data genetik individu baru diperkenalkan sebagai input ke model SVM yang telah dilatih, algoritma ini akan menjalankan data melalui hyperplane yang telah dihasilkan selama pelatihan. SVM kemudian memberikan prediksi tentang apakah individu tersebut memiliki faktor risiko genetik yang tinggi atau rendah terhadap Alzheimer. Proses ini memungkinkan peneliti untuk mengidentifikasi fak tor risiko genetik secara lebih akurat dan memahami hubungan antara polimorfisme genetik tertentu dengan perkembangan Alzheimer. 3.2. Convolutional Neural Network (CNN) Convolutional Neural Network (CNN) adalah suatu metode algoritma machine learning yang terinspirasi oleh struktur dan fungsi otak manusia. CNN terdiri atas tiga bagian utama, yaitu convolution layer, pooling layer, dan, fully connected layer. Lapisan konvolusi merupakan bagian yang mengidentifikasi pola pada input dengan menggunakan filter. Lapisan pooling berfungsi untuk mengurangi dimensi spasial dari fitur dengan down - sampling. Terakhir, yaitu lapisan f ully connected adalah lapisan yang digunakan untuk menyambungkan setiap saraf dari lapisan sebelumnya ke lapisan saat ini. Contoh penelitian dengan implementasi metode CNN yaitu Implementasi Metode CNN untuk Klasifikasi Gambar Jamur Pada Analisis Pengolahan Gambar, penggunaan CNN untuk mengklasifikasikan gambar jamur Agaricus dan Amanita dilakukan dalam dua tahap u tama, yaitu pembelajaran karakteristik yang terdiri dari 2 tahap konvolusi dan 2 tahap pooling.. Kemudian, dilanjutkan dengan tahan klasifikasi dimana arsitektur terbaik didapatkan dengan membandingkan beberapa parameter yakni epoch dan optimizer. Diperol eh perbandingan akurasi dari 3 jenis optimizer yaitu 62 untuk optimizer Adam dengan epoch 100, 54 untuk optimizer RMSProp dengan epoch 50, dan 55 untuk optimizer SGD dengan epoch 50. Hasil akurasi yang diperoleh untuk mengklasifikasikan gambar jamur men ggunakan CNN yakni sebesar 62 dengan menggunakan skenario perbandingan data 1228 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm. 1223 -1232 train validation 80 20, ukuran kernel 3x3, optimizer Adam, 100 epoch, dan learning rate sebesar 0,001. Implementasi Convolutional Neural Network (CNN) Untuk Klasifikasi Batik Tanah Liat Sumatera Barat, Metode neural network convolutional berhasil digunakan untuk mengklasifikasikan gambar batik tanah liat Sumatera Barat. Metode ini menggunakan library keras dan tensorflow dengan bahasa pemrograman phyton. Pada hasil pelatihan data train didapat akurasi sebesar 98.75, sedangkan tahap pelatihan data uji didapat akurasi sebesar 62.5. Tingkat akurasi ini cukup baik, dan sudah layak digunakan sebagai referensi unt uk membangun aplikasi yang nyata untuk mengidentifikasi motif batik atau objek lainnya secara umum. Kemiripan warna, kemiripan motif, ukuran jarak pengambilan gambar, kualitas cahaya, dan posisi gambar menyebabkan beberapa gambar diklasifikasikan kurang te pat karena hampir setiap daerah di Indonesia memiliki motif batik daerahnya sendiri. Klasifikasi Tutupan Lahan Melalui Citra Satelit SPOT -6 dengan Metode Convolutional Neural Network (CNN), Dalam penelitian ini, sebuah sistem telah dirancang untuk mengka tegorikan lima jenis tutupan lahan hutan, bukit gundul, sawah, pemukiman, dan sungai. Data primer, yang dikumpulkan melalui satelit SPOT 6, digunakan sebagai data uji. Sebanyak 350 gambar tutupan lahan, atau data latih dan data uji, digunakan sebagai data uji dalam penelitian ini. Model CNN yang diusulkan untuk penelitian ini terdiri dari 3 hidden layer, 1 fully connected layer, sebuah filter ukuran 3x3 dengan output channel secara berurutan 8,16 dan 32, serta aktivasi softmax. Berdasarkan hasil pengujian sistem yang telah dilakukan, model CNN yang diusung oleh peneliti mampu untuk mengklasifikasikan 5 kelas tutupan lahan dengan performansi terbaik yang dihasilkan yaitu akurasi 95.45, loss 0.2457, precision 0.92, recall 0.92 dan f-1 score 0.92. 3.3. ConvNeXt Salah satu model CNN untuk melakukan klasifikasi adalah ConvNeXt. ConvNeXt adalah model ConvNet dengan dasar arsitektur ResNet yang mengalami modernisasi dengan konsep hierarchical vision transformer (Sw in) (Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, 20 21). ResNet akan dilatih dengan teknik yang sama seperti vision transformer dengan AdamW Optimizer, Epochs, Heavy Data Augmentation, dan Regulation. Pada gambar 7 dapat terlihat bahwa macro design model dimodifikasi dengan stage ratio yang menyes uaikan jum lah blok pada setiap stage untuk meningkatkan akurasi dan patchify stem yang membuat sliding windows bersifat seperti vision transformer. Konsep depth conv dan width milik ResNeXt akan digunakan untuk meningkatkan akurasi dari model. Selain itu, akurasi model akan ditingkatkan dengan inverted bottleneck serta mengubah ukuran kernel yang digunakan. ConvNeXt juga akan menggunakan micro design model yang dimodifikasi melalui Rectified Linear Unit (ReLU) yang diganti dengan Gaussian Linear Unit (GeLU), penggu naan fungsi aktivasi yang lebih jarang, penggunaan lapisan normalisasi yang lebih sedikit dan batch normalization yang diganti dengan layer normalization. Gambar 7 Desain ConvNeXt Arsitektur Conv NeXt yang terlihat pada gambar 8 terdiri dari Conv2d, 4 stage, global average pooling, dan linear. Stage 1 terdiri dari ConvNeXt Block sedangkan stage 2 sampai 4 terdiri dari Downsample dan ConvNeXt Block. ConvNeXt Block terdiri dari Depthwise Conv2d, 2 Conv2d, Layer Scale dan DropPath. Di sisi lain, Downsample terdiri dari Conv2d. Contoh penelitian studi kasus dengan ConvNeXt yaitu penelitian untuk klasifikasi Fine- Grained dalam jurnal ConvNeXt -Based Fine - Grained Image Classification and Bilinear Attention Mechanism Model. Penelitian ini dilakukan menggunakan tiga dataset klasifikasi Fine-Grained yang diakui secara internasional, yaitu CUB200 - 2011, FGVC -Aircraft, dan Stanford Cars. Hasil dari studi ini menunjukkan bahwa model ConvNeXt dapat berhasil digunakan dalam tugas kl asifikasi Fine- Grained dan memberikan hasil yang lebih baik dibandingkan dengan jaringan klasifikasi tradisional. Austin, dkk, Klasifikasi Penyakit Alzheimer 1229 Gambar 8 Arsitektur ConvNeXt Contoh lain penelitian studi kasus lainnya dilakukan oleh Zhang et al. Dalam penelitian ini, mereka mengusulkan sebuah model deteksi objek berbasis ConvNeXt yang disebut AFCNet. Tujuan dari penelitian ini adalah untuk meningkatkan kinerja deteksi objek dengan mengatasi keterbatasan detektor berbasis anchor. Dari penelitia n tersebut dapat disimpulkan bahwa AFCNet, yang merupakan model deteksi objek berbasis ConvNeXt, berhasil meningkatkan kinerja deteksi objek pada dataset IIOPE dan PASCAL VOC 2007. AFCNet mengungguli detektor -detektor lain seperti Faster R - CNN, RetinaNet, FCOS, ATSS, dan TOOD dengan perbedaan masing -masing sebesar 10,6, 15.8, 22.3, 15.6, dan 16.4. Dengan demikian, studi ini menunjukkan bahwa model deteksi objek berbasis ConvNeXt seperti AFCNet memiliki potensi dalam meningkatkan kinerja deteksi objek. Dengan memanfaatkan keunggulan ConvNeXt dan menggabungkannya dengan peningkatan - peningkatan lainnya, AFCNet berhasil mencapai hasil yang lebih baik dalam mendeteksi objek, baik pada dataset gambar inframerah maupun dataset umum. 4. HASIL DAN DISKUSI Hasil pelatihan dan validasi model akan memiliki grafik training validation loss, training validation accuracy, training validation recall, training validation precision, dan training validation f1-score. Grafik training validation loss adalah grafik yang menunjukkan tingkat error pada model saat melakukan proses pelatihan dan validasi pada setiap epoch -nya, sedangkan grafik training validation accuracy adalah grafik yang menunjukkan tingkat akurasi model saat melakukan proses pelatihan d an validasi pada setiap epochnya. Grafik training validation recall adalah grafik yang menunjukkan nilai recall model saat melakukan proses pelatihan dan validasi pada setiap epochnya, sedangkan grafik training validation precision adalah grafik yang menun jukkan nilai presisi model saat melakukan proses pelatihan dan validasi pada setiap epochnya. Grafik training validation f1 -score adalah grafik yang menunjukkan nilai f1 model saat melakukan proses pelatihan dan validasi pada setiap epoch -nya. Gambar 9 Hasil loss pelatihan dan validasi model Berdasarkan grafik training and validation loss pada gambar 9, dapat dilihat bahwa hasil error proses pelatihan dan validasi model mengalami penurunan. Hal ini menunjukkan bahwa model berhasil mengalami peningkatan proses pembelajaran saat proses pelatihan dan validasi. Epoch terbaik model saat melakukan proses validasi adalah epoch 30 dengan error sebesar 0. 1120. Gambar 10 Hasil akurasi pelatihan dan validasi model Selanjutnya berdasarkan grafik training and validation accuracy pada gambar 10, dapat dilihat bahwa hasil akurasi proses pelatihan dan validasi mengalami peningkatan yang signifikan. Hal ini menunjukkan bahwa model memiliki akurasi yang tinggi saat proses pelatihan dan validasi. Epoch terbaik model saat melakukan proses validasi adalah epoch 24 dengan akurasi sebesar 0.9 649. 1230 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm. 1223 -1232 Gambar 11 Hasil recall pelatihan dan validasi model Gambar 12 Hasil precision pelatihan dan validasi model Gambar 1 3 Hasil f1 -score pelatihan dan validasi model Selain itu berdasarkan grafik training and validation recall, precision, dan f1 pada gambar 11 sampai 1 3, dapat dilihat bahwa ketiga nilai tersebut mengalami peningkatan pada proses pelatihan dan validasi. Hal ini menunjukkan bahwa model memiliki nilai rec all, precision, dan f1 yang tinggi saat proses pelatihan dan validasi. Recall terbaik model saat proses validasi didapatkan saat epoch ke 24 dengan nilai 0.9 643, sedangkan precision terbaik model saat proses validasi didapatkan saat epoch ke 26 dengan nilai 0.9 667. Selanjutnya dapat dilihat juga bahwa nilai F1 terbaik model saat proses validasi didapatkan saat epoch ke 26 dengan nilai 0.9654. Selain grafik pelatihan dan validasi, model juga akan melakukan proses uji coba yang menghasilkan confusion matrix. Berdasarkan confusion matrix pada gambar 1 4 dapat dilihat jumlah kebenaran prediksi untuk setiap kelasnya. Kelas MildDemented mendapatkan 73 prediksi benar dan 106 prediksi salah. Kelas ModerateDemented mendapatkan 1 prediksi benar dan 11 prediksi salah. K elas NonDemented mendapatkan 506 prediksi benar dan 134 prediksi salah. Kelas VeryMildDemented mendapatkan 377 prediksi benar dan 71 prediksi salah. Gambar 14 Hasil uji coba model Melalui visualisasi confusion matrix, akan didapatkan nilai True Positi ve (TP), True Negative (TN), False Positive (FP), dan False Negative (FN). Keempat nilai ini akan digunakan untuk menghitung nilai Precision, Recall, dan F1-Score dari model untuk setiap kelas yang ada. Nilai evaluasi tersebut dapat dilihat pada tabel 2. Class P R F1 Mild Demented 0.81 0.41 0.54 Moderate Demented 1.00 0.08 0.15 Non Demented 0.83 0.79 0.81 Very Mild Demented 0.65 0.84 0.73 Proses testing juga akan menghasilkan nilai akurasi dari model yang digunakan. Nilai akurasi yang didapatkan oleh model ConvNeXt adalah 0.7 5. Perbandingan akurasi model ConvNeXt dengan model lain dapat dilihat pada tabel 3. Pada tabel tersebut dapat dilihat bahwa model ConvNeXt memiliki akurasi yang lebih baik dibandingkan dengan model lainnya. Model Accuracy ConvNeXt 0.75 EfficientNet b3 0.73 ResNet50 0.68 MobileNet 0.68 Penelitian dilanjutkan dengan membandingkan kembali model ConvNeXt yang digunakan dengan optimizer berbeda untuk mengurangi error yang terjadi saat proses pelatihan dan validasi. Optimizer yang dapat digunakan antara lain adalah Adam Optimizer, Adamax Opti mizer, dan AdamW Optimizer. Tabel perbandingan model ConvNeXt Austin, dkk, Klasifikasi Penyakit Alzheimer 1231 dengan penggunaan optimizer berbeda dapat dilihat pada tabel 4. Model Accuracy ConvNeXt (Adam) 0.79 ConvNeXt (Adamax) 0.75 ConvNeXt (AdamW) 0.79 ConvNeXt (SGD) 0.56', 'ID+8208.pdf': '1. PENDAHULUAN E-commerce adalah sebuah platform digital yang memfasilitasi transaksi jual beli secara online antara penjual dan konsumen. Tujuan dari e- commerce adalah menjual produk dalam bentuk barang fisik dan layanan digital secara online. Platform e-commerce turut menawarkan berbagai fitur dan kemudahan dalam berbelanja, seperti katalog produk dan keranjang belanja. Selain itu, platform e-commerce juga menyediakan berbagai opsi pembayaran bagi pelanggan. Berbagai f itur tambahan lainnya juga membantu pelanggan dalam menemukan, memilih, dan membeli produk atau layanan. Dalam hal struktur 1244 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm. 1243 -1252 bisnis, e-commerce mencakup beragam model pemasaran seperti pengecer online, layanan berlangganan (subscription ), pasar digital, dan entitas B2B yang mengkhususkan diri dalam menjual produk atau layanan ke bisnis lain. Agar tetap kompetitif, s trategi bisnis yang efektif diperlukan untuk memaksimalkan peluang yang ada. Mengembangkan strategi tertentu yang seperti segmentasi pasar dan alokasi sumber daya yang praktis menjadi sangat penting demi meningkatkan angka penjualan produk. Selain itu, bisnis seperti e-commerce perlu untuk memperoleh keunggulan dalam kompetisi pasar. Sebagai solusi, k ecerdasan buatan dapat dimanfaatkan dalam bidang bisnis. Kecerdasan buatan dapat memberikan rekomendasi yang dipersonalisasi untuk meningkatkan pengalaman pelanggan dalam berbelanja. Hal tersebut dapat membantu pelaku bisnis dalam mendapatkan pemahaman yang lebih dalam tentang perilaku konsumen. Melalui analisis data, kecerdasan buatan dapat membantu pelaku bisnis dalam mengidentifikasi tren aktivitas pengguna. Hal i ni juga dapat membantu dalam memperoleh wawasan tentang preferensi dan karakteristik pelanggan. Analisis dengan kecerdasan buatan menjadi penting dengan mendorong bisnis menerapkan keputusan berbasis data. Analsis data dapat membantu pengambilan keputusan yang lebih cepat dan mendapatkan wawasan tentang karakteristik pelanggan. Proses tersebut mencakup strategi data, rekayasa data, tata kelola, manaje men perubahan, dan budaya. Menurut laporan AI Built to Scale dari Accenture, 84 persen eksekutif bisnis percaya bahwa kecerdasan buatan dapat membantu mencapai tujuan pertumbuhan mereka. Namun, 76 persen mengaku membutuhkan bantuan untuk meningkatkan kecerdasan buatan di seluruh bisnis mereka. Oleh karena itu, bisnis harus melakukan inovasi untuk mengembangkan strategi yang komprehensif. Kecerdasan buatan perlu untuk dimanfaatkan dengan baik agar tetap terdepan dan kompetitif di pasar. Kecerdasan buatan diperlukan dalam mempersonalisasi kan pel anggan agar tetap kompetitif di pasar. Personalisasi tersebut dapat dilakukan dengan melakukan segmentasi terhadap pelanggan, menemukan pola -pola dengan mengelompokkan pelanggan berdasarkan perilaku berbelanja. Segmentasi pelanggan sendiri dapat diartikan sebagai proses mengklasifikasikan pelanggan dengan karakteristik serupa ke dalam segmen serupa. Penggunaan a lgoritma pengelompokan dapat membantu untuk lebih memahami karakteristik pelanggan, baik dalam hal demografi dan perilaku dinamis pel anggan. Mengingat data transaksi penjualan tidak memiliki label (kelas) data, maka algoritma unsupervised machine learning adalah algoritma yang sesuai untuk kasus tersebut. Beberapa algoritma unsupervised machine learning dapat membantu dalam menemukan titik pusat data yang terkait erat. Salah satu algoritma pengelompokan seperti K-Means dapat dimanfaatkan untuk kasus tersebut. Selain itu algoritma tersebut juga cocok digunakan untuk kasus segmentasi pelanggan. Metode ini juga dapat dikombinasikan dengan metode lain seperti Recency, Frequency, dan Monetary (RFM). Metode RFM dapat membantu mengevaluasi pelanggan berdasarkan perilaku belanja mereka. Metode ini juga dapat digunakan untuk meningkatkan analisis pelanggan dan prediksi pengalaman berbelanja. Informasi mengenai bagaimana pelanggan berbelanja dapat dikumpulkan dengan menganalisis riwayat transaksi pelanggan de ngan memanfaatkan data transaksi yang tersimpan dalam database. Dalam proses analisis, beberapa penelitian turut menerapkan kerangka kerja seperti Standard Procedure for Data Mining (CRISP -DM) untuk memastikan langkah kerja yang terstruktur. CRIS P- DM merupakan kerangka kerja data mining yang populer serta menawarkan proses yang baik dalam hal business understa nding hingga deployment. Kerangka kerja CRISP -DM juga digunakan bersamaan dengan analisis data dengan metode RFM dalam beberapa studi kasus yang berhubungan dengan penjualan. Bebe rapa penelitian diantaranya yaitu penerapan pada studi kasus workshop sepeda motor pada masa pandemi COVID -19 dalam hal mencari konsumen yang paling potensial (Mauritsius et al., 202 3), manufaktur produk kayu dalam menemukan pelanggan paling menguntungkan dan tidak menguntungkan, dan peternakan unggas (Mirantika Rijanto., 202 3). Untuk membantu e-commerce penjualan majalah dalam menemukan pola pembelian dari pelanggan, maka dilakukan penelitian yang melibatkan proses segmentasi pelanggan. Eksperimen yang dilakukan melibatkan data transaksi penjualan pada e-commerce penjualan majalah. Metode yang digunakan yaitu RFM yang dikombinasikan dengan algoritma clustering menggunakan K -Means. Algoritma K -Means dipilih ketimbang K -Means karena menawarkan proses inisialisasi awal centroid yang lebih baik dan proses konverge nsi yang lebih singkat. Metode RFM digunakan untuk membentuk fitur dalam bentuk jumlah pembelian (recency ), rasio pembelian ( frequency ), dan total pembelian ( monetary ). Fitur tersebut nantinya akan di klasterisasi dengan algoritma yang umum seperti K - Means yang merupakan bentuk pengembangan dari algoritma K -Means clustering. Proses eksperimen juga melibatkan proses menemukan nilai Manuel, dkk, Segmentasi Pelanggan Majalah 1245 k (jumlah cluster ) yang paling optim al berdasarkan silhouette score. Proses normalisasi juga diterapkan agar data yang diolah memiliki distribusi yang normal. Dalam memvisualisasikan pola data, dilakukan proses reduksi dimensi terlebih dahulu dengan Principal Component Analysis (PCA) dengan mereduksi data menjadi 2 dimensi. Hal tersebut berguna dalam mendapatkan perbandingan data secara visual sebelum dan sesudah proses klasterisasi. Hasil akhir dari eksperimen adalah pola -pola data secara recency, frequency, dan monetary, bagaimana pola untu k tiap klaster yang menggambarkan pola belanja untuk setiap pelanggan. Kerangka kerja CRISP -DM diterapkan dalam memastikan proses analisis dilakukan secara terstruktur dan runtut. 2. METOD E PENELTIAN Penelitian menggunakan metode CRISP -DM yang terdiri dari 5 langkah mulai dari business understanding hingga evaluation. Proses tersebut meliputi business understanding, data understanding, modeling, evaluation, and deployment. Namun pr oses deployment tidak dilakukan pada penelitian ini. Proses yang diterapkan pada penelitian terbatas pada evaluasi, yaitu dihasilkan cluster yang representatif untuk mensegmentai pelanggan. Selain itu pada beberapa proses CRISP -DM berisi sub -proses lain seperti preparation and evaluation data, seperti yang ditunjukkan pada gambar 1. Berikut adalah proses yang diterapkan dalam penelitian 2.1. Business Understanding Situs e-commerce penjualan majalah menyediakan berbagai produk majalah cetak dan majalah elektronik untuk segmen usia yang berbeda dengan segmen kelompok anak -anak, pria, dan wanita. Proses yang terjadi dalam e-commerce adalah serangkaian proses dari pelanggan mendaftar, memasukkan barang ke dalam keranjang, checkout, dan pembayaran hingga transaksi selesai, baik itu transaksi berhasil, kedaluarsa, atau dibatalkan. Sebagai aspek yang dapat menarik pelanggan, e- commerce melakukan promosi seperti diskon produk, bundling prod uk, bonus hadiah, dan voucher diskon. Namun, saat ini, promosi belum dilakukan sesuai target pelanggan. Hal ini diperlukan untuk merencanakan proses promosi kepada pelanggan potensial dengan tujuan tidak hanya meningkatkan pendapatan, Hal ini juga diharapk an untuk menawarkan berbagai promosi yang menarik pelanggan. 2.2. Data Understanding Data dalam e-commerce terdiri dari transaksi pelanggan terhadap e-magazine dan produk cetak. Transaksi dimulai dari 1 Maret 2021 hingga 1 Maret 2023. Data diperoleh dari databa se melalui proses kueri SQL ( Structured Query Language ) e-commerce penjualan majalah dan data tidak tersedia secara publik. Kriteria data riwayat transaksi hanya transaksi berhasil yang terdiri dari data 5.847 baris dan 11 atribut seperti tanggal transaksi, tanggal pembuatan akun, kode transaksi, email, id pengguna, merek, harga berlangganan, jumlah item, harga satuan, jenis produk, dan jenis langganan. Secara umum, data yang tersedia mewakili komponen yang diperlukan dalam metode RFM. Semua atribut ini nan tinya akan digunakan dalam proses pra pemrosesan data. 2.3. Data Preparation Data yang disimpan dalam database e- commerce belum mengalami pemrosesan seperti pada data yang disimpan di data warehouse. Bentuk data seperti tipe data, format, dan ukuran, dan mengha pus nilai null menjadi perhatian dalam proses data mining dalam data transaksi e-commerce. Dalam proses ini akan disesuaikan data dengan tipe data yang sesuai untuk diproses dengan benar. Kemudian, data rahasia akan disamarkan terlebih dahulu, seperti trans_id dan user_id. Atribut baru dibentuk dengan nama produk, yang merupakan kombinasi dari merek, durasi berlangganan, dan jenis produk (E -magazine atau cetak), seperti pada deskripsi pada tabel 1. Nama Atribut Deskripsi trans_date Tanggal transaksi acc_created_date Tanggal pembuatan akun trans_id Nomor transaksi user_id Id unik transaksi brand Merk produk product_name Nama produk dan lama langganan quantity Jumlah item transaksi sub_total Total pembayaran per produk Penelitian ini menggunakan data kategorik dan data numerik. Data kategorik seperti user_id digunakan sebagai unique identifier. Fitur lain dari himpunan data yang tidak digunakan akan dihilangkan. Untuk menghasilkan fitur baru yang dapat diproses dengan metode RFM, metode analisis 1246 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm. 1243 -1252 berdasarkan data riwayat transaksional untuk pemasaran. Recency adalah jarak antara p embelian awal dan pembelian berikutnya. Frequency adalah perhitungan berapa kali pelanggan berbelanja dalam periode yang telah ditentukan. Monetary adalah hasil perhitungan total transaksi nasabah dalam periode yang telah ditentukan. Jika pelanggan memilik i beberapa transaksi, nilai recency didasarkan pada tanggal dan frekuensi transaksi terakhir. Sedangkan monetary adalah nilai total dari keseluruhan pengeluaran. Semua fitur pertama -tama akan dinormalisasi dengan StandardScaler untuk menormalkan data sehin gga meminimalkan nilai kesalahan. Kemudian, data tersebut akan diolah dengan reduksi dimensi dengan Principal Component Analysis (PCA) menjadi data dua dimensi. 2.4. Modeling Model machine learning yang digunakan adalah proses clustering dengan menggunakan K - Means untuk mengatasi permasalahan algoritma K-Means klasik. Bentuk K -Means klasik secara acak menginisialisasi centroid awal, menghasilkan hasil pengelompokan yang berbeda yang dapat menyebabkan kesalahan atau memperlambat algoritma untuk mencapai konvergensi. Iterasi yang ditetapkan akan membatasi K - Means hingga 300 kali hingga model mencapai konvergensinya. Model optimal dihasilkan dari pemilihan parameter optimal nilai k. Untuk proses evaluasi, parameter n_in it digunakan sebagai parameter optimal ditentukan menggunakan visualisasi nilai WSS sehingga dihasilkan grafik untuk evaluasi, kemudian dengan elbow method dan perhitungan berdasarkan silhouette score terbaik. Algoritma K -Means dengan parameter terbaik nantinya akan digunakan untuk mengelompokkan data pelanggan. 2.5. Evaluation Dengan menetapkan nilai k, cluster akan dibentuk menggunakan data yang telah melalui pra - pemrosesan dan dimension reduction dengan PCA. Principal Component Analysis (PCA ) adalah metode untuk mengekstraksi pola dalam fitur dengan mengurangi dimensi. PCA menggabungkan beberapa variabel menjadi dua atau tiga komponen. PCA bekerja dengan mengurangi variasi data dan menemukan pola yang kuat dari kumpulan data. Fitur monetary, recency, dan frequency yang sebelumnya dinormalisasi akan direduksi ( monetary, recency, dan frequency. user_id tidak termasuk didalamnya. Pemilihan dua dimensi pada eksperimen bertujuan untuk meminimalkan dimensi komponen da n proses visualisasi data. Atas maksud tersebut, maka data akan direduksi menjadi 2 dimensi. Kemudian data dikelompokkan menurut cluster masing -masing, di mana setiap pengguna akan diberi label kelas untuk divisualisasi. Data dikelompokkan berdasarkan kategori. Setiap cluster dapat dikelompokkan menjadi rendah, sedang, dan tinggi berdasarkan nilai rata-rata setiap cluster. Pertama, hitung nilai kuartil 1 dari setiap fitur himpunan data. Kedua, hitung nilai kuartil 3 dari setiap fitur himpunan data. Ketiga, data yang nilai rata -ratanya di bawah kuartil satu dikategorikan sebagai low. Keempat, data yang nilai rata-ratanya berada di kisaran kuartil 1 hingga kuartil tiga dikategorikan sebagai medium. Kelima, data yang nilai rata -ratanya di atas kuartil tiga dikategorikan sebagai high. 3. KAJIAN PUSTAKA Dedi et al. mempelajari segmentasi pelanggan berdasarkan nilai Recency, Frequency, and Monetary (RFM) dengan K -means tradisional dan Fuzzy C - means. Data yang digunakan dalam penelitian adalah data transaksional untuk menganalisis perilaku pelanggan. Makalah ini mengusulkan metode baru dengan memilih centroid awal di K -Means dan bertujuan untuk menyegmentasikan pelanggan dengan iterasi dan waktu yang berkur ang. Algoritma RM K -Means yang diusulkan menghabiskan lebih sedikit waktu dan mengurangi iterasi, membuatnya lebih efektif. Segmentasi berfokus pada kebaruan, frekuensi, dan nilai moneter, memungkinkan perusahaan untuk menyesuaikan strategi pemasaran berda sarkan perilaku pembelian. Christy et al. mengelompokkan pelanggan menjadi beberapa kelompok berdasarkan nilai Recurrence, Frequency, dan Monetary (RFM). Algoritma pengelompokan seperti K -means dan Fuzzy C -means digunakan untuk menganalisis perilaku konsumen dengan data transaksi jual beli. Pemilihan centroid awal mampu mengurangi jumlah iterasi dan waktu yang dibutuhkan untuk segmentasi pelanggan. Hasil dibandingkan dengan metode konvensional dengan mempertimbangkan kekompakan kluster, waktu eksekusi, dan jumlah iterasi. Hasil studi menunjukkan bahwa clustering membantu perusahaan memberikan rekomendasi produk, mengidentifikasi tren, dan menyesuaikan program pemasaran. Jinfeng Z hou dkk. mendemonstrasikan model RFMT ( Recency, Frequency, Monetary, and Interpurchase Time ) untuk menyegmentasikan pelanggan di industri ritel. Model ini dapat digunakan untuk mengidentifikasi berbagai kelompok pelanggan berdasarkan perilaku pembelian mer eka. Hasil segmentasi dapat memberikan rekomendasi untuk strategi bisnis, seperti mengalokasikan sumber daya pemasaran dan rekomendasi produk yang disesuaikan. Namun, perlu ada lebih banyak informasi tentang metode yang digunakan untuk mengumpulkan data pe langgan. Selain itu, makalah ini juga perlu memberikan informasi tentang ukuran sampel yang digunakan dalam penelitian. Hasil penelitian dapat menunjukkan informasi yang dapat Manuel, dkk, Segmentasi Pelanggan Majalah 1247 membantu mengevaluasi reliabilitas dan generalisasi hasil segmentasi. Rahim et al. menggunakan model Recency, Frequency, dan Monetary (RFM) yang dikombinasikan dengan model pembelajaran mesin seperti Multi -Layer Perceptron (MLP) dan Support Vector Machine (SVM) untuk mengklasifikasikan pelanggan. Penelitian ini bertujuan untuk mengklasifikasikan pelanggan berdasarkan perilaku belanja di industri ritel. Anitha et al. menerapkan konsep business intelligence dalam mengidentifikasi pelanggan potensial dengan menyediakan data yang relevan dan tepat waktu untuk industri ritel. Studi ini menganalisis riwayat transaksi untuk mengidentifikasi perilaku belanja konsumen dan keuntungan bisnis. Model RFM (Recency, Frequency, dan Monetary) dikombinasikan dengan algoritma K -Means untuk menyegmentasikan pelanggan. Analisis RFM menghitung kebaruan, frekuensi, dan nilai moneter setiap pelanggan untuk proses segmentasi. Algoritma K -Means memilih jumlah cluster berdasarkan silhouette score berdasarkan nilai RFM. Agustino dkk. menggunakan metode RFM dan K-Means dalam memprofil pelanggan pada platform edukasi pada seb uah start-up digital. Pada penelitian diusulkan beberapa metrik seperti Elbow Method, Silhouette Scores, dan Davis Bouldin Index dalam menemukan jumlah cluster yang sesuai. Dataset yang digunakan berdasarkan transaksi pada start-up tersebut dengan jumlah data sebanyak 283 dan fitur yang terdiri atas email, id transaksi, waktu transaksi, tipe transfer, dan jumlah transfer. Dalam proses normalisasi data digunakan library Standar Scaler terhadap fitur recency, frequency, dan monetary yang telah dihitung sebelumnya berdasarkan fitur pada dataset. Hasil dalam penelitian tersebut menunjukkan bahwa 2 cluster adalah yang paling optimal, dimana pelanggan pada cluster 1 menunjukkan pembelian lebih dari satu kali walaupun dengan nominal pembeli an yang sedikit. Monalisa dkk. dalam penelitiannya melakukan identifikasi terhadap pelanggan yang memiliki prospek dengan metode RFM dan DBSCAN algorithm. Dengan menggunakan Silhouette Index didapatkan cluster yang paling optimal ya itu 5. Penelitian tersebut juga melakukan pendekatan analisis demografi terhadap gender, usia, pekerjaan, alamat, dan status pernikahan dalam menganalisis frekuensi pembelian antara cluster pertama (memiliki prospek) dengan cluster loyal customers. Al-Yasir dkk. melakukan penelitian dengan menerapkan metode Fuzzy C -Means dan RFM dalam menganalisis loyalitas pelanggan B2B.. Penelitian menggunakan Davies Bouldin Index (DBI) dalam mendapatkan cluster yang sesuai antara 2 -10. Didapatkan nilai DBI 0,4908 dan dua sebagai jumlah cluster yang sesuai. Digunakan 4 indikator RFM berdasarkan rata -rata dari tiap Recency, Frequency, dan Monetary, yaitu loyal customer, lost customer, new customer, dan prospect customer. Didapatkan 2 cluster, yaitu loyal customer dan lost customer sebagai hasil analisis. 4. HASIL 4.1. Bentuk Data Dilakukan pra -pemrosesan untuk beberapa fitur yang ber bentuk katego rik dan numerik. Fitur user_id tetap dipertahankan sebagai unique identifier untuk setiap transaksi. Setelah proses pra -pemrosesan, 3.900 baris data dihasilkan fitur baru dalam bentuk fitur monetary, frequency, dan recency dalam bentuk numerik. Metode normalisasi data numerik menghasilkan distribusi normal dengan metode standard scaler. Rumus standard scaler dapat dijelaskan seperti rumus berikut z x μ σ (1) di mana x adalah nilai awal, μ adalah mean, dan σ adalah standar deviasi. Normalisasi ini bertujuan untuk mengubah nilai rata -rata distribusi menjadi nol dan standar deviasinya menjadi 1. Dengan demikian, data yang diperoleh memiliki distribusi yang seragam sehingga data dapat diguna kan untuk proses clustering. Beberapa sampel data dapat dilihat pada tabel 2. user_id recency frequency monetary 001b5eddf7 0,4387 0,4416 -0,2096 0023cedbf9 -0,9347 -0,4402 -0,2096 0024ae4898 0,0752 0,4416 -0,2096 002d8b5849 -0,4700 -0,4402 -0,2096 4.2. Reduksi Dimensi Setelah didapatkan fitur berdasarkan recency, frequency, dan monetary dilakukan proses reduksi dimensi data menjadi 2 dimensi. Tujuan dari hal tersebut yaitu memudahkan dalam proses visualisasi dan menerangkan cluster data. Grafik scatter plot digunakan untuk. Pada gambar 2, dapat dilihat bahwa data semakin berhimpit tetapi belum ada pengelompokan yang jelas. 1248 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm. 1243 -1252 4.3. Analisis Jumlah Cluster Sebelum proses clustering, pertama dilakukan proses analisis cluster. Proses analisis cluster bertujuan untuk menemukan jumlah cluster atau nilai k yang optimal. Parameter k adalah input yang digunakan sebagai nilai parameter fungsi K -Means pada library sklearn. Analisis cluster menggunakan elbow method dan silhouette score yang telah dilakukan pada tahap sebelumnya. Nilai (Dalam Jumlah Kuadrat) WSS dihasilkan dengan melakukan iterasi sebanyak sepuluh kali untuk setiap cluster. Pada gambar 3, dapat dilihat bahwa memplot nilai WSS untuk setiap kelompok menghasilkan elbow method. Dengan begitu, kita dapat menentukan bahwa nilai k terbaik berdasarkan elbow method adalah k dengan nilai 3. Mendapatkan silhouette score terhadap semua transaksi k dari satu hingga sepuluh dapat dilakukan dengan menggunakan rumus 2 berikut s(i) b(i) a(i) max a(i),b(i) (2) di mana a(i) adalah rata -rata perbedaan jarak ke semua titik objek dan b(i) adalah nilai minimum antara jarak rata -rata sampel dari sampel ke cluster lain. Dengan menghitung silhouette score (misalnya, k dalam K -Means), silhouette score tertinggi menunjukkan jumlah cluster terbaik. k wss silhouette score 3 843,214747 0,638181 4 843,165970 0,638099 5 843,165970 0,638099 6 843,165970 0,638099 7 843,165970 0,638099 8 843,165970 0,638099 9 843,165970 0,638099 10 843,165970 0,638099 2 892,717979 0,637027 Kemudian dilakukan proses analisis cluster dengan menggunakan metode silhouette score. Iterasi sepuluh kali dilakukan untuk mendapatkan nilai k yang sesuai. Mengacu pada tabel 3, dapat disimpulkan bahwa nilai k yang sesuai berdasarkan silhouette score adalah k 3, dengan nilai 0,63818. Silhouette score terbaik adalah yang paling signifikan dibandingkan dengan jumlah cluster lainnya. 4.4. Clustering Clustering dilakukan dengan menggunakan metode K -Means untuk mendapatkan pola segmentasi pelanggan. Parameter yang diterapkan pada fungsi K -Means adalah n_init 3 nilai k). Selain itu, iterasi maksimum ditentukan dengan menentukan ma x_iter 300. Ini bertujuan untuk menentukan batas iterasi hingga mencapai konvergensi. Proses pe mbentukan model akan membagi data menjadi tiga kelompok yang berbeda. Model K -Means akan menghasilkan label untuk setiap record data. Untuk itu, fitur label akan dibentuk untuk menginisiasi data yang disertakan dalam nomor cluster. gambar 4 menunjukkan bag aimana cluster didistribusikan berdasarkan pola data. Dengan membagi cluster menjadi tiga, maka akan terbentuk 3 centroid. Titik data akan dikelompokkan berdasarkan jarak dengan centroid terdekat. Hanya cluster yang terbentuk untuk saat ini Kemudian, akan dilakukan proses untuk menemukan pola dari masing -masing cluster. 4.5. Pola untuk tiap cluster Menentukan pola masing -masing cluster dilakukan dengan mencari nilai mean dari masing - masing cluster berdasarkan fitur. Kemudian nilai tersebut akan menjadi patokan untuk menentukan apakah cluster dengan fitur RFM -nya dapat dikategorikan sebagai low, medium, atau high. Setiap fitur dihitung t erlebih dahulu. Dikategorikan sebagai low ketika di bawah Q1, medium antara Q1 dan Q3, dan high ketika lebih dari Q3. Tabel 4 menunjukkan bagaimana pola data didasarkan pada nilai rata -rata untuk setiap cluster terhadap fitur -fiturnya. Nilai recency dapat dikategorikan sebagai rendah berarti jarak antara satu pembelian dan pembelian berikutnya cenderung cepat. Nilai recency high berarti bahwa waktu antara satu pembelian dan pembelian berikutnya cenderung Manuel, dkk, Segmentasi Pelanggan Majalah 1249 lambat. Nilai frequency dikategorikan sebagai low jika Anda jarang melakukan pembelian, frequency high berarti pembelian yang sering. Monetary dikategorikan low jika nilai uang yang dikeluarkan untuk melakukan pembelian cenderung rendah, sedangkan high berarti nilai pembelian tinggi. Nasabah yang diinginkan adalah nasabah yang memiliki nilai recency rendah, frequency tinggi, dan monetary tinggi. Berdasarkan proses kategorisasi yang telah dijelaskan, karakteristik masing -masing cluster dapat digambarkan sebagai berikut cluster recency frequency monetary 0 low (1,14) low (1,20) low (301.640) 1 high (249,61) medium (2,62) medium (799.934) 2 medium (233,01) high (6,41) high (2.018.088) pada data yang belum dinormalisasi, pola -pola tersebut dengan nilai mean masing -masing cluster untuk setiap fitur RFM dapat dijelaskan pada Tabel 5 sebagai berikut segmen recency frequency monetary Low 117,07 1,91 550.787 Medium 117,07 dan 249,61 1,91 dan 6,41 550.787 dan 2.018.088 High 249,61 6,41 2.018.088 Pelanggan pada cluster ini berjumlah 3.303 pelanggan dari total 3.900 pelanggan yang dianalisis. Jumlah ini sekitar 84,69 dari total pelanggan yang dianalisis atau mayoritas pembeli di e-commerce. Ini menunjukkan karakteristik pelanggan pada cluster 0. Nilai pembelian rata -rata pada cluster ini adalah Rp. 301.640, Hal ini dapat diklasifikasikan sebagai nilai pembelian yang rendah. Frekuensi rata -rata pembelian adalah 1,20 kali. Ini diklasifikasikan sebagai frekuensi pembelian yang rendah. Nilai rata - rata waktu yang cukup cepat hingga pembelia n berikutnya adalah 1,14 hari. Berdasarkan nilai -nilai tersebut, dapat dikatakan bahwa pelanggan di cluster ini cenderung melakukan pembelian dalam waktu singkat, bahkan dengan nilai pembelian yang rendah. Pelanggan pada cluster ini berjumlah 511 pelanggan dari total 3.900 pelanggan yang dianalisis. Jumlah ini sekitar 13,10 dari total pelanggan yang dianalisis. Rata -rata nilai pembelian di cluster ini adalah Rp. 799.934 atau tergolong nilai pembelian menengah. Rata -rata frekuensi pembelian adalah 2,62 kali dan rata -rata nilai waktu hingga pembelian berikutnya cukup lama, yaitu 249,61 hari. Berbeda dengan pembeli pada cluster sebelumnya, karakteristik pembeli pada cluster ini membeli produk dengan nilai sedang namun akan kembali membeli produk dalam jangka waktu yang lama. Pelanggan pada cluster ini berjumlah 86 pelanggan dari total 3.900 pelanggan yang dianalisis. Jumlah ini sekitar 2,20 dari total pelanggan yang dianalisis. Rata -rata nilai pembelian di cluster ini yaitu Rp. 2.018.088 atau dengan nilai yan g besar dengan frekuensi pembelian rata -rata 6,41 kali, dan nilai rata -rata waktu hingga pembelian berikutnya cukup lama, yaitu 233,01 hari. Karakter pelanggan berikut ini unik karena frekuensinya hingga 3 kali lipat dari cluster lainnya, bahkan dengan nil ai beli yang besar. Hanya saja jangka waktu pembeliannya cukup lama untuk pembelian berikutnya.'}\n"
     ]
    }
   ],
   "source": [
    "# Process multiple documents\n",
    "all_cleaned_texts = {}\n",
    "\n",
    "for filename, text in pdf_text.items():\n",
    "    # Clean and prepare each document\n",
    "    cleaned_text = prepare_text_for_summarization(text)\n",
    "    all_cleaned_texts[filename] = cleaned_text\n",
    "    # print(f\"\\nDocument: {filename}\")\n",
    "    # print(\"Length of cleaned text:\", len(cleaned_text))\n",
    "    # print(\"-\" * 50)\n",
    "    # print(\"Cleaned text:\")\n",
    "    # print(cleaned_text)\n",
    "    \n",
    "\n",
    "print(all_cleaned_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.3-cp311-cp311-win_amd64.whl (12.2 MB)\n",
      "     ---------------------------------------- 0.0/12.2 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.2 MB 991.0 kB/s eta 0:00:13\n",
      "     ---------------------------------------- 0.1/12.2 MB 1.7 MB/s eta 0:00:08\n",
      "      --------------------------------------- 0.3/12.2 MB 2.2 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.4/12.2 MB 2.4 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 0.5/12.2 MB 2.3 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.6/12.2 MB 2.1 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.6/12.2 MB 2.0 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.7/12.2 MB 1.9 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 0.8/12.2 MB 1.9 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 0.8/12.2 MB 1.9 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 0.9/12.2 MB 1.8 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 1.0/12.2 MB 1.7 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 1.1/12.2 MB 1.8 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 1.2/12.2 MB 1.7 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 1.2/12.2 MB 1.8 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 1.3/12.2 MB 1.7 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 1.4/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 1.4/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 1.5/12.2 MB 1.7 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 1.6/12.2 MB 1.7 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 1.6/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 1.6/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 1.7/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 1.8/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ------ --------------------------------- 1.8/12.2 MB 1.5 MB/s eta 0:00:07\n",
      "     ------ --------------------------------- 1.9/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ------ --------------------------------- 2.0/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ------ --------------------------------- 2.1/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.2/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.2/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.3/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.3/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.3/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.3/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.3/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.3/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.3/12.2 MB 1.6 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.4/12.2 MB 1.3 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 2.4/12.2 MB 1.3 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 2.4/12.2 MB 1.3 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.4/12.2 MB 1.3 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.5/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.5/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.6/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.6/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.6/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.7/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.7/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.7/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 2.8/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 2.8/12.2 MB 1.2 MB/s eta 0:00:09\n",
      "     --------- ------------------------------ 2.8/12.2 MB 1.2 MB/s eta 0:00:09\n",
      "     --------- ------------------------------ 2.9/12.2 MB 1.2 MB/s eta 0:00:09\n",
      "     --------- ------------------------------ 2.9/12.2 MB 1.2 MB/s eta 0:00:09\n",
      "     --------- ------------------------------ 3.0/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 3.0/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 3.1/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 3.2/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 3.2/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 3.3/12.2 MB 1.2 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 3.3/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 3.3/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 3.4/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 3.5/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 3.5/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 3.6/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 3.6/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 3.6/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 3.7/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 3.8/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 3.9/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 3.9/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 3.9/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 3.9/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 4.0/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 4.0/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 4.1/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 4.1/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 4.2/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 4.3/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 4.3/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 4.4/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 4.4/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 4.4/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 4.5/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 4.5/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 4.6/12.2 MB 1.1 MB/s eta 0:00:08\n",
      "     --------------- ------------------------ 4.6/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 4.7/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 4.8/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 4.8/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 4.8/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 4.9/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 5.0/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 5.0/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 5.1/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 5.1/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 5.2/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 5.2/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 5.2/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 5.3/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 5.3/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 5.3/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 5.4/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 5.4/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 5.4/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 5.5/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------------ --------------------- 5.5/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------------ --------------------- 5.5/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------------ --------------------- 5.6/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------------ --------------------- 5.7/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------------ --------------------- 5.7/12.2 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------------- -------------------- 5.8/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 5.9/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 5.9/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.0/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.1/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 6.1/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 6.2/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 6.3/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 6.3/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 6.3/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 6.4/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.4/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.5/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.5/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.6/12.2 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.6/12.2 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.6/12.2 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.6/12.2 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.7/12.2 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.7/12.2 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 6.7/12.2 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 6.8/12.2 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 6.8/12.2 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 6.9/12.2 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 7.0/12.2 MB 1.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 7.0/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.1/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.1/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.2/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.2/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.3/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.3/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 7.3/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 7.4/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 7.5/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 7.5/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 7.6/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 7.6/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 7.7/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 7.7/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 7.8/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 7.9/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 7.9/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 8.0/12.2 MB 1.0 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 8.0/12.2 MB 1.0 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.1/12.2 MB 1.0 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.1/12.2 MB 1.0 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.2/12.2 MB 1.0 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.2/12.2 MB 1.0 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.3/12.2 MB 1.0 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.3/12.2 MB 1.0 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.4/12.2 MB 1.0 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.4/12.2 MB 1.0 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.5/12.2 MB 1.1 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 8.6/12.2 MB 1.1 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 8.6/12.2 MB 1.1 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 8.7/12.2 MB 1.1 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 8.7/12.2 MB 1.1 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 8.8/12.2 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 8.9/12.2 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 8.9/12.2 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 9.0/12.2 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 9.1/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.1/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.2/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.2/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.3/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.3/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.4/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.4/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 9.5/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 9.5/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 9.6/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 9.6/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 9.7/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 9.8/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 9.8/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 9.8/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 9.9/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 9.9/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.0/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.0/12.2 MB 1.1 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 10.1/12.2 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.1/12.2 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.2/12.2 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.2/12.2 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.2/12.2 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.2/12.2 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.2/12.2 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.2/12.2 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.3/12.2 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.3/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.3/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.4/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 10.4/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 10.4/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 10.5/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 10.5/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 10.5/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 10.6/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 10.6/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 10.6/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 10.7/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 10.7/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 10.7/12.2 MB 1.0 MB/s eta 0:00:02\n",
      "     --------------------------------- ---- 10.8/12.2 MB 999.6 kB/s eta 0:00:02\n",
      "     --------------------------------- ---- 10.8/12.2 MB 998.0 kB/s eta 0:00:02\n",
      "     --------------------------------- ---- 10.9/12.2 MB 996.5 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 10.9/12.2 MB 993.5 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.0/12.2 MB 996.5 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.0/12.2 MB 993.5 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.1/12.2 MB 990.5 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.1/12.2 MB 992.0 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.2/12.2 MB 989.1 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.2/12.2 MB 986.0 kB/s eta 0:00:02\n",
      "     ----------------------------------- -- 11.2/12.2 MB 983.1 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 11.3/12.2 MB 983.0 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 11.3/12.2 MB 980.0 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 11.3/12.2 MB 978.6 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 11.4/12.2 MB 975.7 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 11.4/12.2 MB 974.3 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 11.4/12.2 MB 968.5 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 11.5/12.2 MB 968.5 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 11.5/12.2 MB 967.1 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 11.6/12.2 MB 968.5 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 11.6/12.2 MB 967.1 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 11.7/12.2 MB 965.7 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 11.7/12.2 MB 964.3 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 11.8/12.2 MB 962.8 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 11.8/12.2 MB 960.0 kB/s eta 0:00:01\n",
      "     -------------------------------------  11.9/12.2 MB 964.3 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.0/12.2 MB 964.3 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.0/12.2 MB 964.3 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.0/12.2 MB 964.3 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.1/12.2 MB 961.4 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.1/12.2 MB 959.9 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.2/12.2 MB 957.2 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.2/12.2 MB 954.4 kB/s eta 0:00:01\n",
      "     -------------------------------------- 12.2/12.2 MB 949.6 kB/s eta 0:00:00\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.11-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.10-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "     ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "     --------- ----------------------------- 30.7/122.3 kB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------ ------------ 81.9/122.3 kB 919.0 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 112.6/122.3 kB 939.4 kB/s eta 0:00:01\n",
      "     ------------------------------------ 122.3/122.3 kB 794.9 kB/s eta 0:00:00\n",
      "Collecting thinc<8.4.0,>=8.3.0\n",
      "  Downloading thinc-8.3.3-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.5 MB 435.7 kB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.0/1.5 MB 326.8 kB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.1/1.5 MB 508.4 kB/s eta 0:00:03\n",
      "     --- ------------------------------------ 0.1/1.5 MB 595.3 kB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 0.2/1.5 MB 787.7 kB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.3/1.5 MB 874.6 kB/s eta 0:00:02\n",
      "     -------- ------------------------------- 0.3/1.5 MB 984.6 kB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 0.4/1.5 MB 958.4 kB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 0.4/1.5 MB 960.7 kB/s eta 0:00:02\n",
      "     ------------ --------------------------- 0.5/1.5 MB 930.9 kB/s eta 0:00:02\n",
      "     ------------- -------------------------- 0.5/1.5 MB 879.9 kB/s eta 0:00:02\n",
      "     ------------- -------------------------- 0.5/1.5 MB 892.8 kB/s eta 0:00:02\n",
      "     --------------- ------------------------ 0.6/1.5 MB 862.7 kB/s eta 0:00:02\n",
      "     --------------- ------------------------ 0.6/1.5 MB 868.6 kB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 0.7/1.5 MB 897.2 kB/s eta 0:00:01\n",
      "     ------------------- -------------------- 0.7/1.5 MB 935.8 kB/s eta 0:00:01\n",
      "     -------------------- ------------------- 0.8/1.5 MB 945.8 kB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 0.8/1.5 MB 965.6 kB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 0.9/1.5 MB 972.0 kB/s eta 0:00:01\n",
      "     ------------------------- -------------- 0.9/1.5 MB 977.8 kB/s eta 0:00:01\n",
      "     -------------------------- ------------- 1.0/1.5 MB 978.2 kB/s eta 0:00:01\n",
      "     -------------------------- ------------- 1.0/1.5 MB 963.4 kB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.1/1.5 MB 968.9 kB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.1/1.5 MB 988.0 kB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.1/1.5 MB 948.9 kB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.2/1.5 MB 949.2 kB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.2/1.5 MB 954.4 kB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 1.3/1.5 MB 948.4 kB/s eta 0:00:01\n",
      "     ------------------------------------ --- 1.4/1.5 MB 975.6 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.4/1.5 MB 975.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- - 1.4/1.5 MB 968.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- - 1.4/1.5 MB 968.9 kB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 939.9 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 919.7 kB/s eta 0:00:00\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.5.0-cp311-cp311-win_amd64.whl (632 kB)\n",
      "     ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "     - ----------------------------------- 30.7/632.6 kB 640.0 kB/s eta 0:00:01\n",
      "     --- --------------------------------- 61.4/632.6 kB 812.7 kB/s eta 0:00:01\n",
      "     ------ ----------------------------- 122.9/632.6 kB 798.9 kB/s eta 0:00:01\n",
      "     -------- --------------------------- 143.4/632.6 kB 774.0 kB/s eta 0:00:01\n",
      "     --------- -------------------------- 174.1/632.6 kB 748.1 kB/s eta 0:00:01\n",
      "     ------------- ---------------------- 235.5/632.6 kB 846.9 kB/s eta 0:00:01\n",
      "     ---------------- ------------------- 286.7/632.6 kB 883.3 kB/s eta 0:00:01\n",
      "     -------------------- --------------- 358.4/632.6 kB 967.1 kB/s eta 0:00:01\n",
      "     ------------------------- ------------ 430.1/632.6 kB 1.0 MB/s eta 0:00:01\n",
      "     ----------------------------- -------- 491.5/632.6 kB 1.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ----- 542.7/632.6 kB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- --- 573.4/632.6 kB 1.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- -- 593.9/632.6 kB 1.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  624.6/632.6 kB 958.5 kB/s eta 0:00:01\n",
      "     ------------------------------------ 632.6/632.6 kB 926.2 kB/s eta 0:00:00\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 0.0/50.3 kB ? eta -:--:--\n",
      "     ----------------------- -------------- 30.7/50.3 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 50.3/50.3 kB 635.4 kB/s eta 0:00:00\n",
      "Collecting typer<1.0.0,>=0.3.0\n",
      "  Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "     ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
      "     ------------------------- ------------ 30.7/44.9 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.9/44.9 kB 438.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from spacy) (2.29.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "     ---------------------------------------- 0.0/431.8 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/431.8 kB ? eta -:--:--\n",
      "     --- --------------------------------- 41.0/431.8 kB 330.3 kB/s eta 0:00:02\n",
      "     ------ ------------------------------ 71.7/431.8 kB 438.9 kB/s eta 0:00:01\n",
      "     ---------- ------------------------- 122.9/431.8 kB 602.4 kB/s eta 0:00:01\n",
      "     ------------ ----------------------- 153.6/431.8 kB 706.2 kB/s eta 0:00:01\n",
      "     ----------------- ------------------ 204.8/431.8 kB 734.2 kB/s eta 0:00:01\n",
      "     ------------------ ----------------- 225.3/431.8 kB 726.5 kB/s eta 0:00:01\n",
      "     --------------------- -------------- 256.0/431.8 kB 684.6 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 286.7/431.8 kB 708.9 kB/s eta 0:00:01\n",
      "     ------------------------- ---------- 307.2/431.8 kB 679.5 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 337.9/431.8 kB 677.0 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 389.1/431.8 kB 693.9 kB/s eta 0:00:01\n",
      "     -----------------------------------  430.1/431.8 kB 708.0 kB/s eta 0:00:01\n",
      "     ------------------------------------ 431.8/431.8 kB 658.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from spacy) (67.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from spacy) (23.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "     ---------------------------------------- 0.0/183.0 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/183.0 kB ? eta -:--:--\n",
      "     -------- ---------------------------- 41.0/183.0 kB 653.6 kB/s eta 0:00:01\n",
      "     -------------- ---------------------- 71.7/183.0 kB 787.7 kB/s eta 0:00:01\n",
      "     ------------------------ ----------- 122.9/183.0 kB 798.9 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 174.1/183.0 kB 876.1 kB/s eta 0:00:01\n",
      "     ------------------------------------ 183.0/183.0 kB 850.9 kB/s eta 0:00:00\n",
      "Collecting language-data>=1.2\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "     ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/5.4 MB 1.3 MB/s eta 0:00:05\n",
      "      --------------------------------------- 0.1/5.4 MB 787.7 kB/s eta 0:00:07\n",
      "      --------------------------------------- 0.1/5.4 MB 787.7 kB/s eta 0:00:07\n",
      "      --------------------------------------- 0.1/5.4 MB 454.0 kB/s eta 0:00:12\n",
      "      --------------------------------------- 0.1/5.4 MB 516.7 kB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.2/5.4 MB 482.7 kB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.2/5.4 MB 530.7 kB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.2/5.4 MB 518.8 kB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.2/5.4 MB 533.8 kB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.3/5.4 MB 547.0 kB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.3/5.4 MB 573.4 kB/s eta 0:00:09\n",
      "     -- ------------------------------------- 0.3/5.4 MB 580.3 kB/s eta 0:00:09\n",
      "     -- ------------------------------------- 0.3/5.4 MB 540.7 kB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.4/5.4 MB 546.3 kB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.4/5.4 MB 541.9 kB/s eta 0:00:10\n",
      "     --- ------------------------------------ 0.4/5.4 MB 544.1 kB/s eta 0:00:10\n",
      "     --- ------------------------------------ 0.5/5.4 MB 554.9 kB/s eta 0:00:09\n",
      "     --- ------------------------------------ 0.5/5.4 MB 554.9 kB/s eta 0:00:09\n",
      "     --- ------------------------------------ 0.5/5.4 MB 533.1 kB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 0.5/5.4 MB 550.1 kB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 0.6/5.4 MB 563.2 kB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 0.6/5.4 MB 597.8 kB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 0.7/5.4 MB 609.0 kB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 0.7/5.4 MB 628.8 kB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 0.7/5.4 MB 628.8 kB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 0.7/5.4 MB 596.9 kB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 0.8/5.4 MB 599.5 kB/s eta 0:00:08\n",
      "     ------ --------------------------------- 0.8/5.4 MB 608.8 kB/s eta 0:00:08\n",
      "     ------ --------------------------------- 0.9/5.4 MB 611.5 kB/s eta 0:00:08\n",
      "     ------ --------------------------------- 0.9/5.4 MB 619.3 kB/s eta 0:00:08\n",
      "     ------ --------------------------------- 0.9/5.4 MB 634.8 kB/s eta 0:00:08\n",
      "     ------- -------------------------------- 1.0/5.4 MB 642.1 kB/s eta 0:00:07\n",
      "     ------- -------------------------------- 1.0/5.4 MB 662.1 kB/s eta 0:00:07\n",
      "     -------- ------------------------------- 1.1/5.4 MB 674.6 kB/s eta 0:00:07\n",
      "     -------- ------------------------------- 1.1/5.4 MB 686.4 kB/s eta 0:00:07\n",
      "     -------- ------------------------------- 1.2/5.4 MB 703.5 kB/s eta 0:00:06\n",
      "     --------- ------------------------------ 1.3/5.4 MB 720.5 kB/s eta 0:00:06\n",
      "     --------- ------------------------------ 1.3/5.4 MB 730.2 kB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 1.4/5.4 MB 733.8 kB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 1.4/5.4 MB 759.1 kB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 1.5/5.4 MB 777.9 kB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 1.6/5.4 MB 791.7 kB/s eta 0:00:05\n",
      "     ------------ --------------------------- 1.6/5.4 MB 791.6 kB/s eta 0:00:05\n",
      "     ------------ --------------------------- 1.7/5.4 MB 807.3 kB/s eta 0:00:05\n",
      "     ------------- -------------------------- 1.8/5.4 MB 819.2 kB/s eta 0:00:05\n",
      "     ------------- -------------------------- 1.8/5.4 MB 800.7 kB/s eta 0:00:05\n",
      "     ------------- -------------------------- 1.8/5.4 MB 800.7 kB/s eta 0:00:05\n",
      "     ------------- -------------------------- 1.8/5.4 MB 795.7 kB/s eta 0:00:05\n",
      "     ------------- -------------------------- 1.9/5.4 MB 810.5 kB/s eta 0:00:05\n",
      "     -------------- ------------------------- 1.9/5.4 MB 807.4 kB/s eta 0:00:05\n",
      "     -------------- ------------------------- 2.0/5.4 MB 818.3 kB/s eta 0:00:05\n",
      "     --------------- ------------------------ 2.0/5.4 MB 822.4 kB/s eta 0:00:05\n",
      "     --------------- ------------------------ 2.1/5.4 MB 827.4 kB/s eta 0:00:04\n",
      "     --------------- ------------------------ 2.1/5.4 MB 832.2 kB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 2.2/5.4 MB 834.1 kB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 2.2/5.4 MB 833.9 kB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 2.2/5.4 MB 830.8 kB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 2.3/5.4 MB 837.0 kB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 2.4/5.4 MB 841.2 kB/s eta 0:00:04\n",
      "     ------------------ --------------------- 2.4/5.4 MB 844.1 kB/s eta 0:00:04\n",
      "     ------------------ --------------------- 2.5/5.4 MB 848.1 kB/s eta 0:00:04\n",
      "     ------------------ --------------------- 2.5/5.4 MB 849.6 kB/s eta 0:00:04\n",
      "     ------------------- -------------------- 2.6/5.4 MB 849.1 kB/s eta 0:00:04\n",
      "     ------------------- -------------------- 2.7/5.4 MB 862.8 kB/s eta 0:00:04\n",
      "     -------------------- ------------------- 2.7/5.4 MB 869.5 kB/s eta 0:00:04\n",
      "     -------------------- ------------------- 2.8/5.4 MB 877.2 kB/s eta 0:00:03\n",
      "     -------------------- ------------------- 2.8/5.4 MB 883.6 kB/s eta 0:00:03\n",
      "     --------------------- ------------------ 2.9/5.4 MB 896.1 kB/s eta 0:00:03\n",
      "     --------------------- ------------------ 2.9/5.4 MB 895.7 kB/s eta 0:00:03\n",
      "     --------------------- ------------------ 3.0/5.4 MB 886.2 kB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 3.0/5.4 MB 882.9 kB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 3.0/5.4 MB 876.8 kB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 3.0/5.4 MB 874.8 kB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 3.0/5.4 MB 874.8 kB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 3.1/5.4 MB 859.6 kB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 3.1/5.4 MB 858.7 kB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 3.2/5.4 MB 863.7 kB/s eta 0:00:03\n",
      "     ------------------------ --------------- 3.3/5.4 MB 869.3 kB/s eta 0:00:03\n",
      "     ------------------------ --------------- 3.3/5.4 MB 874.8 kB/s eta 0:00:03\n",
      "     ------------------------- -------------- 3.4/5.4 MB 881.1 kB/s eta 0:00:03\n",
      "     ------------------------- -------------- 3.4/5.4 MB 885.3 kB/s eta 0:00:03\n",
      "     -------------------------- ------------- 3.5/5.4 MB 894.0 kB/s eta 0:00:03\n",
      "     -------------------------- ------------- 3.6/5.4 MB 906.2 kB/s eta 0:00:02\n",
      "     --------------------------- ------------ 3.6/5.4 MB 901.8 kB/s eta 0:00:02\n",
      "     --------------------------- ------------ 3.7/5.4 MB 900.0 kB/s eta 0:00:02\n",
      "     --------------------------- ------------ 3.7/5.4 MB 897.9 kB/s eta 0:00:02\n",
      "     --------------------------- ------------ 3.7/5.4 MB 895.9 kB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 3.8/5.4 MB 893.4 kB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 3.8/5.4 MB 895.5 kB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 3.9/5.4 MB 894.3 kB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 3.9/5.4 MB 893.6 kB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 3.9/5.4 MB 886.9 kB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 4.0/5.4 MB 885.2 kB/s eta 0:00:02\n",
      "     ------------------------------ --------- 4.1/5.4 MB 883.5 kB/s eta 0:00:02\n",
      "     ------------------------------ --------- 4.1/5.4 MB 885.6 kB/s eta 0:00:02\n",
      "     ------------------------------ --------- 4.2/5.4 MB 887.7 kB/s eta 0:00:02\n",
      "     ------------------------------- -------- 4.2/5.4 MB 889.9 kB/s eta 0:00:02\n",
      "     ------------------------------- -------- 4.2/5.4 MB 890.3 kB/s eta 0:00:02\n",
      "     ------------------------------- -------- 4.3/5.4 MB 894.4 kB/s eta 0:00:02\n",
      "     -------------------------------- ------- 4.4/5.4 MB 896.5 kB/s eta 0:00:02\n",
      "     -------------------------------- ------- 4.4/5.4 MB 898.4 kB/s eta 0:00:02\n",
      "     --------------------------------- ------ 4.5/5.4 MB 899.3 kB/s eta 0:00:02\n",
      "     --------------------------------- ------ 4.5/5.4 MB 905.2 kB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 4.6/5.4 MB 911.9 kB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 4.6/5.4 MB 913.5 kB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 4.7/5.4 MB 917.1 kB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 4.8/5.4 MB 922.6 kB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 4.8/5.4 MB 926.3 kB/s eta 0:00:01\n",
      "     ------------------------------------ --- 4.9/5.4 MB 928.8 kB/s eta 0:00:01\n",
      "     ------------------------------------ --- 5.0/5.4 MB 934.9 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.0/5.4 MB 930.6 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.0/5.4 MB 927.3 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.1/5.4 MB 929.5 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.1/5.4 MB 929.5 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.1/5.4 MB 919.3 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.1/5.4 MB 919.3 kB/s eta 0:00:01\n",
      "     -------------------------------------- - 5.1/5.4 MB 912.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- - 5.2/5.4 MB 911.1 kB/s eta 0:00:01\n",
      "     ---------------------------------------  5.3/5.4 MB 911.8 kB/s eta 0:00:01\n",
      "     ---------------------------------------  5.3/5.4 MB 912.2 kB/s eta 0:00:01\n",
      "     ---------------------------------------  5.4/5.4 MB 914.8 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.4/5.4 MB 915.0 kB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/2.0 MB 640.0 kB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.1/2.0 MB 656.4 kB/s eta 0:00:03\n",
      "     - -------------------------------------- 0.1/2.0 MB 655.4 kB/s eta 0:00:03\n",
      "     --- ------------------------------------ 0.2/2.0 MB 893.0 kB/s eta 0:00:03\n",
      "     --- ------------------------------------ 0.2/2.0 MB 952.6 kB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 0.2/2.0 MB 778.2 kB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 0.3/2.0 MB 896.4 kB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.3/2.0 MB 905.4 kB/s eta 0:00:02\n",
      "     ------- -------------------------------- 0.4/2.0 MB 930.9 kB/s eta 0:00:02\n",
      "     -------- ------------------------------- 0.4/2.0 MB 949.4 kB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 0.5/2.0 MB 983.0 kB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 0.6/2.0 MB 992.2 kB/s eta 0:00:02\n",
      "     ------------ --------------------------- 0.6/2.0 MB 1.0 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 0.7/2.0 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 0.8/2.0 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 0.8/2.0 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 0.9/2.0 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 0.9/2.0 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 1.0/2.0 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 1.0/2.0 MB 1.1 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.0/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.1/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 1.1/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 1.2/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.2/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 1.3/2.0 MB 1.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.4/2.0 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.4/2.0 MB 1.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.5/2.0 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.5/2.0 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.6/2.0 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.6/2.0 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.6/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.6/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 1.7/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 1.8/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 1.8/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.8/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.8/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.9/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 1.9/2.0 MB 1.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 1.9/2.0 MB 980.5 kB/s eta 0:00:01\n",
      "     ---------------------------------------  1.9/2.0 MB 975.0 kB/s eta 0:00:01\n",
      "     ---------------------------------------  1.9/2.0 MB 975.0 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.0/2.0 MB 949.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Collecting blis<1.2.0,>=1.1.0\n",
      "  Downloading blis-1.1.0-cp311-cp311-win_amd64.whl (6.3 MB)\n",
      "     ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.3 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------------------------- 0.0/6.3 MB 667.8 kB/s eta 0:00:10\n",
      "      --------------------------------------- 0.1/6.3 MB 770.8 kB/s eta 0:00:09\n",
      "      --------------------------------------- 0.1/6.3 MB 853.3 kB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.2/6.3 MB 807.1 kB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.2/6.3 MB 942.1 kB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.3/6.3 MB 1.1 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.4/6.3 MB 1.1 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.4/6.3 MB 1.1 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 0.5/6.3 MB 1.1 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 0.6/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 0.6/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 0.7/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 0.7/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 0.8/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 0.9/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 0.9/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 1.0/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 1.0/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 1.1/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 1.2/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 1.2/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 1.3/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 1.3/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 1.4/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 1.5/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 1.5/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 1.6/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 1.6/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 1.7/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 1.8/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 1.8/6.3 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 1.9/6.3 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 2.0/6.3 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 2.0/6.3 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 2.1/6.3 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 2.1/6.3 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 2.2/6.3 MB 1.3 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 2.2/6.3 MB 1.3 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 2.3/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 2.4/6.3 MB 1.3 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 2.4/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 2.4/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 2.5/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 2.5/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 2.6/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 2.6/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 2.7/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 2.7/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 2.8/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 2.9/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 2.9/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 3.0/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 3.0/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 3.0/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 3.0/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 3.1/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 3.1/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 3.2/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 3.2/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 3.3/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 3.3/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 3.3/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 3.4/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 3.4/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 3.5/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 3.6/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 3.6/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 3.6/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 3.6/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 3.6/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 3.7/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 3.8/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 3.8/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 3.9/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 3.9/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 3.9/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 4.0/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 4.1/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 4.1/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 4.2/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 4.2/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 4.3/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 4.4/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 4.4/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 4.5/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 4.5/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 4.6/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 4.6/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 4.7/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 4.7/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 4.8/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 4.8/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 4.8/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 4.9/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 5.0/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 5.0/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 5.1/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 5.1/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 5.2/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 5.3/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 5.3/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 5.3/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 5.4/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 5.4/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 5.5/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 5.5/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 5.6/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 5.6/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 5.6/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 5.7/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 5.7/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 5.8/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 5.8/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 5.9/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.9/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.9/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.9/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.9/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 6.0/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 6.0/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 6.1/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 6.1/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 6.1/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.2/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.3/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.3/6.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.3/6.3 MB 1.1 MB/s eta 0:00:00\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "     ---------------------------------------- 0.0/242.4 kB ? eta -:--:--\n",
      "     ---- -------------------------------- 30.7/242.4 kB 640.0 kB/s eta 0:00:01\n",
      "     ---------- -------------------------- 71.7/242.4 kB 787.7 kB/s eta 0:00:01\n",
      "     ---------------------- --------------- 143.4/242.4 kB 1.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- -- 225.3/242.4 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 242.4/242.4 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "     ---------------------------------------- 0.0/52.5 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/52.5 kB ? eta -:--:--\n",
      "     ---------------------- --------------- 30.7/52.5 kB 330.3 kB/s eta 0:00:01\n",
      "     -------------------------------------  51.2/52.5 kB 290.5 kB/s eta 0:00:01\n",
      "     -------------------------------------- 52.5/52.5 kB 300.0 kB/s eta 0:00:00\n",
      "Collecting smart-open<8.0.0,>=5.2.1\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 0.0/61.7 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 30.7/61.7 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.7/61.7 kB 817.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting marisa-trie>=1.1.0\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-win_amd64.whl (152 kB)\n",
      "     ---------------------------------------- 0.0/152.0 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 30.7/152.0 kB 660.6 kB/s eta 0:00:01\n",
      "     ----------------------- --------------- 92.2/152.0 kB 1.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- -- 143.4/152.0 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 152.0/152.0 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
      "     ------------- ------------------------ 30.7/87.5 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 87.5/87.5 kB 990.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dhima\\miniconda3\\envs\\chatbot_notebook\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, shellingham, pydantic-core, murmurhash, mdurl, marisa-trie, cloudpathlib, catalogue, blis, annotated-types, srsly, pydantic, preshed, markdown-it-py, language-data, rich, langcodes, confection, typer, thinc, weasel, spacy\n",
      "Successfully installed annotated-types-0.7.0 blis-1.1.0 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.10 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.11 preshed-3.0.9 pydantic-2.10.4 pydantic-core-2.27.2 rich-13.9.4 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.3 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.0 thinc-8.3.3 typer-0.15.1 wasabi-1.1.3 weasel-0.4.1\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 330.3 kB/s eta 0:00:39\n",
      "     --------------------------------------- 0.1/12.8 MB 656.4 kB/s eta 0:00:20\n",
      "     --------------------------------------- 0.1/12.8 MB 737.3 kB/s eta 0:00:18\n",
      "     --------------------------------------- 0.2/12.8 MB 838.4 kB/s eta 0:00:16\n",
      "      -------------------------------------- 0.2/12.8 MB 787.7 kB/s eta 0:00:17\n",
      "      -------------------------------------- 0.2/12.8 MB 801.7 kB/s eta 0:00:16\n",
      "      -------------------------------------- 0.3/12.8 MB 936.6 kB/s eta 0:00:14\n",
      "     - -------------------------------------- 0.4/12.8 MB 1.1 MB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.5/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.6/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     -- ------------------------------------- 0.7/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     -- ------------------------------------- 0.8/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 1.0/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.1/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.2/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.2/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 1.6/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 1.7/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 1.9/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 1.9/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 2.0/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 2.1/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 2.1/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 2.2/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 2.3/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 2.3/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 2.4/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 2.5/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 2.5/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.6/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.7/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.8/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.8/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.9/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 3.0/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 3.0/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 3.1/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 3.1/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 3.2/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ---------- ----------------------------- 3.2/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ---------- ----------------------------- 3.5/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.5/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 3.9/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 4.0/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 4.0/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 4.1/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 4.2/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 4.2/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 4.3/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 4.4/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 4.4/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 4.5/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 4.6/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 4.6/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 4.7/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 4.7/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 4.8/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 4.9/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 4.9/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 5.0/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 5.1/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 5.1/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 5.8/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 5.8/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ------------------ --------------------- 5.9/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ------------------ --------------------- 6.0/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ------------------- -------------------- 6.1/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ------------------- -------------------- 6.1/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ------------------- -------------------- 6.1/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ------------------- -------------------- 6.2/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ------------------- -------------------- 6.4/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     -------------------- ------------------- 6.4/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     -------------------- ------------------- 6.5/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     -------------------- ------------------- 6.5/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     -------------------- ------------------- 6.5/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     -------------------- ------------------- 6.6/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     -------------------- ------------------- 6.7/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 6.7/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 6.8/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 6.9/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 6.9/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 7.0/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 1.4 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 1.4 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 1.3 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 1.3 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 1.3 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 1.3 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 1.3 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 7.7/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 7.7/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 7.7/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 7.8/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 7.8/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 7.9/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 7.9/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 7.9/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 8.0/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.0/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.1/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.1/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.2/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.2/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.3/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.3/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.3/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.4/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.4/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.5/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.5/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.6/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.6/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.6/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.7/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.7/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.8/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.8/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.8/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.9/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.9/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.3/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 9.3/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.3/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.6/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.6/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.6/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.6/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.7/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.7/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.8/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.9/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.9/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 9.9/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.1/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.1/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.2/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.2/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.3/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.3/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.4/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.4/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.4/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.5/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.5/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.6/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.6/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.6/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.7/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.7/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.8/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.8/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.9/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.2/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.2/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 11.6/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 11.6/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 11.7/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 11.8/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.5/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "30959\n"
     ]
    }
   ],
   "source": [
    "print(len(all_cleaned_texts))\n",
    "print(len(cleaned_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy.lang.id.stop_words as STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diminta',\n",
       " 'nantinya',\n",
       " 'sana',\n",
       " 'caranya',\n",
       " 'buat',\n",
       " 'termasuk',\n",
       " 'sesekali',\n",
       " 'dilihat',\n",
       " 'bertanya-tanya',\n",
       " 'diibaratkannya',\n",
       " 'sekadar',\n",
       " 'semaunya',\n",
       " 'dibuatnya',\n",
       " 'apakah',\n",
       " 'tertuju',\n",
       " 'jika',\n",
       " 'kita',\n",
       " 'selama',\n",
       " 'ungkapnya',\n",
       " 'kira-kira',\n",
       " 'menanyakan',\n",
       " 'lah',\n",
       " 'beberapa',\n",
       " 'tahun',\n",
       " 'perlunya',\n",
       " 'daripada',\n",
       " 'kenapa',\n",
       " 'sampai-sampai',\n",
       " 'diketahuinya',\n",
       " 'ucapnya',\n",
       " 'bung',\n",
       " 'tanpa',\n",
       " 'sekalian',\n",
       " 'tutur',\n",
       " 'memperkirakan',\n",
       " 'dituturkannya',\n",
       " 'ketika',\n",
       " 'ditunjuknya',\n",
       " 'sela',\n",
       " 'memperbuat',\n",
       " 'terlebih',\n",
       " 'masalah',\n",
       " 'menjadi',\n",
       " 'berbagai',\n",
       " 'diakhirinya',\n",
       " 'membuat',\n",
       " 'diantaranya',\n",
       " 'dikarenakan',\n",
       " 'berkenaan',\n",
       " 'anda',\n",
       " 'adalah',\n",
       " 'ujar',\n",
       " 'kalian',\n",
       " 'kasus',\n",
       " 'semula',\n",
       " 'waktunya',\n",
       " 'bakalan',\n",
       " 'bermula',\n",
       " 'berapa',\n",
       " 'betul',\n",
       " 'namun',\n",
       " 'berturut',\n",
       " 'bukan',\n",
       " 'tegas',\n",
       " 'gunakan',\n",
       " 'minta',\n",
       " 'lanjutnya',\n",
       " 'awal',\n",
       " 'mulanya',\n",
       " 'mengucapkan',\n",
       " 'sama-sama',\n",
       " 'adapun',\n",
       " 'malah',\n",
       " 'bersiap-siap',\n",
       " 'sinilah',\n",
       " 'juga',\n",
       " 'mengenai',\n",
       " 'seseorang',\n",
       " 'bukankah',\n",
       " 'padahal',\n",
       " 'sekitarnya',\n",
       " 'menunjuk',\n",
       " 'bahwa',\n",
       " 'akan',\n",
       " 'berawal',\n",
       " 'berakhirlah',\n",
       " 'terjadinya',\n",
       " 'seharusnya',\n",
       " 'kan',\n",
       " 'sekarang',\n",
       " 'bagian',\n",
       " 'empat',\n",
       " 'tanya',\n",
       " 'menggunakan',\n",
       " 'akulah',\n",
       " 'ternyata',\n",
       " 'terhadap',\n",
       " 'misal',\n",
       " 'ditegaskan',\n",
       " 'inginkah',\n",
       " 'dini',\n",
       " 'yakin',\n",
       " 'beginilah',\n",
       " 'tadi',\n",
       " 'katanya',\n",
       " 'waktu',\n",
       " 'segalanya',\n",
       " 'persoalan',\n",
       " 'tersampaikan',\n",
       " 'menunjuki',\n",
       " 'ditunjukkan',\n",
       " 'masa',\n",
       " 'kamu',\n",
       " 'seingat',\n",
       " 'keadaan',\n",
       " 'tanyanya',\n",
       " 'mampu',\n",
       " 'cukup',\n",
       " 'bisa',\n",
       " 'lagi',\n",
       " 'terdahulu',\n",
       " 'kelihatan',\n",
       " 'masing',\n",
       " 'nyaris',\n",
       " 'sebabnya',\n",
       " 'seorang',\n",
       " 'diperlukan',\n",
       " 'bagaikan',\n",
       " 'masalahnya',\n",
       " 'antar',\n",
       " 'disinilah',\n",
       " 'berdatangan',\n",
       " 'menyampaikan',\n",
       " 'maupun',\n",
       " 'seolah-olah',\n",
       " 'semata',\n",
       " 'mendatangi',\n",
       " 'inginkan',\n",
       " 'mana',\n",
       " 'semasih',\n",
       " 'dipertanyakan',\n",
       " 'menantikan',\n",
       " 'mengibaratkannya',\n",
       " 'setengah',\n",
       " 'kepada',\n",
       " 'benar',\n",
       " 'umum',\n",
       " 'sehingga',\n",
       " 'bapak',\n",
       " 'ibaratnya',\n",
       " 'dan',\n",
       " 'mempunyai',\n",
       " 'dikira',\n",
       " 'katakanlah',\n",
       " 'diibaratkan',\n",
       " 'hal',\n",
       " 'disebut',\n",
       " 'waduh',\n",
       " 'pertanyakan',\n",
       " 'terbanyak',\n",
       " 'kamulah',\n",
       " 'akhir',\n",
       " 'sebagaimana',\n",
       " 'antaranya',\n",
       " 'ataupun',\n",
       " 'meyakini',\n",
       " 'tandasnya',\n",
       " 'mengira',\n",
       " 'pantas',\n",
       " 'pihak',\n",
       " 'diperlihatkan',\n",
       " 'menunjuknya',\n",
       " 'dituturkan',\n",
       " 'selaku',\n",
       " 'menanti-nanti',\n",
       " 'berikut',\n",
       " 'sejauh',\n",
       " 'apaan',\n",
       " 'sekecil',\n",
       " 'dimulai',\n",
       " 'biasanya',\n",
       " 'dong',\n",
       " 'terhadapnya',\n",
       " 'ditunjuki',\n",
       " 'tahu',\n",
       " 'tambah',\n",
       " 'walaupun',\n",
       " 'depan',\n",
       " 'mengingatkan',\n",
       " 'sebetulnya',\n",
       " 'sejumlah',\n",
       " 'menyiapkan',\n",
       " 'sebanyak',\n",
       " 'artinya',\n",
       " 'antara',\n",
       " 'setelah',\n",
       " 'bagai',\n",
       " 'sebaiknya',\n",
       " 'menambahkan',\n",
       " 'agaknya',\n",
       " 'berkata',\n",
       " 'para',\n",
       " 'mempersiapkan',\n",
       " 'sebagainya',\n",
       " 'ibarat',\n",
       " 'soal',\n",
       " 'mirip',\n",
       " 'sedemikian',\n",
       " 'ingat-ingat',\n",
       " 'jauh',\n",
       " 'hanya',\n",
       " 'lima',\n",
       " 'kok',\n",
       " 'sebisanya',\n",
       " 'sebenarnya',\n",
       " 'mau',\n",
       " 'dipersoalkan',\n",
       " 'hanyalah',\n",
       " 'terutama',\n",
       " 'demikian',\n",
       " 'sebaik',\n",
       " 'menaiki',\n",
       " 'diberikannya',\n",
       " 'keinginan',\n",
       " 'terdapat',\n",
       " 'sangatlah',\n",
       " 'tetap',\n",
       " 'diperkirakan',\n",
       " 'percuma',\n",
       " 'karena',\n",
       " 'diperbuat',\n",
       " 'lewat',\n",
       " 'semasa',\n",
       " 'bahwasanya',\n",
       " 'memulai',\n",
       " 'kira',\n",
       " 'sedikit',\n",
       " 'mengucapkannya',\n",
       " 'semisalnya',\n",
       " 'merupakan',\n",
       " 'merekalah',\n",
       " 'sekurangnya',\n",
       " 'hampir',\n",
       " 'mengetahui',\n",
       " 'tegasnya',\n",
       " 'dimulainya',\n",
       " 'mempergunakan',\n",
       " 'pertama-tama',\n",
       " 'semua',\n",
       " 'ditanyakan',\n",
       " 'ibaratkan',\n",
       " 'jumlahnya',\n",
       " 'seolah',\n",
       " 'banyak',\n",
       " 'tambahnya',\n",
       " 'paling',\n",
       " 'dekat',\n",
       " 'baik',\n",
       " 'jangan',\n",
       " 'siap',\n",
       " 'cara',\n",
       " 'ditanya',\n",
       " 'lama',\n",
       " 'mampukah',\n",
       " 'menghendaki',\n",
       " 'terus',\n",
       " 'punya',\n",
       " 'walau',\n",
       " 'naik',\n",
       " 'kurang',\n",
       " 'makin',\n",
       " 'selama-lamanya',\n",
       " 'oleh',\n",
       " 'berakhir',\n",
       " 'jawab',\n",
       " 'belakangan',\n",
       " 'sebelumnya',\n",
       " 'diucapkannya',\n",
       " 'serupa',\n",
       " 'bersiap',\n",
       " 'begitu',\n",
       " 'bagi',\n",
       " 'sayalah',\n",
       " 'tandas',\n",
       " 'enggak',\n",
       " 'bermacam',\n",
       " 'menuturkan',\n",
       " 'dimaksudkannya',\n",
       " 'mengatakannya',\n",
       " 'ditunjukkannya',\n",
       " 'begitukah',\n",
       " 'sekitar',\n",
       " 'bila',\n",
       " 'jadinya',\n",
       " 'maka',\n",
       " 'jikalau',\n",
       " 'sama',\n",
       " 'memberikan',\n",
       " 'diketahui',\n",
       " 'sedangkan',\n",
       " 'bagaimana',\n",
       " 'ditanyai',\n",
       " 'sangat',\n",
       " 'sedang',\n",
       " 'diperbuatnya',\n",
       " 'mereka',\n",
       " 'usah',\n",
       " 'mulailah',\n",
       " 'serta',\n",
       " 'begitulah',\n",
       " 'berkehendak',\n",
       " 'sementara',\n",
       " 'meski',\n",
       " 'lalu',\n",
       " 'semisal',\n",
       " 'ataukah',\n",
       " 'mendatangkan',\n",
       " 'seberapa',\n",
       " 'tetapi',\n",
       " 'teringat',\n",
       " 'diinginkan',\n",
       " 'kemungkinannya',\n",
       " 'keseluruhannya',\n",
       " 'setiap',\n",
       " 'kemudian',\n",
       " 'yakni',\n",
       " 'keluar',\n",
       " 'siapakah',\n",
       " 'mulai',\n",
       " 'tampak',\n",
       " 'dimungkinkan',\n",
       " 'sewaktu',\n",
       " 'tersebut',\n",
       " 'bolehlah',\n",
       " 'seenaknya',\n",
       " 'asal',\n",
       " 'melainkan',\n",
       " 'se',\n",
       " 'boleh',\n",
       " 'lainnya',\n",
       " 'menandaskan',\n",
       " 'ditambahkan',\n",
       " 'ujarnya',\n",
       " 'sejak',\n",
       " 'pertanyaan',\n",
       " 'sesuatu',\n",
       " 'tinggi',\n",
       " 'apatah',\n",
       " 'saya',\n",
       " 'apa',\n",
       " 'lain',\n",
       " 'khususnya',\n",
       " 'sering',\n",
       " 'diberi',\n",
       " 'sebab',\n",
       " 'seusai',\n",
       " 'merasa',\n",
       " 'semakin',\n",
       " 'segera',\n",
       " 'penting',\n",
       " 'kami',\n",
       " 'sekurang-kurangnya',\n",
       " 'di',\n",
       " 'sesuatunya',\n",
       " 'pada',\n",
       " 'sesudahnya',\n",
       " 'pukul',\n",
       " 'bisakah',\n",
       " 'menurut',\n",
       " 'sebutlah',\n",
       " 'dalam',\n",
       " 'satu',\n",
       " 'kalaulah',\n",
       " 'tidakkah',\n",
       " 'lagian',\n",
       " 'ucap',\n",
       " 'belumlah',\n",
       " 'tersebutlah',\n",
       " 'kalaupun',\n",
       " 'tunjuk',\n",
       " 'tak',\n",
       " 'akankah',\n",
       " 'didatangkan',\n",
       " 'tempat',\n",
       " 'setibanya',\n",
       " 'mendatang',\n",
       " 'dulu',\n",
       " 'untuk',\n",
       " 'digunakan',\n",
       " 'andalah',\n",
       " 'berikan',\n",
       " 'dikatakan',\n",
       " 'menunjukkan',\n",
       " 'sebelum',\n",
       " 'dialah',\n",
       " 'sesampai',\n",
       " 'memintakan',\n",
       " 'sepanjang',\n",
       " 'dengan',\n",
       " 'diberikan',\n",
       " 'selalu',\n",
       " 'rasanya',\n",
       " 'terasa',\n",
       " 'agar',\n",
       " 'aku',\n",
       " 'kemungkinan',\n",
       " 'melihatnya',\n",
       " 'perlukah',\n",
       " 'seluruh',\n",
       " 'diungkapkan',\n",
       " 'sekiranya',\n",
       " 'menanya',\n",
       " 'dahulu',\n",
       " 'manalagi',\n",
       " 'baru',\n",
       " 'diucapkan',\n",
       " 'masih',\n",
       " 'mungkin',\n",
       " 'bakal',\n",
       " 'kapanpun',\n",
       " 'dia',\n",
       " 'sebagai',\n",
       " 'memastikan',\n",
       " 'pun',\n",
       " 'pastilah',\n",
       " 'tapi',\n",
       " 'telah',\n",
       " 'bulan',\n",
       " 'secukupnya',\n",
       " 'menyebutkan',\n",
       " 'hari',\n",
       " 'jadi',\n",
       " 'ditujukan',\n",
       " 'dijelaskan',\n",
       " 'kamilah',\n",
       " 'semampu',\n",
       " 'memang',\n",
       " 'menyeluruh',\n",
       " 'kelamaan',\n",
       " 'demikianlah',\n",
       " 'kebetulan',\n",
       " 'rupanya',\n",
       " 'tiba',\n",
       " 'dirinya',\n",
       " 'seterusnya',\n",
       " 'semacam',\n",
       " 'diingatkan',\n",
       " 'sudahlah',\n",
       " 'dapat',\n",
       " 'dibuat',\n",
       " 'setiba',\n",
       " 'menginginkan',\n",
       " 'memisalkan',\n",
       " 'saat',\n",
       " 'kiranya',\n",
       " 'pasti',\n",
       " 'ini',\n",
       " 'ialah',\n",
       " 'menuju',\n",
       " 'tertentu',\n",
       " 'kedua',\n",
       " 'meminta',\n",
       " 'jumlah',\n",
       " 'sesegera',\n",
       " 'dijelaskannya',\n",
       " 'meskipun',\n",
       " 'sajalah',\n",
       " 'entah',\n",
       " 'selamanya',\n",
       " 'berlainan',\n",
       " 'nyatanya',\n",
       " 'betulkah',\n",
       " 'beginian',\n",
       " 'terdiri',\n",
       " 'harusnya',\n",
       " 'setidaknya',\n",
       " 'mengingat',\n",
       " 'semuanya',\n",
       " 'dimaksudkan',\n",
       " 'itu',\n",
       " 'kesampaian',\n",
       " 'umumnya',\n",
       " 'bekerja',\n",
       " 'tentu',\n",
       " 'belum',\n",
       " 'mempersoalkan',\n",
       " 'tanyakan',\n",
       " 'wah',\n",
       " 'terlalu',\n",
       " 'ke',\n",
       " 'benarkah',\n",
       " 'dari',\n",
       " 'kapan',\n",
       " 'melakukan',\n",
       " 'sepantasnyalah',\n",
       " 'bertutur',\n",
       " 'balik',\n",
       " 'dimintai',\n",
       " 'inikah',\n",
       " 'diingat',\n",
       " 'guna',\n",
       " 'dimaksud',\n",
       " 'sepertinya',\n",
       " 'cukuplah',\n",
       " 'tengah',\n",
       " 'kinilah',\n",
       " 'mengapa',\n",
       " 'berturut-turut',\n",
       " 'per',\n",
       " 'olehnya',\n",
       " 'dikatakannya',\n",
       " 'berlalu',\n",
       " 'hendaknya',\n",
       " 'tidaklah',\n",
       " 'ikut',\n",
       " 'mendapat',\n",
       " 'macam',\n",
       " 'amat',\n",
       " 'pak',\n",
       " 'sebut',\n",
       " 'akhiri',\n",
       " 'apabila',\n",
       " 'ingin',\n",
       " 'ditunjuk',\n",
       " 'mengakhiri',\n",
       " 'pentingnya',\n",
       " 'akhirnya',\n",
       " 'berupa',\n",
       " 'bermacam-macam',\n",
       " 'melalui',\n",
       " 'keduanya',\n",
       " 'jelaslah',\n",
       " 'besar',\n",
       " 'lebih',\n",
       " 'sebaik-baiknya',\n",
       " 'itukah',\n",
       " 'saja',\n",
       " 'mengerjakan',\n",
       " 'setidak-tidaknya',\n",
       " 'tepat',\n",
       " 'yaitu',\n",
       " 'kembali',\n",
       " 'justru',\n",
       " 'nanti',\n",
       " 'bahkan',\n",
       " 'selanjutnya',\n",
       " 'selain',\n",
       " 'ingat',\n",
       " 'menyangkut',\n",
       " 'pertama',\n",
       " 'sekalipun',\n",
       " 'ia',\n",
       " 'berujar',\n",
       " 'diri',\n",
       " 'atau',\n",
       " 'jawaban',\n",
       " 'menanyai',\n",
       " 'sebagian',\n",
       " 'karenanya',\n",
       " 'enggaknya',\n",
       " 'entahlah',\n",
       " 'memerlukan',\n",
       " 'sampaikan',\n",
       " 'sendirian',\n",
       " 'berikutnya',\n",
       " 'bermaksud',\n",
       " 'sekadarnya',\n",
       " 'sini',\n",
       " 'dua',\n",
       " 'begini',\n",
       " 'bersama',\n",
       " 'kapankah',\n",
       " 'saling',\n",
       " 'memperlihatkan',\n",
       " 'lamanya',\n",
       " 'dimaksudnya',\n",
       " 'kelima',\n",
       " 'nah',\n",
       " 'panjang',\n",
       " 'tentunya',\n",
       " 'seperlunya',\n",
       " 'dikerjakan',\n",
       " 'ungkap',\n",
       " 'dilalui',\n",
       " 'jadilah',\n",
       " 'luar',\n",
       " 'terjadi',\n",
       " 'sudahkah',\n",
       " 'didapat',\n",
       " 'semampunya',\n",
       " 'setempat',\n",
       " 'mungkinkah',\n",
       " 'sebesar',\n",
       " 'kini',\n",
       " 'cukupkah',\n",
       " 'sebegitu',\n",
       " 'soalnya',\n",
       " 'semata-mata',\n",
       " 'sampai',\n",
       " 'kecil',\n",
       " 'beginikah',\n",
       " 'mendapatkan',\n",
       " 'mempertanyakan',\n",
       " 'terjadilah',\n",
       " 'mengungkapkan',\n",
       " 'tentang',\n",
       " 'bawah',\n",
       " 'kala',\n",
       " 'biasa',\n",
       " 'rata',\n",
       " 'sebutnya',\n",
       " 'apalagi',\n",
       " 'benarlah',\n",
       " 'berkeinginan',\n",
       " 'sejenak',\n",
       " 'sepihak',\n",
       " 'siapapun',\n",
       " 'demi',\n",
       " 'wong',\n",
       " 'berapapun',\n",
       " 'kitalah',\n",
       " 'mengatakan',\n",
       " 'jelas',\n",
       " 'berakhirnya',\n",
       " 'hendaklah',\n",
       " 'sepantasnya',\n",
       " 'dimisalkan',\n",
       " 'mula',\n",
       " 'sekali-kali',\n",
       " 'disebutkannya',\n",
       " 'harus',\n",
       " 'haruslah',\n",
       " 'pernah',\n",
       " 'jelasnya',\n",
       " 'kepadanya',\n",
       " 'seketika',\n",
       " 'amatlah',\n",
       " 'sedikitnya',\n",
       " 'diperlukannya',\n",
       " 'menjawab',\n",
       " 'tiga',\n",
       " 'tentulah',\n",
       " 'berapakah',\n",
       " 'bersama-sama',\n",
       " 'masihkah',\n",
       " 'perlu',\n",
       " 'bukannya',\n",
       " 'saatnya',\n",
       " 'ada',\n",
       " 'misalnya',\n",
       " 'kelihatannya',\n",
       " 'mengibaratkan',\n",
       " 'hendak',\n",
       " 'sesaat',\n",
       " 'asalkan',\n",
       " 'sekali',\n",
       " 'bolehkah',\n",
       " 'disini',\n",
       " 'pula',\n",
       " 'suatu',\n",
       " 'diantara',\n",
       " 'terkira',\n",
       " 'toh',\n",
       " 'seperti',\n",
       " 'kalau',\n",
       " 'dilakukan',\n",
       " 'dipunyai',\n",
       " 'bertanya',\n",
       " 'sebaliknya',\n",
       " 'segala',\n",
       " 'menegaskan',\n",
       " 'rasa',\n",
       " 'ibu',\n",
       " 'tuturnya',\n",
       " 'beri',\n",
       " 'belakang',\n",
       " 'tiba-tiba',\n",
       " 'makanya',\n",
       " 'berjumlah',\n",
       " 'masing-masing',\n",
       " 'bagaimanakah',\n",
       " 'sekaligus',\n",
       " 'jawabnya',\n",
       " 'keseluruhan',\n",
       " 'adanya',\n",
       " 'ditandaskan',\n",
       " 'sendirinya',\n",
       " 'turut',\n",
       " 'wahai',\n",
       " 'usai',\n",
       " 'berada',\n",
       " 'awalnya',\n",
       " 'bagaimanapun',\n",
       " 'berlebihan',\n",
       " 'manakala',\n",
       " 'tiap',\n",
       " 'yang',\n",
       " 'memberi',\n",
       " 'inilah',\n",
       " 'jangankan',\n",
       " 'katakan',\n",
       " 'atas',\n",
       " 'secara',\n",
       " 'bilakah',\n",
       " 'jelaskan',\n",
       " 'tadinya',\n",
       " 'dijawab',\n",
       " 'tidak',\n",
       " 'menjelaskan',\n",
       " 'berkali-kali',\n",
       " 'disampaikan',\n",
       " 'itulah',\n",
       " 'pihaknya',\n",
       " 'agak',\n",
       " 'sesama',\n",
       " 'melihat',\n",
       " 'terakhir',\n",
       " 'berapalah',\n",
       " 'sudah',\n",
       " 'sebuah',\n",
       " 'teringat-ingat',\n",
       " 'sendiri',\n",
       " 'janganlah',\n",
       " 'supaya',\n",
       " 'padanya',\n",
       " 'diakhiri',\n",
       " 'sebegini',\n",
       " 'datang',\n",
       " 'seluruhnya',\n",
       " 'dipastikan',\n",
       " 'sempat',\n",
       " 'menanti',\n",
       " 'begitupun',\n",
       " 'cuma',\n",
       " 'berlangsung',\n",
       " 'keterlaluan',\n",
       " 'dipergunakan',\n",
       " 'kata',\n",
       " 'bukanlah',\n",
       " 'malahan',\n",
       " 'sesudah',\n",
       " 'seringnya',\n",
       " 'setinggi',\n",
       " 'misalkan',\n",
       " 'memungkinkan',\n",
       " 'hingga',\n",
       " 'terlihat',\n",
       " 'sambil',\n",
       " 'berarti',\n",
       " 'memihak',\n",
       " 'meyakinkan',\n",
       " 'menyatakan',\n",
       " 'disebutkan',\n",
       " 'siapa',\n",
       " 'dimulailah',\n",
       " 'lanjut',\n",
       " 'tampaknya']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS.STOP_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '.', 'PENDAHULUAN', 'Bahasa', 'isyarat', 'merupakan', 'hal', 'yang', 'sangat', 'penting', 'bagi', 'suatu', 'kelompok', 'masyarakat', ',', 'yaitu', 'masyarakat', 'bisu', 'atau', 'tuli', '.', 'Untuk', 'masyarakat', 'yang', 'bisu', 'atau', 'tuli', ',', 'bahasa', 'isyarat', 'adalah', 'metode', 'terpenting', 'untuk', 'berkomunikasi', '.', 'Tanpa', 'adanya', 'bahasa', 'isyarat', ',', 'akan', 'sulit', 'bagi', 'mereka', 'yang', 'bisu', 'atau', 'tuli', 'untuk', 'dapat', 'menyatakan', 'maksud', 'atau', 'pikiran', 'mereka', '.', 'Untuk', 'dapat', 'berkomunik', 'asi', 'dengan', 'masyarakat', 'bisu', 'atau', 'tuli', ',', 'orang', 'yang', 'tidak', 'bisu', 'atau', 'tuli', 'memerlukan', 'bahasa', 'isyarat', 'tersebut', 'untuk', 'dapat', 'mengerti', 'maksud', 'atau', 'pikiran', 'mereka', 'yang', 'bisu', 'atau', 'tuli', '.', 'Setiap', 'orang', 'harus', 'memiliki', 'kemampuan', 'menggunakan', 'bahasa', 'isyarat', ',', 'agar', 'dapat', 'berko', 'munikasi', 'dengan', 'mereka', 'yang', 'bisu', 'atau', 'tuli', '.', 'Bahasa', 'isyarat', 'diekspresikan', 'menggunakan', 'tangan', ',', 'lengan', ',', 'serta', 'wajah', 'dan', 'dimengerti', 'menggunakan', 'mata', '.', 'Pembuatan', 'sistem', 'klasifikasi', 'bahasa', 'isyarat', 'sebelumnya', 'pernah', 'dilakukan', 'oleh', 'yang', 'membuat', 'asisten', 'virtual', 'untuk', 'bahasa', 'isyarat', 'menggunakan', 'deep', 'learning', 'dan', 'tensorflow', '.', 'Kesimpulan', 'dari', 'penelitian', 'ini', 'adalah', 'untuk', 'dapat', 'mendeteksi', 'bahasa', 'isyarat', ',', 'diperlukan', 'dataset', 'tertentu', 'untuk', 'setiap', 'bentuk', 'bahasa', 'isyarat', '.', 'Hal', 'ini', 'dikarenakan', 'terdapat', 'banyak', 'bentuk', 'bahasa', 'isyarat', 'di', 'dunia', ',', 'sehingga', 'untuk', 'dapat', 'mendeteksi', 'bahasa', 'isyarat', 'yang', 'ada', 'pada', 'regional', 'tertentu', ',', 'diperlukan', 'dataset', 'bahasa', 'isyarat', 'dari', 'lokasi', 'tersebut', '.', 'Selain', 'itu', ',', 'diperlukan', 'pula', 'latar', 'belakang', 'yang', 'mendukun', 'g', 'ketika', 'mengambil', 'gambar', ',', 'sehingga', 'tidak', 'dapat', 'digunakan', 'di', 'sembarang', 'tempat', '.', 'Penelitian', 'ini', 'lebih', 'memfokuskan', 'terhadap', 'pembuatan', 'aplikasinya', ',', 'sehingga', 'tidak', 'terlalu', 'menunjukkan', 'terhadap', 'akurasi', 'atau', 'performa', 'yang', 'lebih', 'mendalam', '.', 'Penelitian', 'lain', 'yang', 'mend', 'alami', 'performa', 'dari', 'model', 'deep', 'learning', '-nya', 'yaitu', 'oleh', 'tentang', 'klasifikasi', 'wajah', 'dan', 'penelitian', 'oleh', 'tentang', 'deteksi', 'citra', 'Covid', '-', '19', '.', 'Kedua', 'penelitian', 'ini', 'tidak', 'melakukan', 'klasifikasi', 'terhadap', 'bahasa', 'isyarat', ',', 'teta', 'pi', 'metode', 'untuk', 'mendapatkan', 'performa', 'yang', 'terbaik', 'dijadikan', 'penulis', 'sebagai', 'referensi', '.', 'Kesimpulan', 'dari', 'penelitian', 'kedua', 'adalah', 'untuk', 'dapat', 'mendeteksi', 'wajah', ',', 'ada', 'sangat', 'banyak', 'elemen', 'yang', 'perlu', 'diperhatikan', 'seperti', 'cahaya', ',', 'pose', ',', 'angle', 'atau', 'posisi', 'kamera', ',', 'da', 'n', 'lainnya', '.', 'Tidak', 'akan', 'mudah', 'untuk', 'dapat', 'mendapatkan', 'hasil', 'yang', 'sempurna', ',', 'tetapi', 'CNN', 'mampu', 'mendapatkan', 'hasil', 'yang', 'baik', 'dikarenakan', 'pembelajaran', 'fiturnya', 'yang', 'kuat', ',', 'sehingga', 'mampu', 'bertahan', 'pada', 'lingkungan', 'yang', 'kompleks', '.', 'Hal', 'yang', 'sama', 'juga', 'dapat', 'diaplikasikan', 'terhadap', 'bahasa', 'isyarat', ',', 'sebagaimana', 'disebutkan', 'pada', 'kesimpulan', 'penelitian', 'pertama', '.', 'Kesimpulan', 'dari', 'penelitian', 'ketiga', 'adalah', 'X', '-Ray', 'serta', 'CT', '-', 'Scan', 'yang', 'termasuk', 'kepada', 'radiografi', 'dada', 'sangatlah', 'membantu', 'untuk', 'mendeteksi', 'penyakit', '-', 'penyakit', ',', 'dan', 'penelitian', 'men', 'ggunakan', 'Transfer', 'Learning', 'dari', 'PyTorch', 'tadi', 'mendapatkan', 'hasil', 'yang', 'memuaskan', ',', 'dengan', 'akurasi', 'sebesar', '97,78', '.', 'Hasil', 'ini', 'sangat', 'memuaskan', 'dan', 'menjadikan', 'penulis', 'tertarik', 'pada', 'metode', 'yang', 'digunakan', 'untuk', 'dicoba', 'diberikan', 'pada', 'aplikasi', 'rekognisi', 'bahasa', 'isyara', 't.', 'Penelitian', 'terakhir', 'adalah', 'tentang', 'penggunaan', 'metode', 'Spatial', 'Transformer', 'dan', 'optimisasi', 'stokastik', 'pada', 'rekognisi', 'rambu', 'lalu', 'lintas', 'oleh', '.', 'Penelitian', 'ini', 'menggunakan', 'metode', 'Spatial', 'Transformer', 'dan', 'mampu', 'mendapatkan', 'akurasi', 'sebe', 'sar', '99,71', 'pada', 'dataset', 'dengan', 'jumlah', 'data', 'uji', 'sebanyak', '12.630', '.', 'Hasil', 'ini', 'menunjukkan', 'kalau', 'metode', 'Spatial', 'Transformer', 'pantas', 'untuk', 'digunakan', 'untuk', 'mencoba', 'meningkatkan', 'akurasi', 'dari', 'penelitian', '.', 'Oleh', 'karena', 'itu', ',', 'penulis', 'mengusulkan', 'dikembangkan', 'sistem', 'reko', 'gnisi', 'citra', 'digital', 'untuk', 'dapat', 'mengenali', 'bahasa', 'isyarat', 'tersebut', '.', 'Dengan', 'menggunakan', 'metode', 'Convolutional', 'Neural', 'Network', '(', 'CNN', ')', 'yang', 'merupakan', 'bagian', 'dari', 'Deep', 'Learning', 'atau', 'Machine', 'Learning', 'dan', 'dengan', 'metode', 'Spatial', 'Transformer', ',', 'sistem', 'akan', 'mengenali', 'pose', 'atau', 'bentuk', 'dari', 'citra', 'bahasa', 'isyarat', 'yang', 'dimasukkan', ',', 'dan', 'memberikan', 'luaran', 'yang', 'sesuai', 'dengan', 'maksud', 'dari', 'pose', 'atau', 'bentuk', 'dari', 'citra', 'bahasa', 'isyarat', 'tersebut', '.', '2', '.', 'METODE', 'PENELITIAN', '2.1', 'Data', 'Penelitian', 'Data', 'yang', 'digunakan', 'untuk', 'training', 'model', 'adalah', 'data', 'sekunder', 'yang', 'didapat', 'secara', 'open', '-', 'source', 'dari', 'berbagai', 'halaman', 'web', 'tertentu', 'yang', 'menyediakan', 'dataset', '-dataset', 'secara', 'gratis', 'dan', 'legal', '.', 'Untuk', 'penelitian', 'ini', ',', 'digunakan', 'dataset', '-dataset', 'dengan', 'tema', 'bahasa', 'isyarat', '.', 'Adapun', 'situs', 'yang', 'menyediakan', 'set', 'data', 'tersebut', 'bernama', 'Kaggle', '.', 'Data', 'sekunder', 'yang', 'akan', 'digunakan', 'ada', 'dua', 'macam', ',', 'yaitu', 'data', 'bahasa', 'isyarat', 'dengan', 'background', 'hitam', 'dan', 'data', 'bahasa', 'isyarat', 'dengan', 'background', 'putih', '.', 'Data', 'dengan', 'background', 'hitam', 'merupakan', 'data', 'publik', 'dari', 'situs', 'Kaggle', 'sebagaimana', 'ditunjukkan', 'pada', 'data', 'dengan', 'background', 'putih', 'juga', 'merupakan', 'data', 'publik', 'dari', 'situs', 'Kaggle', 'sebagaimana', 'ditunjukkan', 'pada', 'hitam', 'memiliki', 'jumlah', 'sebanyak', '70', 'gambar', ',', 'sedangkan', 'dataset', 'background', 'putih', 'memiliki', 'jumlah', 'sebanyak', '21', 'gambar', '.', 'Selain', 'data', 'sekunder', 'dari', 'internet', ',', 'digunakan', 'pula', 'data', 'yang', 'diambil', 'oleh', 'penulis', 'secara', 'pribadi', '.', 'Pengambilan', 'data', 'pribadi', 'ini', 'dilakukan', 'untuk', 'Mahardika', ',', 'dkk', ',', 'Sistem', 'Rekognisi', 'Citra', 'Digital', '1161', 'menguji', 'adanya', 'perbedaan', 'hasil', 'pada', 'pengujian', 'apabila', 'menggunakan', 'data', 'dengan', 'background', 'yang', 'berbeda', 'dan', 'mengetahui', 'seberapa', 'besar', 'pengaruh', 'yang', 'dimiliki', 'oleh', 'background', 'tersebut', 'terhadap', 'keseluruhan', 'percobaan', ',', 'sebagaimana', 'permasalahan', 'ini', 'disebutkan', 'sebelumnya', 'oleh', '.', 'Data', 'gamb', 'ar', 'yang', 'diambil', 'akan', 'memiliki', 'pose', 'dan', 'bentuk', 'bahasa', 'isyarat', 'yang', 'sama', 'dengan', 'data', 'sekunder', 'dari', 'internet', 'tersebut', ',', 'tetapi', 'akan', 'memiliki', 'background', 'yang', 'bervariasi', '.', 'Data', 'yang', 'diambil', 'memiliki', 'dua', 'macam', 'background', ',', 'yaitu', 'data', 'dengan', 'background', 'karpet', 'bermot', 'if', 'ditunjukkan', 'pada', 'Gambar', '3', 'dan', 'data', 'dengan', 'background', 'pemandangan', 'pagi', 'ditunjukkan', 'pada', 'background', 'karpet', 'memiliki', 'jumlah', 'sebanyak', '54', 'gambar', ',', 'sedangkan', 'dataset', 'background', 'pemandangan', 'memiliki', 'jumlah', 'sebanyak', '40', 'gambar', '.', 'Data', 'uji', 'yang', 'akan', 'digunakan', 'adalah', 'dataset', 'yang', 'menggabungkan', 'keempat', 'dataset', 'yang', 'digunakan', 'untuk', 'training', 'dan', 'validation', '.', 'Selain', 'itu', ',', 'ditambahkan', 'pula', 'tiga', 'set', 'gambar', 'yang', 'tidak', 'berada', 'dalam', 'data', 'training', 'maupun', 'validation', ',', 'yaitu', 'dataset', 'dengan', 'background', 'bunga', ',', 'dataset', 'dengan', 'background', 'langit', 'merah', ',', 'dan', 'dataset', 'dengan', 'background', 'gunung', '.', 'Penyusunan', 'dataset', 'uji', 'per', 'alfabet', 'adalah', 'satu', 'gambar', 'dari', 'setiap', 'dataset', 'background', 'hitam', ',', 'putih', ',', 'karpet', ',', 'dan', 'pemandangan', 'ditambah', 'tiga', 'gambar', 'dari', 'setiap', 'dataset', 'background', 'bunga', ',', 'langit', 'merah', ',', 'dan', 'gunung', 'sebagaimana', 'ditunjukkan', 'pada', 'gambar', 'unt', 'uk', 'setiap', 'alfabet', ',', 'menjadikan', '338', 'total', 'gambar', 'data', 'uji', '.', 'Pada', 'perancangan', 'model', 'Convolutional', 'Neural', 'Network', 'dari', 'sistem', 'rekognisi', 'citra', 'digital', 'bahasa', 'isyarat', 'diawali', 'dengan', 'adanya', 'pemrosesan', 'awal', 'dengan', 'mengubah', 'di', 'mensi', 'dari', 'data', 'dan', 'juga', 'mengkonversi', 'data', 'menjadi', 'berbentuk', 'Tensor', 'agar', 'dapat', 'diberikan', 'sebagai', 'input', 'kepada', 'model', 'CNN', '.', 'Setelah', 'dilakukan', 'pemrosesan', 'awal', ',', 'dibuatlah', 'arsitektur', 'dari', 'model', 'CNN', 'yang', 'akan', 'melakukan', 'pembelajaran', 'mendalam', 'atau', 'Deep', 'Learning', '.', 'Penentuan', 'Arsitektur', 'dari', 'model', 'CNN', 'ini', 'dilakukan', 'dengan', 'memasukan', 'lapisan', '-lapisan', 'neural', 'network', 'yang', 'terbaik', 'untuk', 'data', 'yang', 'digunakan', '.', 'Dalam', 'arsitektur', 'model', 'akan', 'ditambahkan', 'modul', 'Spatial', 'Transformer', ',', 'yang', 'di', 'tambahkan', 'sebelum', 'bagian', 'utama', 'dari', 'neural', 'network', '.', 'Data', 'akan', 'melewati', 'lapisan', '-lapisan', 'Spatial', 'Transformer', 'terlebih', 'dahulu', 'sebelum', 'memasuki', 'bagian', 'neural', 'network', 'utama', '.', 'Setelah', 'arsitektur', 'dari', 'model', 'CNN', 'telah', 'ditentukan', ',', 'dilakukan', 'proses', 'pelatihan', 'atau', 'Training', 'pada', 'dataset', '.', 'Training', 'atau', 'pelatihan', 'dilakukan', 'dengan', 'tujuan', 'memberikan', 'model', 'pengetahuan', 'yang', 'dibutuhkannya', 'untuk', 'dapat', 'mengklasifikasikan', 'dan', 'merekognisi', 'data', 'digital', '.', 'Terakhir', ',', 'dilakukan', 'pengujian', 'dengan', 'data', 'uji', 'untuk', 'menentukan', 'seberapa', 'baik', 'ki', 'nerja', 'model', 'dalam', 'pekerjaan', 'mengklasifikasi', 'dan', 'merekognisi', 'dataset', 'digital', 'tersebut', '.', 'Apabila', 'kinerja', 'model', 'masih', 'kurang', 'baik', ',', 'maka', 'perlu', 'dilakukan', 'perbaikan', 'atau', 'Tweaking', 'pada', 'model', 'dengan', 'tujuan', 'mendapatkan', 'hasil', 'yang', 'lebih', 'baik', '.', 'Pada', 'penelitian', 'ini', ',', 'tar', 'get', 'yang', 'dicari', 'adalah', 'nilai', 'akurasi', 'yang', 'tinggi', '.', 'Alur', 'perancangan', 'model', 'ini', 'dilakukan', 'sebagaimana', 'pada', '1162', 'Jurnal', 'Teknologi', 'Informasi', 'dan', 'Ilmu', 'Komputer', '(', 'JTIIK', ')', ',', 'Vol', '.', '11', ',', 'No', '.', '6', ',', 'Desember', '2024', ',', 'hlm.1159', '-1168', 'Arsitektur', 'yang', 'akan', 'digunakan', 'dalam', 'penelitian', 'sistem', 'rekognisi', 'citra', 'digital', 'bahasa', 'isyarat', 'menggunakan', 'Convolutional', 'Neural', 'Network', 'akan', 'menggunakan', 'berbagai', 'pretrained', 'weights', 'yang', 'telah', 'disediakan', 'oleh', 'library', 'PyTorch', '.', 'Contoh', 'model', 'dan', 'weights', '-nya', 'yang', 'disediakan', 'oleh', 'library', 'PyTorch', 'yaitu', 'ResNet', ',', 'AlexNet', ',', 'atau', 'EfficientNet', '.', 'Model', 'dan', 'weights', '-nya', 'sudah', 'dilatih', 'sebelumnya', 'menggunakan', 'dataset', 'ImageNet', '-1k', 'dengan', 'tujuan', 'membantu', 'meningkatkan', 'akurasi', 'dari', 'model', '.', 'Selain', 'menggunakan', 'pretrained', 'weights', ',', 'arsitektur', 'model', 'yang', 'akan', 'digunakan', 'juga', 'akan', 'memiliki', 'penambahan', 'Spatial', 'Transformer', 'berupa', 'lapis', 'an', 'Localization', ',', 'fully', 'connected', ',', 'dan', 'sampler', '.', 'Penambahan', 'Spatial', 'Transformer', 'diposisikan', 'sebelum', 'bagian', 'utama', 'arsitektur', ',', 'tepatnya', 'di', 'awal', 'arsitektur', '.', 'Data', 'akan', 'melewati', 'lapisan', 'Spatial', 'Transformer', 'terlebih', 'dahulu', 'untuk', 'ditransformasi', 'sebelum', 'memasuki', 'lap', 'isan', 'utama', 'dari', 'Convolutional', 'Neural', 'Network', '.', '3', '.', 'DASAR', 'TEORI', '3.1', 'Bahasa', 'Isyarat', 'Bahasa', 'isyarat', 'diekspresikan', 'menggunakan', 'tangan', ',', 'lengan', ',', 'serta', 'wajah', 'dan', 'dimengerti', 'menggunakan', 'mata', '.', 'Bahasa', 'isyarat', 'juga', 'memiliki', 'struktur', 'dan', 'peraturan', 'untuk', 'berbagai', 'kata', ',', 'kalimat', ',', 'atau', 'percakapan', ',', 'sebagaimana', 'bahasa', 'lain', 'pada', 'umumnya', '.', 'Sebagian', 'besar', 'percakapan', 'pada', 'bahasa', 'isyarat', 'dilakukan', 'dengan', 'menggunakan', 'tangan', ',', 'dimana', 'tangan', 'beserta', 'jari', '-', 'jarinya', 'digunakan', 'untuk', 'membentuk', 'pose', 'atau', 'bentuk', 'yang', 'unik', ',', 's', 'ehingga', 'dapat', 'dikenali', 'sebagai', 'maksud', 'tertentu', '.', 'Pada', 'negara', 'tertentu', ',', 'bahasa', 'isyarat', 'yang', 'dikembangkan', 'dapat', 'berbeda', 'dengan', 'bahasa', 'isyarat', 'dari', 'negara', 'lain', '.', 'Contoh', 'dari', 'bahasa', 'isyarat', 'yang', 'ada', 'pada', 'suatu', 'negara', 'tertentu', 'yaitu', 'American', 'Sign', 'Language', '(', 'ASL', ')', 'y', 'ang', 'merupakan', 'bahasa', 'isyarat', 'populer', 'yang', 'berasal', 'dari', 'Amerika', 'Serikat', '.', 'Selain', 'itu', ',', 'terdapat', 'pula', 'bahasa', 'isyarat', 'dari', 'Inggris', 'yaitu', 'British', 'Sign', 'Language', '(', 'BSL', ')', '.', 'Selain', 'kedua', 'negara', 'tersebut', ',', 'terdapat', 'Australian', 'Sign', 'Language', '(', 'Auslan', ')', ',', 'Italian', 'Sign', 'Language', '(', 'LIS', ')', ',', 'Japanese', 'Sign', 'Language', '(', 'JSL', ')', ',', 'dan', 'lainnya', '.', '3.2', 'Convolutional', 'Neural', 'Network', 'Convolutional', 'Neural', 'Network', '(', 'CNN', ')', 'adalah', 'jaringan', 'saraf', 'neuron', 'lapisan', 'banyak', 'yang', 'tidak', 'sepenuhnya', 'tersambung', '.', 'CNN', 'berisi', 'lapisan', 'convolutional', ',', 'lapisan', 'sampling', 'atau', 'sub', '-', 'sampling', ',', 'dan', 'lapisan', 'tersembunyi', 'yang', 'masih', 'berupa', 'lapisan', 'convolutional', 'atau', 'sampling', '.', 'Setiap', 'lapisan', 'convolution', 'pada', 'CNN', 'diikuti', 'dengan', 'lapisan', 'penghitung', 'untuk', 'dilakukan', 'pemerataan', 'dan', 'ekstraksi', '.', 'Adapun', 'perhitungan', 'yang', 'dilakukan', 'pada', 'lapisan', 'convolutional', 'adalah', 'sebagai', 'berikut', 'H(x', ',', 'y', ')', 'b', 'F(x', ',', 'y', ')', 'G(x', ',', 'y', ')', 'b', 'F(j', ',', 'k', ')', 'k', '(', ')', 'j', '(', ')', 'G(x', 'j', ',', 'y', 'k', ')', '(', '1', ')', 'Keterangan', 'F', 'Filter', 'Lapisan', 'G', 'Input', 'feature', 'map', 'H', 'Output', 'feature', 'map', 'b', 'Bias', 'x', 'Sumbu', 'X', 'pada', 'data', 'dan', 'filter', 'y', 'Sumbu', 'Y', 'pada', 'data', 'dan', 'filter', 'j', 'Increment', 'untuk', 'sumbu', 'X', 'k', 'Increment', 'untuk', 'sumbu', 'Y', 'Suatu', 'input', 'feature', 'map', 'G', 'dengan', 'nilai', 'G(x', ',', 'y', ')', 'akan', 'dimasukkan', 'ke', 'dalam', 'lapisan', 'konvolusi', '.', 'Kernel', 'F', 'yang', 'berada', 'di', 'dalam', 'lapisan', 'konvolusi', 'memiliki', 'nilai', 'F(x', ',', 'y', ')', 'untuk', 'menjadi', 'pengali', 'dari', 'input', 'tersebut', '.', 'Untuk', 'setiap', 'j', 'pada', 'sumbu', 'x', 'dan', 'setiap', 'k', 'pada', 'sumbu', 'y', ',', 'nilai', 'input', 'G(x', 'j', ',', 'y', 'k', ')', 'akan', 'dikalikan', 'dengan', 'nilai', 'kernel', 'F(j', ',', 'k', ')', 'dan', 'hasilnya', 'akan', 'dijumlahkan', 'sesuai', 'dengan', 'ukuran', 'data', 'input', 'pada', 'nilai', 'j', 'dan', 'k.', 'Hasil', 'dari', 'total', 'penjumlahan', 'tersebut', 'akan', 'dijumlahkan', 'dengan', 'nilai', 'bias', 'b', 'untuk', 'menjadi', 'nilai', 'output', 'H(x', ',', 'y', ')', '.', 'Perhitungan', 'akan', 'dilanjutkan', 'ke', 'pixel', 'selanjutnya', 'pada', 'input', 'G', 'hingga', 'seluruh', 'pixel', 'pada', 'output', 'feature', 'map', 'H', 'mendapatkan', 'hasil', '.', '3.3', 'Transfer', 'Learning', 'Transfer', 'Learning', 'merupakan', 'salah', 'satu', 'teknik', 'dari', 'penggunaan', 'Deep', 'Learning', ',', 'dimana', 'model', 'yang', 'sebelumnya', 'telah', 'melewati', 'tahap', 'training', 'digunakan', 'kembali', 'untuk', 'mengekstrak', 'dan', 'tuning', 'lebih', 'lanjut', 'pada', 'model', 'lain', 'untuk', 'memperbaiki', 'akurasi', '.', 'Keuntungan', 'dari', 'penggunaan', 'teknik', 'Transfer', 'Learning', 'terletak', 'pada', 'penghematan', 'waktu', 'penjalanan', 'proses', 'training', 'serta', 'penghematan', 'resource', 'dikarenakan', 'me', 'nggunakan', 'data', 'yang', 'lebih', 'sedikit', '.', 'Teknik', 'ini', 'dapat', 'digunakan', 'untuk', 'mendeteksi', 'berbagai', 'macam', 'objek', '.', '3.4', 'Spatial', 'Transformer', 'Spatial', 'Transformer', 'merupakan', 'modul', 'yang', 'bisa', 'ditambahkan', 'ke', 'dalam', 'Convolutional', 'Neural', 'Network', 'yang', 'memungkinkan', 'manipulasi', 'spasial', 'data', 'di', 'dalam', 'jaringan', '.', 'Modul', 'yang', 'dapat', 'dibedakan', 'ini', 'dapat', 'dimasukkan', 'ke', 'dalam', 'arsitektur', 'Convolutional', 'Neural', 'Network', 'yang', 'sudah', 'ada', ',', 'memberikan', 'neural', 'network', 'kemampuan', 'untuk', 'secara', 'aktif', 'mentransformasikan', 'feature', 'map', 'secara', 'spasial', ',', 'tergantung', 'pada', 'feature', 'map', 'itu', 'sendiri', 'tanpa', 'pengawasan', 'pelatihan', 'tambahan', 'atau', 'modifikasi', 'pada', 'proses', 'pengoptimalan', '.', 'Tahapan', 'dari', 'Spatial', 'Transformer', 'digambarkan', 'pada', 'Mahardika', ',', 'dkk', ',', 'Sistem', 'Rekognisi', 'Citra', 'Digital', '1163', 'Pada', 'Gambar', '7', ',', 'mekanisme', 'Spatial', 'Transformer', 'dibagi', 'menjadi', 'tiga', 'bagian', ',', 'yaitu', 'jaringan', 'Localization', ',', 'Sampling', 'Grid', ',', 'dan', 'Sampler', '.', 'Jaringan', 'Localization', 'mengambil', 'feature', 'map', 'input', 'dan', 'mengeluarkan', 'parameter', 'transformasi', 'Teta', '(', 'θ', ')', 'yang', 'harus', 'diterapkan', 'pada', 'feature', 'map', 'melalui', 'sejumlah', 'hidden', 'layer', '.', 'Hasil', 'output', 'jaringan', 'Localization', 'berupa', 'parameter', 'transformasi', 'Teta', '(', 'θ', ')', 'akan', 'digunakan', 'untuk', 'membuat', 'Sampling', 'Grid', ',', 'yang', 'merupakan', 'sekumpulan', 'titik', 'di', 'mana', 'map', 'input', 'harus', 'diambil', 'sampelnya', 'untuk', 'menghasilkan', 'output', 'yang', 'telah', 'diubah', '.', 'Hal', 'ini', 'dilakukan', 'oleh', 'generator', 'grid', ',', 'yang', 'merupakan', 'komponen', 'Spatial', 'Transformer', 'yang', 'memiliki', 'fungsi', 'eksklusif', 'untuk', 'melakukan', 'transformasi', 'invers', 'dari', 'output', '.', 'Terakhir', ',', 'feature', 'map', 'dan', 'Sampling', 'Grid', 'yang', 'dihasilkan', 'oleh', 'Grid', 'Generator', 'diambil', 'sebagai', 'input', 'untuk', 'Sampler', ',', 'komponen', 'lain', 'dari', 'Spatial', 'Transformer', 'selain', 'Grid', 'generator', '.', 'Tujuan', 'dari', 'Sampler', 'adalah', 'untuk', 'menghasilkan', 'output', 'map', 'yang', 'di', '-sampling', 'dari', 'input', 'pada', 'titik', '-titik', 'grid', '.', 'Sampler', 'mengulangi', 'entri', 'grid', 'pengambilan', 'sampel', 'dan', 'mengekstrak', 'nilai', 'pixel', 'yang', 'sesuai', 'dari', 'input', 'map', 'menggunakan', 'interpolasi', 'bilinear', '.', 'Output', 'dari', 'ketiga', 'tahapan', 'Spatial', 'Transformer', 'tersebut', 'kemudian', 'akan', 'diteruskan', 'ke', 'jaringan', 'konvolusi', 'setelahnya', '.', 'xis', 'yis', 'τθ(Gi', ')', 'Aθ(xit', 'yit', '1', ')', 'θ1,1θ1,2θ1,3', 'θ2,1θ2,3θ2,3', '(', 'xit', 'yit', '1', ')', '(', '2', ')', 'Keterangan', 'τθ', 'Transformasi', 'Afin', '2D', 'Aθ', 'Gi', 'Grid', 'dari', 'Output', 'Feature', 'Map', 'Aθ', 'Matriks', 'Transformasi', 'Afin', 'θ', 'xis', 'Sumber', 'Kordinat', 'Sumbu', 'X', 'yis', 'Sumber', 'Kordinat', 'Sumbu', 'Y', 'xit', 'Target', 'Kordinat', 'Sumbu', 'X', 'yit', 'Target', 'Kordinat', 'Sumbu', 'Y', 'θ', 'Luaran', 'Localization', 'Kordinat', '(', 'xit', ',', 'yit', ')', 'adalah', 'target', 'kordinat', 'pada', 'titik', '-titik', 'grid', '(', 'Gi', ')', 'dan', 'berasal', 'dari', 'output', 'feature', 'map', '.', 'Kordinat', '(', 'xis', ',', 'yis', ')', 'adalah', 'sumber', 'kordinat', 'dari', 'input', 'feature', 'map', 'yang', 'menentukan', 'titik', 'sampel', '.', 'Output', 'dari', 'lapisan', 'Localization', 'yaitu', 'θ', 'menjadi', 'penentu', 'transformasi', 'target', ',', 'dan', 'mungkin', 'saja', 'mengambil', 'berbagai', 'transformasi', '.', 'Aθ', 'adalah', 'matriks', 'transformasi', 'afin', 'θ', '.', 'Transformasi', 'yang', 'didefinisikan', 'adalah', 'seperti', 'cropping', ',', 'translation', ',', 'rotation', ',', 'scale', ',', 'dan', 'skew', 'untuk', 'diterapkan', 'pada', 'input', 'feature', 'map', ',', 'dan', 'hanya', 'membutuhkan', '6', 'parameter', '(', '6', 'elemen', 'Aθ', ')', 'yang', 'diproduksi', 'oleh', 'lapisan', 'Localization', '.', '3.5', '.', 'Confusion', 'Matrix', 'Confusion', 'Matrix', 'adalah', 'salah', 'satu', 'metode', 'pengukuran', 'kinerja', 'untuk', 'masalah', 'klasifikasi', 'dalam', 'machine', 'learning', ',', 'di', 'mana', 'output', '-nya', 'dapat', 'berupa', 'dua', 'kelas', 'atau', 'lebih', '.', 'Confusion', 'Matrix', 'dapat', 'berupa', 'tabel', 'dengan', 'empat', 'macam', 'kombinasi', 'berbeda', 'dari', 'nilai', 'prediksi', 'dan', 'nilai', 'sebenarnya', '.', 'Keempat', 'macam', 'kombinasi', 'tersebut', 'adalah', 'True', 'Positive', '(', 'TP', ')', ',', 'False', 'Positive', '(', 'FP', ')', ',', 'True', 'Negative', '(', 'TN', ')', ',', 'dan', 'False', 'Negative', '(', 'FP', ')', '.', 'Positif', 'Sebenarnya', 'Negatif', 'Sebenarnya', 'Positif', 'Prediksi', 'True', 'Positive', 'False', 'Positive', 'Negatif', 'Prediksi', 'False', 'Negative', 'True', 'Negative', 'Keempat', 'kombinasi', 'yang', 'ditunjukkan', 'pada', 'Tabel', '1', 'dapat', 'digunakan', 'untuk', 'melakukan', 'perhitungan', 'metrik', '-metrik', 'untuk', 'mengevaluasi', 'hasil', 'prediksi', 'sistem', '.', 'Metrik', 'yang', 'digunakan', 'untuk', 'mengevaluasi', 'yaitu', 'Accuracy', 'atau', 'akurasi', ',', 'Precision', ',', 'Recall', ',', 'dan', 'F1', '-', 'Score', '.', 'Adapun', 'rumus', 'dari', 'setiap', 'metrik', 'tersebut', 'ditunjukkan', 'pada', 'persamaan', '-', 'persamaan', 'berikut', 'Accuracy', 'TP', 'TN', 'TP', 'FP', 'TN', 'FN', '(', '3', ')', 'Precision', 'TP', 'TP', 'FP', '(', '4', ')', 'Recall', 'TP', 'TP', 'FN', '(', '5', ')', 'F1', 'Score', '2', 'Precision', 'Recall', 'Precision', 'Recall', '(', '6', ')', 'Keterangan', 'TP', 'True', 'Positive', 'TN', 'True', 'Negative', 'FP', 'False', 'Positive', 'FN', 'False', 'Negative', 'Perhitungan', 'akurasi', 'dilakukan', 'dengan', 'membagi', 'seluruh', 'prediksi', 'yang', 'benar', '(', 'TP', 'TN', ')', 'oleh', 'keseluruhan', 'data', '(', 'TP', 'FP', 'TN', 'FN', ')', 'dan', 'digunakan', 'untuk', 'mengetahui', 'keefektifan', 'secara', 'menyeluruh', 'dari', 'sistem', '.', 'Perhitungan', 'Precision', 'digunakan', 'untuk', 'mengetahui', 'kesepakatan', 'kelas', 'label', 'data', 'dengan', 'label', 'positif', 'yang', 'diberikan', 'o', 'leh', 'sistem', ',', 'dengan', 'cara', 'membagi', 'nilai', 'True', 'Positive', '(', 'TP', ')', 'dan', 'penjumlahan', 'True', 'Positive', 'dan', 'False', 'Positive', '(', 'TP', 'FP', ')', '.', 'Perhitungan', 'Recall', 'digunakan', 'untuk', '1164', 'Jurnal', 'Teknologi', 'Informasi', 'dan', 'Ilmu', 'Komputer', '(', 'JTIIK', ')', ',', 'Vol', '.', '11', ',', 'No', '.', '6', ',', 'Desember', '2024', ',', 'hlm.1159', '-1168', 'mengetahui', 'keefektifan', 'dari', 'sistem', 'untuk', 'mengidentifikasi', 'label', 'yang', 'positif', ',', 'dilakukan', 'dengan', 'membagi', 'nilai', 'True', 'Positive', '(', 'TP', ')', 'dengan', 'penjumlahan', 'True', 'Positive', 'dan', 'False', 'Negative', '(', 'TP', 'FN', ')', '.', 'Perhitungan', 'F1', '-', 'Score', 'digunakan', 'untuk', 'mengeta', 'hui', 'hubungan', 'antara', 'data', 'dengan', 'label', 'positif', 'dan', 'data', 'yang', 'dilabelkan', 'positif', 'oleh', 'sistem', '.', '3.5', 'Flask', 'Flask', 'adalah', 'sebuah', 'kerangka', 'kerja', 'aplikasi', 'web', 'yang', 'memberikan', 'alat', ',', 'pustaka', ',', 'dan', 'teknologi', 'untuk', 'membuat', 'aplikasi', 'web', '.', 'Flask', 'meru', 'pakan', 'modul', 'python', 'untuk', 'membuat', 'aplikasi', 'berbasis', 'web', 'yang', 'cukup', 'mudah', 'untuk', 'digunakan', '.', 'Dengan', 'menggunakan', 'flask', ',', 'suatu', 'model', 'deep', 'learning', 'dapat', 'diintegrasikan', 'ke', 'dalam', 'aplikasi', 'web', 'untuk', 'dapat', 'digunakan', '.', '4', '.', 'HASIL', 'DAN', 'PEMBAHASAN', 'Pengujian', 'pertama', 'yang', 'akan', 'diuji', 'adalah', 'pengaturan', 'arsitektur', 'CNN', 'dengan', 'model', '-model', 'yang', 'memiliki', 'pretrained', 'weights', '.', 'Adapun', 'model', '-', 'model', 'yang', 'akan', 'diuji', 'yaitu', 'ResNet18', 'dan', 'ResNet50', ',', 'AlexNet', ',', 'dan', 'EfficientNet', 'B4', '.', 'Selain', 'arsitektur', 'CNN', ',', 'hal', 'lain', 'yang', 'akan', 'diuji', 'adalah', 'Hyperparameter', 'dari', 'proses', 'pelatihan', '.', 'Parameter', 'yang', 'akan', 'diuji', 'adalah', 'optimizer', 'dan', 'learning', 'rate', '.', 'Berbagai', 'optimizer', 'yang', 'akan', 'diuji', 'seperti', 'SGD', ',', 'RMSPr', 'op', ',', 'dan', 'Adam', '.', 'Sedangkan', 'untuk', 'learning', 'rate', ',', 'pengujian', 'hanya', 'akan', 'menguji', 'penggunaan', 'learning', 'rate', 'scheduler', 'untuk', 'menilai', 'keefektifan', 'scheduler', 'dalam', 'membantu', 'proses', 'training', '.', 'Setelah', 'didapat', 'model', 'dan', 'pengaturan', 'hyperparameter', 'yang', 'terbaik', ',', 'dilakukan', 'pen', 'gujian', 'penggunaan', 'pretrained', 'weights', 'dari', 'arsitektur', 'model', 'untuk', 'mencoba', 'menaikkan', 'hasil', 'akurasi', '.', 'Spatial', 'Transformer', 'juga', 'akan', 'diuji', 'coba', 'untuk', 'melihat', 'apakah', 'penggunaannya', 'mampu', 'membuat', 'akurasi', 'meningkat', '.', 'Terakhir', ',', 'setelah', 'didapatkan', 'hasil', 'yang', 'maksimum', 'dari', 'kombinasi', 'pengaturan', 'yang', 'terbaik', ',', 'dilakukan', 'uji', 'coba', 'secara', 'real', '-', 'time', '.', 'Pengujian', 'secara', 'real', '-', 'time', 'dilakukan', 'dengan', 'melakukan', 'export', 'terhadap', 'model', 'dengan', 'hasil', 'yang', 'terbaik', ',', 'lalu', 'diuji', 'dengan', 'gambar', 'nyata', 'yang', 'diambil', 'menggunakan', 'kamera', 'atau', 'webcam', '.', 'Pengujian', 'secara', 'real', '-', 'time', 'juga', 'akan', 'memiliki', 'variasi', 'terhadap', 'pengujiannya', ',', 'dimana', 'masing', '-masing', 'dari', 'keempat', 'dataset', 'akan', 'diuji', 'coba', 'melakukan', 'klasifikasi', 'secara', 'real', '-', 'time', 'terhadap', 'tiga', 'macam', 'latar', 'belakang', ',', 'yaitu', 'latar', 'belakang', 'putih', 'polos', ',', 'latar', 'belak', 'ang', 'hitam', 'polos', ',', 'dan', 'latar', 'belakang', 'abstrak', 'atau', 'bermacam', '-macam', 'warna', '.', 'Uji', 'coba', 'latar', 'belakang', 'abstrak', 'dilakukan', 'untuk', 'melihat', 'pengaruh', 'dari', 'variasi', 'warna', 'pada', 'latar', 'belakang', '.', 'Setelah', 'melihat', 'performa', 'dari', 'masing', '-', 'masing', 'dataset', ',', 'dilakukan', 'uji', 'coba', 'mengguna', 'kan', 'dataset', 'gabungan', 'dari', 'keempat', 'dataset', 'untuk', 'mencoba', 'mendapatkan', 'hasil', 'yang', 'terbaik', '.', 'Pengujian', 'model', ',', 'hyperparameter', ',', 'pretrained', 'weights', ',', 'dan', 'Spatial', 'Transformer', 'akan', 'menggunakan', 'akurasi', 'sebagai', 'metrik', 'utama', 'dengan', 'mencatat', 'juga', 'waktu', 'jalannya', 'proses', 'tr', 'aining', '.', 'Khusus', 'untuk', 'learning', 'rate', ',', 'ditambahkan', 'metrik', 'berupa', 'epoch', 'hingga', 'konvergen', 'untuk', 'menilai', 'seberapa', 'cepat', 'model', 'mampu', 'mencapai', 'titik', 'konvergen', 'pada', 'proses', 'pelatihan', '.', '4.1', 'Pengujian', 'Arsitektur', 'Model', 'Dalam', 'pengujian', 'ini', 'digunakan', 'empat', 'tipe', 'model', '.', 'ResNet1', '8', 'cukup', 'populer', 'di', 'kalangan', 'dataset', 'kecil', ',', 'tetapi', 'juga', 'layak', 'digunakan', 'pada', 'dataset', 'besar', '.', 'Selain', 'ResNet18', ',', 'model', 'populer', 'lain', 'yang', 'juga', 'digunakan', 'adalah', 'AlexNet', '.', 'ResNet50', 'juga', 'digunakan', 'untuk', 'membandingkan', 'dengan', 'tipe', 'sebelumnya', '.', 'Terakhir', ',', 'EfficientNet', 'B4', 'digunakan', 'karena', 'jumlah', 'trainable', 'parameter', '-nya', 'yang', 'tinggi', ',', 'tetapi', 'tidak', 'terlalu', 'besar', 'untuk', 'mencegah', 'overfitting', '.', 'Pengujian', 'dilakukan', 'dengan', 'menggunakan', 'Hyperparameter', 'yang', 'sama', ',', 'yaitu', 'optimizer', 'Adam', ',', 'learning', 'rate', '0.001', ',', 'dan', 'loss', 'Cross', 'Entropy', '.', 'Pengujian', 'ini', 'tidak', 'menggunakan', 'Spatial', 'Transformer', '.', 'Hasil', 'dari', 'pengujian', 'ditunjukkan', 'pada', 'Model', 'Akurasi', 'Waktu', 'Training', 'Train', 'Valid', 'ation', 'Test', 'ResNet18', '99,89', '100', '54,73', '3585s', 'AlexNet', '99,93', '100', '57,39', '3350s', 'ResNet50', '99,83', '100', '57,10', '4167s', 'Efficient', 'Net', 'B4', '99,96', '100', '78,10', '4924s', 'Hasil', 'pengujian', 'pada', 'Tabel', '2', 'menunjukkan', 'bahwa', 'model', 'dengan', 'arsitektur', 'EfficientNet', 'B4', 'memiliki', 'akurasi', 'testing', 'yang', 'tertinggi', 'sebesar', '78,10', '.', 'Hasil', 'ini', 'menunjukkan', 'bahwa', 'model', 'EfficientNet', 'B4', 'mampu', 'mendeteksi', 'alfabet', 'dalam', 'data', 'uji', 'hingga', 'didapatkan', '78,10', 'kebenarannya', '.', 'Selain', 'memiliki', 'akurasi', 'testing', 'yang', 'tertinggi', ',', 'akurasi', 'training', 'dan', 'validation', 'dari', 'model', 'Effi', 'cientNet', 'B4', 'juga', 'yang', 'terbesar', ',', 'yaitu', 'sebesar', '99,96', 'untuk', 'training', 'dan', '100', 'untuk', 'validation', '.', 'Seluruh', 'model', 'mendapatkan', 'akurasi', 'training', 'yang', 'tidak', 'begitu', 'jauh', 'dari', 'satu', 'sama', 'lain', ',', 'dengan', 'perbedaan', 'antara', 'hasil', 'terendah', 'dan', 'tertinggi', 'hanya', 'sebesar', '0,13', '.', 'Akurasi', 'validation', 'tampak', 'merata', 'untuk', 'keempat', 'arsitektur', 'yang', 'diuji', '.', 'Waktu', 'pelatihan', 'tercepat', 'jatuh', 'kepada', 'model', 'AlexNet', 'dengan', 'waktu', '3350', 'detik', 'atau', 'hanya', '55', 'menit', 'dan', 'terlama', 'pada', 'model', 'EfficientNet', 'B4', 'dengan', 'waktu', '4924', 'detik', 'atau', '1', 'jam', '22', 'menit', '.', 'Hasil', 'ini', 'menunjukkan', 'bahwa', 'model', 'EfficientNet', 'B4', 'memiliki', 'kemampuan', 'terbaik', 'dalam', 'prediksi', 'data', 'uji', 'dibanding', 'model', 'lainnya', ',', 'walau', 'waktu', 'pelatihannya', 'memakan', 'waktu', 'paling', 'lama', '.', '4.2', 'Pengujian', 'Hyperparameter', 'Pengujian', 'Hyperparameter', 'dilakukan', 'dengan', 'menentukan', 'pengat', 'uran', 'Hyperparameter', 'yang', 'dapat', 'Mahardika', ',', 'dkk', ',', 'Sistem', 'Rekognisi', 'Citra', 'Digital', '1165', 'memberikan', 'hasil', 'yang', 'terbaik', ',', 'dan', 'pengaturan', 'Hyperparameter', 'yang', 'akan', 'diuji', 'yaitu', 'optimizer', 'dan', 'penggunaan', 'learning', 'rate', 'scheduler', '.', 'Untuk', 'model', 'pengujian', 'digunakan', 'model', 'EfficientNet', 'B4', 'untuk', 'mencari', 'kombinasi', 'Hyperparameter', 'yang', 'terbaik', '.', 'Jumlah', 'epoch', 'yang', 'digunakan', 'adalah', '20', ',', 'dan', 'Learning', 'Rate', 'yang', 'digunakan', 'yaitu', '0.001', '.', 'Pengujian', 'optimizer', 'dilakukan', 'dengan', 'mencoba', 'satu', 'per', 'satu', 'optimizer', 'yang', 'dapat', 'digunakan', '.', 'Opsi', 'optimizer', 'yang', 'akan', 'dicoba', 'yaitu', 'Adam', ',', 'SGD', ',', 'dan', 'RMSProp', '.', 'Pengujian', 'ini', 'juga', 'tidak', 'menggunakan', 'Spatial', 'Transformer', '.', 'Hasil', 'dari', 'pengujian', 'ditunjukkan', 'pada', 'Optimizer', 'Akurasi', 'Waktu', 'Training', 'Train', 'Validation', 'Test', 'Adam', '99,96', '100', '78,10', '4924s', 'SGD', '4,79', '3,85', '3,84', '4707s', 'RMSProp', '99,98', '100', '57,39', '4767s', 'Berdasarkan', 'hasil', 'pengujian', 'Tabel', '3', ',', 'dapat', 'dilihat', 'bahwa', 'model', 'yang', 'menggunakan', 'optimizer', 'SGD', 'terlihat', 'tidak', 'berkembang', '.', 'Akurasi', 'yang', 'didapat', 'terlihat', 'tidak', 'mampu', 'mencapai', '5', ',', 'baik', 'akurasi', 'training', ',', 'validation', ',', 'maupun', 'testing', '.', 'Hal', 'ini', 'diduga', 'karena', 'optimizer', 'SGD', 'memiliki', 'sifat', 'yang', 'stokastik', 'atau', 'random', 'dalam', 'memilih', 'data', 'latih', 'untuk', 'setiap', 'step', ',', 'sehingga', 'membutuhkan', 'lebih', 'banyak', 'epoch', 'dibandingkan', 'dengan', 'optimizer', 'lain', '.', 'Model', 'dengan', 'optimizer', 'RMSProp', 'terlihat', 'cukup', 'baik', ',', 'akan', 'tetapi', 'akurasi', 'testing', '-nya', 'tidak', 'sebaik', 'dengan', 'model', 'yang', 'menggunakan', 'optimizer', 'Adam', '.', 'Hasil', 'ini', 'diduga', 'dikarenakan', 'optimizer', 'Adam', 'merupakan', 'hasil', 'perkembangan', 'gabungan', 'dari', 'kedua', 'optimizer', '.', 'Setelah', 'optimizer', ',', 'pengujian', 'Hyperparameter', 'selanjutnya', 'adalah', 'penggunaan', 'learning', 'rate', 'scheduler', '.', 'Learning', 'Rate', 'Akurasi', 'Epoch', 'mencapai', 'Konvergen', 'Train', 'Test', 'LR', '0.001', '98,83', '76,33', 'Belum', 'Konvergen', 'LR', '0.001', 'Scheduler', '99,96', '78,10', 'Epoch', 'ke-8', 'Pengujian', 'learning', 'rate', 'scheduler', 'dilakukan', 'dengan', 'menguji', 'performa', 'dari', 'pelatihan', 'apabila', 'penggunaan', 'scheduler', 'diberikan', '.', 'Metrik', 'utama', 'yang', 'akan', 'diperhatikan', 'adalah', 'jumlah', 'epoch', 'yang', 'diperlukan', 'dari', 'model', 'hingga', 'mencapai', 'titik', 'konvergen', ',', 'atau', 'titik', 'dimana', 'akurasi', 'pelatihan', 'tidak', 'lagi', 'fluktuatif', '.', 'Untuk', 'nilai', 'learning', 'rate', 'yang', 'akan', 'digunakan', 'yaitu', '0.001', ',', 'dan', 'learning', 'rate', 'scheduler', 'yang', 'digunakan', 'adalah', 'Exponential', 'Learning', 'Rate', 'Scheduler', 'dari', 'library', 'torch', 'optim', '.', 'Sebagaimana', 'ditunjukkan', 'pada', 'Tabel', '4', ',', 'Gambar', '8', ',', 'dan', 'Gambar', '9', ',', 'pe', 'ngujian', 'penggunaan', 'Learning', 'Rate', 'Scheduler', 'pada', 'model', 'CNN', 'tampak', 'memiliki', 'pengaruh', 'terhadap', 'proses', 'pelatihan', 'maupun', 'hasil', 'dari', 'output', 'model', 'tersebut', '.', 'Dengan', 'adanya', 'Learning', 'Rate', 'Scheduler', ',', 'proses', 'pelatihan', 'model', 'terlihat', 'menjadi', 'lebih', 'stabil', '.', 'Perubahan', 'ter', 'hadap', 'nilai', 'learning', 'rate', 'menjadikan', 'proses', 'pelatihan', 'menjadi', 'lebih', 'teratur', 'dan', 'tidak', 'fluktuatif', ',', 'sebagaimana', 'dapat', 'dilihat', 'pada', 'model', 'yang', 'dilatih', 'masih', 'belum', 'mampu', 'memberikan', 'hasil', 'yang', 'konsisten', '.', 'Hal', 'ini', 'memiliki', 'pengaruh', 'terhadap', 'hasil', 'output', ',', 'dibuktikan', 'dengan', 'akurasi', 'yang', 'didapat', 'terlihat', 'lebih', 'kecil', 'dibandingkan', 'dengan', 'model', 'yang', 'menggunakan', 'scheduler', '.', 'Gambar', '8', 'menunjukkan', 'bahwa', 'pengujian', 'yang', 'tidak', 'menggunakan', 'scheduler', 'tampak', 'fluktuatif', 'dan', 'tidak', 'teratur', '.', 'Sel', 'ain', 'itu', ',', 'hal', 'ini', 'juga', 'memiliki', 'pengaruh', 'terhadap', 'hasil', 'output', ',', 'dibuktikan', 'dengan', 'akurasi', 'yang', 'didapat', 'terlihat', 'lebih', 'kecil', 'dibandingkan', 'dengan', 'model', 'yang', 'menggunakan', 'scheduler', 'sebagaimana', 'ditunjukkan', 'pada', 'maupun', 'testing', ',', 'peng', 'gunaan', 'scheduler', 'terlihat', 'mampu', 'menaikkan', 'akurasi', 'pada', 'model', 'yang', 'dilatih', '4.3', '.', 'Pen', 'gujian', 'Penggunaan', 'Pretrained', 'Weights', 'Pengujian', 'penggunaan', 'pretrained', 'weights', 'dilakukan', 'dengan', 'menggunakan', 'parameter', 'pretrained', 'True', 'ketika', 'memanggil', 'model', 'menggunakan', 'library', 'torch', 'untuk', 'menggunakan', 'weights', 'yang', 'sebelumnya', 'telah', 'dilatih', 'dan', 'disediakan', 'pada', 'pemanggilan', 'model', '.', 'Model', 'yang', 'akan', 'digunakan', 'sama', 'seperti', 'pengujian', 'sebelumnya', ',', 'yaitu', 'ResNet18', ',', 'AlexNet', ',', 'ResNet50', 'dan', 'EfficientNet', 'B4', '.', '1166', 'Jurnal', 'Teknologi', 'Informasi', 'dan', 'Ilmu', 'Komputer', '(', 'JTIIK', ')', ',', 'Vol', '.', '11', ',', 'No', '.', '6', ',', 'Desember', '2024', ',', 'hlm.1159', '-1168', 'Tujuan', 'pengujian', 'adalah', 'untuk', 'm', 'engetahui', 'seberapa', 'besar', 'pengaruh', 'pretrained', 'weights', 'pada', 'proses', 'pelatihan', 'dan', 'hasilnya', '.', 'Pengujian', 'menggunakan', 'optimizer', 'Adam', 'dan', 'learning', 'rate', '0.001', 'serta', 'scheduler', '-nya', '.', 'Pengujian', 'ini', 'tidak', 'menggunakan', 'Spatial', 'Transformer', '.', 'Model', 'Akurasi', 'Waktu', 'Training', 'Train', 'Validation', 'Test', 'ResNet18', '99,89', '100', '54,73', '3585s', 'ResNet18', 'Pretrained', '100', '100', '84,91', '3566s', 'AlexNet', '99,93', '100', '57,39', '3350s', 'AlexNet', 'Pretrained', '99,96', '99,04', '75,44', '3345s', 'ResNet50', '99,83', '100', '57,10', '4167s', 'ResNet50', 'Pretrained', '99,89', '99,52', '65,09', '4119s', 'EfficientNet', 'B4', '99,96', '100', '78,10', '4924s', 'EfficientNet', 'B4', 'Pretrained', '99,96', '100', '100', '4870s', 'Berdasarkan', 'hasil', 'pengujian', 'yang', 'ditunjukkan', 'pada', 'Tabel', '5', ',', 'dapat', 'dilihat', 'bahwa', 'terdapat', 'peningkatan', 'pada', 'akurasi', 'testing', 'untuk', 'seluruh', 'model', '.', 'Peningkatan', 'tersebut', 'berbeda', '-beda', 'pada', 'setiap', 'model', ',', 'berkisar', 'antara', 'angka', '8', 'hingga', '30', '.', 'Model', 'ResNet18', 'mendapatkan', 'peningkatan', 'akurasi', 'testing', 'yang', 'paling', 'besar', ',', 'yaitu', '30,18', '.', 'Model', 'AlexNet', 'juga', 'mendapatkan', 'peningkatan', ',', 'yaitu', 'sebesa', 'r', '18,05', '.', 'Model', 'ResNet50', 'mendapatkan', 'peningkatan', 'paling', 'kecil', ',', 'yaitu', 'hanya', 'sebesar', '7,99', '.', 'Terakhir', ',', 'model', 'EfficientNet', 'B4', 'mendapatkan', 'peningkatan', 'sebesar', '21,9', 'dan', 'mampu', 'mencapai', 'akurasi', 'maksimum', ',', 'yaitu', '100', '.', 'Hasil', 'ini', 'menunjukkan', 'bahwa', 'model', 'EfficientNet', 'B4', 'sudah', 'mampu', 'mendeteksi', 'seluruh', 'data', 'uji', 'secara', 'sempurna', 'diduga', 'karena', 'tingkat', 'kesulitan', 'untuk', 'mendeteksi', 'data', 'uji', 'tidak', 'begitu', 'tinggi', '.', 'Dari', 'keempat', 'model', ',', 'dapat', 'dilihat', 'bahwa', 'model', 'EfficientNet', 'B4', 'masih', 'memiliki', 'akurasi', 'terbesar', ',', 'bahkan', 'mampu', 'mencapai', 'angka', 'maksimum', '.', 'Hal', 'ini', 'menunjukkan', 'bahwa', 'model', 'EfficientNet', 'B4', 'merupakan', 'model', 'yang', 'terbaik', 'dari', 'keempat', 'model', 'yang', 'diuji', 'dalam', 'mengklasifikasikan', 'dataset', 'yang', 'diberikan', '.', '4.4', '.', 'Pen', 'gujian', 'Penggunaan', 'Spatial', 'Transformer', 'Pengujian', 'ini', 'dilakukan', 'dengan', 'menambah', 'kan', 'lapisan', 'localization', 'dan', 'lapisan', 'Fully', 'Connected', 'yang', 'merupakan', 'bagian', 'dari', 'Spatial', 'Transformer', 'Network', '.', 'Lapisan', '-lapisan', 'ini', 'ditambahkan', 'tepat', 'sebelum', 'dimasukkan', 'ke', 'model', 'EfficientNet', 'B4', 'yang', 'menjadi', 'arsitektur', 'utama', '.', 'Pengujian', 'akan', 'menggunakan', 'optimiz', 'er', 'Adam', 'dan', 'learning', 'rate', '0.001', 'serta', 'scheduler', '-nya', '.', 'Model', 'Akurasi', 'Train', 'Akurasi', 'Test', 'Waktu', 'Training', 'EfficientNet', 'B4', '99,96', '78,10', '4924s', 'EfficientNet', 'B4', 'dengan', 'Spatial', 'Transformer', '100', '86,09', '5950s', 'EfficientNet', 'B4', 'Pretrained', 'dengan', 'Spatial', 'Transformer', '100', '100', '6537s', 'Dari', 'hasil', 'pengujian', 'yang', 'ditunjukkan', 'pada', 'Tabel', '6', ',', 'terlihat', 'terdapat', 'peningkatan', 'akurasi', 'Test', 'pada', 'model', 'EfficientNet', 'B4', 'dengan', 'Spatial', 'Transformer', ',', 'yaitu', 'sebesar', '8', '.', 'Akurasi', 'yang', 'didapat', 'apabila', 'EfficientNet', 'B4', 'Pretrained', 'menggunakan', 'Spatial', 'Transformer', 'mampu', 'mencapai', 'akurasi', 'maksimum', 'pada', 'data', 'Test', ',', 'yaitu', 'sebesar', '100', '.', 'Adanya', 'peningkatan', 'akurasi', 'menunjukkan', 'bahwa', 'Spatial', 'Transformer', 'memiliki', 'kemampuan', 'untuk', 'meningkatkan', 'kemampuan', 'dari', 'model', 'dalam', 'klasifikasi', ',', 'sehingga', 'pantas', 'untuk', 'digunakan', 'untuk', 'model', 'akhir', '.', 'Model', 'akhir', 'ini', 'mampu', 'mendapatkan', 'nilai', 'maksimum', 'dari', 'data', 'testing', ',', 'sehingga', 'siap', 'untuk', 'diuji', 'coba', 'secara', 'real', '-', 'time', '.', '4.5', '.', 'Pen', 'gujian', 'Secara', 'Real', '-Time', 'Pengujian', 'secara', 'real', '-', 'time', 'dilakukan', 'dengan', 'mencoba', 'dataset', 'satu', 'per', 'satu', 'terhadap', 'suatu', 'kondisi', 'atau', 'tampilan', 'latar', 'belakang', 'tertentu', 'dan', 'menilai', 'ke', '-', 'efektifan', 'masing', '-masing', 'data', 'terhadap', 'masing', '-', 'masing', 'tampilan', 'latar', 'belakang', ',', 'yaitu', 'latar', 'belakang', 'putih', ',', 'hitam', ',', 'dan', 'abstrak', '.', 'Setelah', 'itu', ',', 'keempat', 'dataset', 'akan', 'digabungkan', 'menjadi', 'satu', 'untuk', 'dicoba', 'melihat', 'keefektifannya', 'terhadap', 'masing', '-masing', 'tampilan', 'latar', 'belakang', '.', 'Model', 'yang', 'digunakan', 'adalah', 'model', 'dengan', 'pengaturan', 'serta', 'arsitektur', 'ya', 'ng', 'terbaik', ',', 'yaitu', 'EfficientNet', 'B4', 'Pretrained', 'dengan', 'Spatial', 'Transformer', '.', 'Data', 'gambar', 'akan', 'di', '-convert', 'menjadi', 'single', 'channel', 'agar', 'mempermudah', 'prediksi', 'melalui', 'aplikasi', '.', 'Dataset', 'Total', 'Benar', 'Akurasi', 'Latar', 'Belakang', 'Pengujian', 'Putih', 'Hitam', 'Abstrak', 'Latar', 'Belakang', 'Putih', 'Total', 'Benar', '22', '23', '13', 'Akurasi', '85', '88', '50', 'Latar', 'Belakang', 'Hitam', 'Total', 'Benar', '13', '16', '6', 'Akurasi', '50', '62', '23', 'Latar', 'Belakang', 'Karpet', 'Total', 'Benar', '9', '12', '3', 'Akurasi', '35', '46', '12', 'Latar', 'Belakang', 'Pemandangan', 'Total', 'Benar', '9', '4', '3', 'Akurasi', '35', '15', '12', 'Gabungan', 'Total', 'Benar', '26', '26', '23', 'Akurasi', '100', '100', '88', 'Tabel', '7', 'menunjukkan', 'bahwa', 'akurasi', 'yang', 'didapat', 'menggunakan', 'dataset', 'latar', 'belakang', 'hitam', 'terlihat', 'masih', 'kurang', 'baik', '.', 'Dataset', 'masih', 'mampu', 'melakukan', 'klasifikasi', 'pada', 'latar', 'belakang', 'pengujian', 'Mahardika', ',', 'dkk', ',', 'Sistem', 'Rekognisi', 'Citra', 'Digital', '1167', 'yang', 'polos', ',', 'seperti', 'latar', 'belakang', 'putih', 'dan', 'hitam', '.', 'Total', 'prediksi', 'yang', 'benar', 'masih', 'mampu', 'mencapai', '50', 'dari', 'seluruh', 'alfabet', 'pada', 'latar', 'belakang', 'putih', 'dan', 'sebesar', '62', 'pada', 'latar', 'belakang', 'hitam', '.', 'Hasil', 'pengujian', 'pada', 'latar', 'belakang', 'abstrak', 'terlihat', 'hanya', 'sebesar', '23', '.', 'Dapat', 'juga', 'dilihat', 'pada', 'Tabel', '7', 'bahwa', 'dataset', 'dengan', 'latar', 'belakang', 'putih', 'mampu', 'melakukan', 'klasifikasi', 'dengan', 'baik', 'pada', 'latar', 'belakang', 'pengujian', 'putih', 'dan', 'hitam', 'polos', ',', 'tetapi', 'tidak', 'te', 'rlalu', 'buruk', 'pada', 'klasifikasi', 'dengan', 'background', 'abstrak', '.', 'Total', 'benar', 'yang', 'didapat', 'pada', 'latar', 'belakang', 'putih', 'sebesar', '85', 'dan', 'latar', 'belakang', 'hitam', '88', 'dari', 'seluruh', 'alfabet', '.', 'Hasil', 'pengujian', 'pada', 'latar', 'belakang', 'abstrak', 'hanya', 'sebesar', '50', ',', 'tetapi', 'hasil', 'ini', 'masih', 'lebih', 'baik', 'jika', 'dibandingkan', 'dengan', 'dataset', 'berlatar', 'belakang', 'hitam', '.', 'Hasil', 'pengujian', 'dataset', 'berlatar', 'belakang', 'pemandangan', 'terlihat', 'kurang', 'baik', '.', 'Pada', 'latar', 'belakang', 'putih', ',', 'total', 'benar', 'yang', 'didapat', 'hanya', 'sebesar', '35', 'dari', 'seluruh', 'alfabet', ',', 'hasil', 'yang', 'lebih', 'buruk', 'jika', 'dibandingkan', 'dengan', 'kedua', 'dataset', 'di', 'pengujian', 'sebelumnya', '.', 'Tetapi', ',', 'pengujian', 'pada', 'latar', 'belakang', 'hitam', 'terlihat', 'lebih', 'buruk', ',', 'hanya', 'sebesar', '15', '.', 'Pengujian', 'pada', 'latar', 'belakang', 'abstrak', 'terlihat', 'tidak', 'jauh', ',', 'yaitu', 'hanya', 'sebesar', '12', '.', 'Dataset', 'berlatar', 'be', 'lakang', 'karpet', 'yang', 'ditunjukkan', 'pada', 'Tabel', '7', 'terlihat', 'lebih', 'baik', 'daripada', 'pengujian', 'pada', 'dataset', 'berlatar', 'belakang', 'pemandangan', ',', 'tetapi', 'masih', 'kurang', 'jika', 'dibandingkan', 'dengan', 'dataset', 'berlatar', 'belakang', 'hitam', 'dan', 'putih', '.', 'Pengujian', 'pada', 'latar', 'belakang', 'putih', 'terli', 'hat', 'mendapatkan', 'total', 'benar', 'sebesar', '35', ',', 'dan', 'pengujian', 'pada', 'latar', 'belakang', 'hitam', 'terlihat', 'mendapatkan', 'total', 'benar', 'sebesar', '46', 'dari', 'seluruh', 'alfabet', '.', 'Tetapi', ',', 'pengujian', 'pada', 'latar', 'belakang', 'abstrak', 'masih', 'terlihat', 'buruk', ',', 'yaitu', 'hanya', '12', '.', 'Setelah', 'keempat', 'dataset', 'diatas', 'digabungkan', ',', 'terlihat', 'hasil', 'pengujian', 'secara', 'real', '-', 'time', 'yang', 'didapat', 'cukup', 'memuaskan', '.', 'Sebagaimana', 'ditunjukkan', 'pada', 'Tabel', '7', ',', 'hasil', 'pengujian', 'dataset', 'gabungan', 'pada', 'latar', 'belakang', 'putih', 'terlihat', 'mencapai', '100', 'total', 'benar', '.', 'Pengujian', 'pada', 'latar', 'belakang', 'hitam', 'juga', 'mencapai', '100', 'total', 'benar', '.', 'Terakhir', ',', 'pengujian', 'pada', 'latar', 'belakang', 'abstrak', 'juga', 'terlihat', 'baik', ',', 'yaitu', 'sebesar', '88', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# langkah selanjutnya adalah me remove tanda baca dan stopwords\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies = {}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 6,\n",
       " 'PENDAHULUAN': 1,\n",
       " 'Bahasa': 5,\n",
       " 'isyarat': 32,\n",
       " 'kelompok': 1,\n",
       " 'masyarakat': 4,\n",
       " 'bisu': 7,\n",
       " 'tuli': 7,\n",
       " 'bahasa': 30,\n",
       " 'metode': 9,\n",
       " 'terpenting': 1,\n",
       " 'berkomunikasi': 1,\n",
       " 'sulit': 1,\n",
       " 'maksud': 4,\n",
       " 'pikiran': 2,\n",
       " 'berkomunik': 1,\n",
       " 'asi': 1,\n",
       " 'orang': 2,\n",
       " 'mengerti': 1,\n",
       " 'memiliki': 23,\n",
       " 'kemampuan': 5,\n",
       " 'berko': 1,\n",
       " 'munikasi': 1,\n",
       " 'diekspresikan': 2,\n",
       " 'tangan': 4,\n",
       " 'lengan': 2,\n",
       " 'wajah': 4,\n",
       " 'dimengerti': 2,\n",
       " 'mata': 2,\n",
       " 'Pembuatan': 1,\n",
       " 'sistem': 10,\n",
       " 'klasifikasi': 9,\n",
       " 'asisten': 1,\n",
       " 'virtual': 1,\n",
       " 'deep': 3,\n",
       " 'learning': 17,\n",
       " 'tensorflow': 1,\n",
       " 'Kesimpulan': 3,\n",
       " 'penelitian': 11,\n",
       " 'mendeteksi': 8,\n",
       " 'dataset': 36,\n",
       " 'bentuk': 6,\n",
       " 'dunia': 1,\n",
       " 'regional': 1,\n",
       " 'lokasi': 1,\n",
       " 'latar': 31,\n",
       " 'mendukun': 1,\n",
       " 'g': 1,\n",
       " 'mengambil': 3,\n",
       " 'gambar': 12,\n",
       " 'sembarang': 1,\n",
       " 'Penelitian': 5,\n",
       " 'memfokuskan': 1,\n",
       " 'pembuatan': 1,\n",
       " 'aplikasinya': 1,\n",
       " 'akurasi': 30,\n",
       " 'performa': 5,\n",
       " 'mendalam': 2,\n",
       " 'mend': 1,\n",
       " 'alami': 1,\n",
       " 'model': 65,\n",
       " '-nya': 8,\n",
       " 'deteksi': 1,\n",
       " 'citra': 6,\n",
       " 'Covid': 1,\n",
       " '19': 1,\n",
       " 'teta': 1,\n",
       " 'pi': 1,\n",
       " 'terbaik': 11,\n",
       " 'dijadikan': 1,\n",
       " 'penulis': 4,\n",
       " 'referensi': 1,\n",
       " 'elemen': 2,\n",
       " 'diperhatikan': 2,\n",
       " 'cahaya': 1,\n",
       " 'pose': 5,\n",
       " 'angle': 1,\n",
       " 'posisi': 1,\n",
       " 'kamera': 2,\n",
       " 'da': 1,\n",
       " 'n': 1,\n",
       " 'mudah': 2,\n",
       " 'hasil': 25,\n",
       " 'sempurna': 2,\n",
       " 'CNN': 12,\n",
       " 'pembelajaran': 2,\n",
       " 'fiturnya': 1,\n",
       " 'kuat': 1,\n",
       " 'bertahan': 1,\n",
       " 'lingkungan': 1,\n",
       " 'kompleks': 1,\n",
       " 'diaplikasikan': 1,\n",
       " 'kesimpulan': 1,\n",
       " 'ketiga': 2,\n",
       " 'X': 5,\n",
       " '-Ray': 1,\n",
       " 'CT': 1,\n",
       " 'Scan': 1,\n",
       " 'radiografi': 1,\n",
       " 'dada': 1,\n",
       " 'membantu': 3,\n",
       " 'penyakit': 2,\n",
       " 'men': 1,\n",
       " 'ggunakan': 1,\n",
       " 'Transfer': 4,\n",
       " 'Learning': 13,\n",
       " 'PyTorch': 3,\n",
       " 'memuaskan': 3,\n",
       " '97,78': 1,\n",
       " 'Hasil': 14,\n",
       " 'menjadikan': 3,\n",
       " 'tertarik': 1,\n",
       " 'dicoba': 3,\n",
       " 'aplikasi': 6,\n",
       " 'rekognisi': 4,\n",
       " 'isyara': 1,\n",
       " 't.': 1,\n",
       " 'penggunaan': 10,\n",
       " 'Spatial': 29,\n",
       " 'Transformer': 29,\n",
       " 'optimisasi': 1,\n",
       " 'stokastik': 2,\n",
       " 'rambu': 1,\n",
       " 'lintas': 1,\n",
       " 'sebe': 1,\n",
       " 'sar': 1,\n",
       " '99,71': 1,\n",
       " 'data': 39,\n",
       " 'uji': 11,\n",
       " '12.630': 1,\n",
       " 'mencoba': 5,\n",
       " 'meningkatkan': 3,\n",
       " 'mengusulkan': 1,\n",
       " 'dikembangkan': 2,\n",
       " 'reko': 1,\n",
       " 'gnisi': 1,\n",
       " 'digital': 5,\n",
       " 'mengenali': 2,\n",
       " 'Convolutional': 8,\n",
       " 'Neural': 8,\n",
       " 'Network': 9,\n",
       " 'Deep': 3,\n",
       " 'Machine': 1,\n",
       " 'dimasukkan': 4,\n",
       " 'luaran': 1,\n",
       " 'sesuai': 3,\n",
       " '2': 4,\n",
       " 'METODE': 1,\n",
       " 'PENELITIAN': 1,\n",
       " '2.1': 1,\n",
       " 'Data': 10,\n",
       " 'training': 10,\n",
       " 'sekunder': 4,\n",
       " 'open': 1,\n",
       " 'source': 1,\n",
       " 'halaman': 1,\n",
       " 'web': 5,\n",
       " 'menyediakan': 2,\n",
       " '-dataset': 2,\n",
       " 'gratis': 1,\n",
       " 'legal': 1,\n",
       " 'tema': 1,\n",
       " 'situs': 3,\n",
       " 'set': 2,\n",
       " 'bernama': 1,\n",
       " 'Kaggle': 3,\n",
       " 'background': 19,\n",
       " 'hitam': 16,\n",
       " 'putih': 15,\n",
       " 'publik': 2,\n",
       " '70': 1,\n",
       " '21': 1,\n",
       " 'internet': 2,\n",
       " 'diambil': 6,\n",
       " 'pribadi': 2,\n",
       " 'Pengambilan': 1,\n",
       " 'Mahardika': 4,\n",
       " 'dkk': 4,\n",
       " 'Sistem': 4,\n",
       " 'Rekognisi': 4,\n",
       " 'Citra': 4,\n",
       " 'Digital': 4,\n",
       " '1161': 1,\n",
       " 'menguji': 3,\n",
       " 'perbedaan': 2,\n",
       " 'pengujian': 28,\n",
       " 'berbeda': 4,\n",
       " 'pengaruh': 6,\n",
       " 'dimiliki': 1,\n",
       " 'percobaan': 1,\n",
       " 'permasalahan': 1,\n",
       " 'gamb': 1,\n",
       " 'ar': 1,\n",
       " 'bervariasi': 1,\n",
       " 'karpet': 4,\n",
       " 'bermot': 1,\n",
       " 'if': 1,\n",
       " 'Gambar': 5,\n",
       " '3': 6,\n",
       " 'pemandangan': 5,\n",
       " 'pagi': 1,\n",
       " '54': 1,\n",
       " '40': 1,\n",
       " 'menggabungkan': 1,\n",
       " 'keempat': 8,\n",
       " 'validation': 6,\n",
       " 'bunga': 2,\n",
       " 'langit': 2,\n",
       " 'merah': 2,\n",
       " 'gunung': 2,\n",
       " 'Penyusunan': 1,\n",
       " 'alfabet': 7,\n",
       " 'ditambah': 1,\n",
       " 'unt': 1,\n",
       " 'uk': 1,\n",
       " '338': 1,\n",
       " 'total': 7,\n",
       " 'perancangan': 2,\n",
       " 'diawali': 1,\n",
       " 'pemrosesan': 2,\n",
       " 'mengubah': 1,\n",
       " 'mensi': 1,\n",
       " 'mengkonversi': 1,\n",
       " 'berbentuk': 1,\n",
       " 'Tensor': 1,\n",
       " 'input': 13,\n",
       " 'dibuatlah': 1,\n",
       " 'arsitektur': 14,\n",
       " 'Penentuan': 1,\n",
       " 'Arsitektur': 3,\n",
       " 'memasukan': 1,\n",
       " 'lapisan': 17,\n",
       " '-lapisan': 3,\n",
       " 'neural': 4,\n",
       " 'network': 4,\n",
       " 'modul': 3,\n",
       " 'tambahkan': 1,\n",
       " 'utama': 7,\n",
       " 'melewati': 3,\n",
       " 'memasuki': 2,\n",
       " 'ditentukan': 1,\n",
       " 'proses': 11,\n",
       " 'pelatihan': 12,\n",
       " 'Training': 6,\n",
       " 'tujuan': 3,\n",
       " 'pengetahuan': 1,\n",
       " 'dibutuhkannya': 1,\n",
       " 'mengklasifikasikan': 2,\n",
       " 'merekognisi': 2,\n",
       " 'menentukan': 3,\n",
       " 'ki': 1,\n",
       " 'nerja': 1,\n",
       " 'pekerjaan': 1,\n",
       " 'mengklasifikasi': 1,\n",
       " 'kinerja': 2,\n",
       " 'perbaikan': 1,\n",
       " 'Tweaking': 1,\n",
       " 'tar': 1,\n",
       " 'get': 1,\n",
       " 'dicari': 1,\n",
       " 'nilai': 16,\n",
       " 'Alur': 1,\n",
       " '1162': 1,\n",
       " 'Jurnal': 3,\n",
       " 'Teknologi': 3,\n",
       " 'Informasi': 3,\n",
       " 'Ilmu': 3,\n",
       " 'Komputer': 3,\n",
       " 'JTIIK': 3,\n",
       " 'Vol': 3,\n",
       " '11': 3,\n",
       " 'No': 3,\n",
       " '6': 8,\n",
       " 'Desember': 3,\n",
       " '2024': 3,\n",
       " 'hlm.1159': 3,\n",
       " '-1168': 3,\n",
       " 'pretrained': 8,\n",
       " 'weights': 10,\n",
       " 'disediakan': 3,\n",
       " 'library': 4,\n",
       " 'Contoh': 2,\n",
       " 'ResNet': 1,\n",
       " 'AlexNet': 9,\n",
       " 'EfficientNet': 22,\n",
       " 'Model': 12,\n",
       " 'dilatih': 4,\n",
       " 'ImageNet': 1,\n",
       " '-1k': 1,\n",
       " 'penambahan': 1,\n",
       " 'lapis': 1,\n",
       " 'an': 1,\n",
       " 'Localization': 7,\n",
       " 'fully': 1,\n",
       " 'connected': 1,\n",
       " 'sampler': 1,\n",
       " 'Penambahan': 1,\n",
       " 'diposisikan': 1,\n",
       " 'tepatnya': 1,\n",
       " 'ditransformasi': 1,\n",
       " 'lap': 1,\n",
       " 'isan': 1,\n",
       " 'DASAR': 1,\n",
       " 'TEORI': 1,\n",
       " '3.1': 1,\n",
       " 'Isyarat': 1,\n",
       " 'struktur': 1,\n",
       " 'peraturan': 1,\n",
       " 'kalimat': 1,\n",
       " 'percakapan': 2,\n",
       " 'dimana': 4,\n",
       " 'beserta': 1,\n",
       " 'jari': 1,\n",
       " 'jarinya': 1,\n",
       " 'membentuk': 1,\n",
       " 'unik': 1,\n",
       " 's': 1,\n",
       " 'ehingga': 1,\n",
       " 'dikenali': 1,\n",
       " 'negara': 4,\n",
       " 'American': 1,\n",
       " 'Sign': 5,\n",
       " 'Language': 5,\n",
       " 'ASL': 1,\n",
       " 'y': 11,\n",
       " 'ang': 2,\n",
       " 'populer': 3,\n",
       " 'berasal': 2,\n",
       " 'Amerika': 1,\n",
       " 'Serikat': 1,\n",
       " 'Inggris': 1,\n",
       " 'British': 1,\n",
       " 'BSL': 1,\n",
       " 'Australian': 1,\n",
       " 'Auslan': 1,\n",
       " 'Italian': 1,\n",
       " 'LIS': 1,\n",
       " 'Japanese': 1,\n",
       " 'JSL': 1,\n",
       " '3.2': 1,\n",
       " 'jaringan': 5,\n",
       " 'saraf': 1,\n",
       " 'neuron': 1,\n",
       " 'sepenuhnya': 1,\n",
       " 'tersambung': 1,\n",
       " 'berisi': 1,\n",
       " 'convolutional': 3,\n",
       " 'sampling': 3,\n",
       " 'sub': 1,\n",
       " 'tersembunyi': 1,\n",
       " 'convolution': 1,\n",
       " 'diikuti': 1,\n",
       " 'penghitung': 1,\n",
       " 'pemerataan': 1,\n",
       " 'ekstraksi': 1,\n",
       " 'perhitungan': 2,\n",
       " 'H(x': 2,\n",
       " 'b': 4,\n",
       " 'F(x': 2,\n",
       " 'G(x': 4,\n",
       " 'F(j': 2,\n",
       " 'k': 7,\n",
       " 'j': 6,\n",
       " 'Keterangan': 3,\n",
       " 'F': 2,\n",
       " 'Filter': 1,\n",
       " 'Lapisan': 2,\n",
       " 'G': 3,\n",
       " 'Input': 1,\n",
       " 'feature': 12,\n",
       " 'map': 15,\n",
       " 'H': 2,\n",
       " 'Output': 4,\n",
       " 'Bias': 1,\n",
       " 'x': 2,\n",
       " 'Sumbu': 6,\n",
       " 'filter': 2,\n",
       " 'Y': 4,\n",
       " 'Increment': 2,\n",
       " 'sumbu': 4,\n",
       " 'konvolusi': 3,\n",
       " 'Kernel': 1,\n",
       " 'pengali': 1,\n",
       " 'dikalikan': 1,\n",
       " 'kernel': 1,\n",
       " 'hasilnya': 2,\n",
       " 'dijumlahkan': 2,\n",
       " 'ukuran': 1,\n",
       " 'k.': 1,\n",
       " 'penjumlahan': 3,\n",
       " 'bias': 1,\n",
       " 'output': 11,\n",
       " 'Perhitungan': 5,\n",
       " 'dilanjutkan': 1,\n",
       " 'pixel': 3,\n",
       " '3.3': 1,\n",
       " 'salah': 2,\n",
       " 'teknik': 2,\n",
       " 'tahap': 1,\n",
       " 'mengekstrak': 2,\n",
       " 'tuning': 1,\n",
       " 'memperbaiki': 1,\n",
       " 'Keuntungan': 1,\n",
       " 'terletak': 1,\n",
       " 'penghematan': 2,\n",
       " 'penjalanan': 1,\n",
       " 'resource': 1,\n",
       " 'me': 1,\n",
       " 'nggunakan': 1,\n",
       " 'Teknik': 1,\n",
       " 'objek': 1,\n",
       " '3.4': 1,\n",
       " 'manipulasi': 1,\n",
       " 'spasial': 2,\n",
       " 'Modul': 1,\n",
       " 'dibedakan': 1,\n",
       " 'aktif': 1,\n",
       " 'mentransformasikan': 1,\n",
       " 'tergantung': 1,\n",
       " 'pengawasan': 1,\n",
       " 'tambahan': 1,\n",
       " 'modifikasi': 1,\n",
       " 'pengoptimalan': 1,\n",
       " 'Tahapan': 1,\n",
       " 'digambarkan': 1,\n",
       " '1163': 1,\n",
       " '7': 5,\n",
       " 'mekanisme': 1,\n",
       " 'dibagi': 1,\n",
       " 'Sampling': 3,\n",
       " 'Grid': 6,\n",
       " 'Sampler': 4,\n",
       " 'Jaringan': 1,\n",
       " 'mengeluarkan': 1,\n",
       " 'parameter': 5,\n",
       " 'transformasi': 6,\n",
       " 'Teta': 2,\n",
       " 'θ': 6,\n",
       " 'diterapkan': 2,\n",
       " 'hidden': 1,\n",
       " 'layer': 1,\n",
       " 'sekumpulan': 1,\n",
       " 'titik': 7,\n",
       " 'sampelnya': 1,\n",
       " 'menghasilkan': 2,\n",
       " 'diubah': 1,\n",
       " 'generator': 2,\n",
       " 'grid': 4,\n",
       " 'komponen': 2,\n",
       " 'fungsi': 1,\n",
       " 'eksklusif': 1,\n",
       " 'invers': 1,\n",
       " 'dihasilkan': 1,\n",
       " 'Generator': 1,\n",
       " 'Tujuan': 2,\n",
       " '-sampling': 1,\n",
       " '-titik': 2,\n",
       " 'mengulangi': 1,\n",
       " 'entri': 1,\n",
       " 'pengambilan': 1,\n",
       " 'sampel': 2,\n",
       " 'interpolasi': 1,\n",
       " 'bilinear': 1,\n",
       " 'tahapan': 1,\n",
       " 'diteruskan': 1,\n",
       " 'setelahnya': 1,\n",
       " 'xis': 3,\n",
       " 'yis': 3,\n",
       " 'τθ(Gi': 1,\n",
       " 'Aθ(xit': 1,\n",
       " 'yit': 4,\n",
       " 'θ1,1θ1,2θ1,3': 1,\n",
       " 'θ2,1θ2,3θ2,3': 1,\n",
       " 'xit': 3,\n",
       " 'τθ': 1,\n",
       " 'Transformasi': 3,\n",
       " 'Afin': 2,\n",
       " '2D': 1,\n",
       " 'Aθ': 4,\n",
       " 'Gi': 2,\n",
       " 'Feature': 1,\n",
       " 'Map': 1,\n",
       " 'Matriks': 1,\n",
       " 'Sumber': 2,\n",
       " 'Kordinat': 6,\n",
       " 'Target': 2,\n",
       " 'Luaran': 1,\n",
       " 'target': 2,\n",
       " 'kordinat': 2,\n",
       " 'sumber': 1,\n",
       " 'penentu': 1,\n",
       " 'matriks': 1,\n",
       " 'afin': 1,\n",
       " 'didefinisikan': 1,\n",
       " 'cropping': 1,\n",
       " 'translation': 1,\n",
       " 'rotation': 1,\n",
       " 'scale': 1,\n",
       " 'skew': 1,\n",
       " 'membutuhkan': 2,\n",
       " 'diproduksi': 1,\n",
       " '3.5': 2,\n",
       " 'Confusion': 3,\n",
       " 'Matrix': 3,\n",
       " 'pengukuran': 1,\n",
       " 'machine': 1,\n",
       " 'kelas': 2,\n",
       " 'tabel': 1,\n",
       " 'kombinasi': 5,\n",
       " 'prediksi': 6,\n",
       " 'Keempat': 2,\n",
       " 'True': 11,\n",
       " 'Positive': 11,\n",
       " 'TP': 14,\n",
       " 'False': 8,\n",
       " 'FP': 7,\n",
       " 'Negative': 7,\n",
       " 'TN': 6,\n",
       " 'Positif': 2,\n",
       " 'Negatif': 2,\n",
       " 'Prediksi': 2,\n",
       " 'Tabel': 10,\n",
       " 'metrik': 4,\n",
       " '-metrik': 1,\n",
       " 'mengevaluasi': 2,\n",
       " 'Metrik': 2,\n",
       " 'Accuracy': 2,\n",
       " 'Precision': 5,\n",
       " 'Recall': 5,\n",
       " 'F1': 3,\n",
       " 'Score': 3,\n",
       " 'rumus': 1,\n",
       " 'persamaan': 2,\n",
       " 'FN': 5,\n",
       " '4': 4,\n",
       " '5': 3,\n",
       " 'membagi': 3,\n",
       " 'keefektifan': 3,\n",
       " 'kesepakatan': 1,\n",
       " 'label': 4,\n",
       " 'positif': 4,\n",
       " 'o': 1,\n",
       " 'leh': 1,\n",
       " '1164': 1,\n",
       " 'mengidentifikasi': 1,\n",
       " 'mengeta': 1,\n",
       " 'hui': 1,\n",
       " 'hubungan': 1,\n",
       " 'dilabelkan': 1,\n",
       " 'Flask': 3,\n",
       " 'kerangka': 1,\n",
       " 'kerja': 1,\n",
       " 'alat': 1,\n",
       " 'pustaka': 1,\n",
       " 'teknologi': 1,\n",
       " 'meru': 1,\n",
       " 'pakan': 1,\n",
       " 'python': 1,\n",
       " 'berbasis': 1,\n",
       " 'flask': 1,\n",
       " 'diintegrasikan': 1,\n",
       " 'HASIL': 1,\n",
       " 'PEMBAHASAN': 1,\n",
       " 'Pengujian': 22,\n",
       " 'diuji': 12,\n",
       " 'pengaturan': 5,\n",
       " '-model': 1,\n",
       " 'ResNet18': 7,\n",
       " 'ResNet50': 7,\n",
       " 'B4': 23,\n",
       " 'Hyperparameter': 8,\n",
       " 'Parameter': 1,\n",
       " 'optimizer': 16,\n",
       " 'rate': 13,\n",
       " 'SGD': 5,\n",
       " 'RMSPr': 1,\n",
       " 'op': 1,\n",
       " 'Adam': 8,\n",
       " 'scheduler': 13,\n",
       " 'menilai': 3,\n",
       " 'hyperparameter': 2,\n",
       " 'pen': 1,\n",
       " 'gujian': 4,\n",
       " 'menaikkan': 2,\n",
       " 'coba': 6,\n",
       " 'penggunaannya': 1,\n",
       " 'meningkat': 1,\n",
       " 'didapatkan': 2,\n",
       " 'maksimum': 5,\n",
       " 'real': 7,\n",
       " 'time': 7,\n",
       " 'export': 1,\n",
       " 'nyata': 1,\n",
       " 'webcam': 1,\n",
       " 'variasi': 2,\n",
       " 'pengujiannya': 1,\n",
       " '-masing': 3,\n",
       " 'polos': 4,\n",
       " 'belak': 1,\n",
       " 'abstrak': 9,\n",
       " '-macam': 1,\n",
       " 'warna': 2,\n",
       " 'Uji': 1,\n",
       " 'mengguna': 1,\n",
       " 'gabungan': 3,\n",
       " 'mencatat': 1,\n",
       " 'jalannya': 1,\n",
       " 'tr': 1,\n",
       " 'aining': 1,\n",
       " 'Khusus': 1,\n",
       " 'epoch': 4,\n",
       " 'konvergen': 3,\n",
       " 'cepat': 1,\n",
       " 'mencapai': 10,\n",
       " '4.1': 1,\n",
       " 'tipe': 2,\n",
       " 'ResNet1': 1,\n",
       " '8': 5,\n",
       " 'kalangan': 1,\n",
       " 'layak': 1,\n",
       " 'membandingkan': 1,\n",
       " 'trainable': 1,\n",
       " 'mencegah': 1,\n",
       " 'overfitting': 1,\n",
       " '0.001': 7,\n",
       " 'loss': 1,\n",
       " 'Cross': 1,\n",
       " 'Entropy': 1,\n",
       " 'Akurasi': 15,\n",
       " 'Train': 5,\n",
       " 'Valid': 1,\n",
       " 'ation': 1,\n",
       " 'Test': 7,\n",
       " '99,89': 3,\n",
       " '100': 24,\n",
       " '54,73': 2,\n",
       " '3585s': 2,\n",
       " '99,93': 2,\n",
       " '57,39': 3,\n",
       " '3350s': 2,\n",
       " '99,83': 2,\n",
       " '57,10': 2,\n",
       " '4167s': 2,\n",
       " 'Efficient': 1,\n",
       " 'Net': 1,\n",
       " '99,96': 8,\n",
       " '78,10': 7,\n",
       " '4924s': 4,\n",
       " 'testing': 8,\n",
       " 'tertinggi': 3,\n",
       " 'kebenarannya': 1,\n",
       " 'Effi': 1,\n",
       " 'cientNet': 1,\n",
       " 'terbesar': 2,\n",
       " 'terendah': 1,\n",
       " '0,13': 1,\n",
       " 'merata': 1,\n",
       " 'tercepat': 1,\n",
       " 'jatuh': 1,\n",
       " '3350': 1,\n",
       " 'detik': 2,\n",
       " '55': 1,\n",
       " 'menit': 2,\n",
       " 'terlama': 1,\n",
       " '4924': 1,\n",
       " 'jam': 1,\n",
       " '22': 2,\n",
       " 'dibanding': 1,\n",
       " 'pelatihannya': 1,\n",
       " 'memakan': 1,\n",
       " '4.2': 1,\n",
       " 'pengat': 1,\n",
       " 'uran': 1,\n",
       " '1165': 1,\n",
       " 'mencari': 1,\n",
       " '20': 1,\n",
       " 'Rate': 5,\n",
       " 'Opsi': 1,\n",
       " 'RMSProp': 3,\n",
       " 'Optimizer': 1,\n",
       " 'Validation': 2,\n",
       " '4,79': 1,\n",
       " '3,85': 1,\n",
       " '3,84': 1,\n",
       " '4707s': 1,\n",
       " '99,98': 1,\n",
       " '4767s': 1,\n",
       " 'Berdasarkan': 2,\n",
       " 'berkembang': 1,\n",
       " 'diduga': 3,\n",
       " 'sifat': 1,\n",
       " 'random': 1,\n",
       " 'memilih': 1,\n",
       " 'latih': 1,\n",
       " 'step': 1,\n",
       " 'dibandingkan': 6,\n",
       " 'perkembangan': 1,\n",
       " 'Epoch': 2,\n",
       " 'Konvergen': 2,\n",
       " 'LR': 2,\n",
       " '98,83': 1,\n",
       " '76,33': 1,\n",
       " 'Scheduler': 4,\n",
       " 'ke-8': 1,\n",
       " 'fluktuatif': 3,\n",
       " 'Exponential': 1,\n",
       " 'torch': 2,\n",
       " 'optim': 1,\n",
       " '9': 3,\n",
       " 'pe': 1,\n",
       " 'ngujian': 1,\n",
       " 'stabil': 1,\n",
       " 'Perubahan': 1,\n",
       " 'ter': 1,\n",
       " 'hadap': 1,\n",
       " 'teratur': 2,\n",
       " 'konsisten': 1,\n",
       " 'dibuktikan': 2,\n",
       " 'Sel': 1,\n",
       " 'ain': 1,\n",
       " 'peng': 1,\n",
       " 'gunaan': 1,\n",
       " '4.3': 1,\n",
       " 'Pen': 3,\n",
       " 'Penggunaan': 2,\n",
       " 'Pretrained': 8,\n",
       " 'Weights': 1,\n",
       " 'memanggil': 1,\n",
       " 'pemanggilan': 1,\n",
       " '1166': 1,\n",
       " 'm': 1,\n",
       " 'engetahui': 1,\n",
       " '84,91': 1,\n",
       " '3566s': 1,\n",
       " '99,04': 1,\n",
       " '75,44': 1,\n",
       " '3345s': 1,\n",
       " '99,52': 1,\n",
       " '65,09': 1,\n",
       " '4119s': 1,\n",
       " '4870s': 1,\n",
       " 'peningkatan': 7,\n",
       " 'Peningkatan': 1,\n",
       " '-beda': 1,\n",
       " 'berkisar': 1,\n",
       " 'angka': 2,\n",
       " '30': 1,\n",
       " '30,18': 1,\n",
       " 'sebesa': 1,\n",
       " 'r': 1,\n",
       " '18,05': 1,\n",
       " '7,99': 1,\n",
       " '21,9': 1,\n",
       " 'tingkat': 1,\n",
       " 'kesulitan': 1,\n",
       " '4.4': 1,\n",
       " 'menambah': 1,\n",
       " 'localization': 1,\n",
       " 'Fully': 1,\n",
       " 'Connected': 1,\n",
       " 'optimiz': 1,\n",
       " 'er': 1,\n",
       " '86,09': 1,\n",
       " '5950s': 1,\n",
       " '6537s': 1,\n",
       " '4.5': 1,\n",
       " 'Real': 1,\n",
       " '-Time': 1,\n",
       " 'kondisi': 1,\n",
       " 'tampilan': 3,\n",
       " 'efektifan': 1,\n",
       " 'digabungkan': 2,\n",
       " 'keefektifannya': 1,\n",
       " 'ya': 1,\n",
       " 'ng': 1,\n",
       " '-convert': 1,\n",
       " 'single': 1,\n",
       " 'channel': 1,\n",
       " 'mempermudah': 1,\n",
       " 'Dataset': 3,\n",
       " 'Total': 8,\n",
       " 'Latar': 5,\n",
       " 'Putih': 2,\n",
       " 'Hitam': 2,\n",
       " 'Abstrak': 1,\n",
       " '23': 4,\n",
       " '13': 2,\n",
       " '85': 2,\n",
       " '88': 4,\n",
       " '50': 4,\n",
       " '16': 1,\n",
       " '62': 2,\n",
       " 'Karpet': 1,\n",
       " '12': 5,\n",
       " '35': 4,\n",
       " '46': 2,\n",
       " 'Pemandangan': 1,\n",
       " '15': 2,\n",
       " 'Gabungan': 1,\n",
       " '26': 2,\n",
       " '1167': 1,\n",
       " 'te': 1,\n",
       " 'rlalu': 1,\n",
       " 'buruk': 4,\n",
       " 'berlatar': 5,\n",
       " 'be': 1,\n",
       " 'lakang': 1,\n",
       " 'terli': 1,\n",
       " 'hat': 1,\n",
       " 'diatas': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency = max(word_frequencies.values())\n",
    "max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word]/max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 0.09230769230769231, 'PENDAHULUAN': 0.015384615384615385, 'Bahasa': 0.07692307692307693, 'isyarat': 0.49230769230769234, 'kelompok': 0.015384615384615385, 'masyarakat': 0.06153846153846154, 'bisu': 0.1076923076923077, 'tuli': 0.1076923076923077, 'bahasa': 0.46153846153846156, 'metode': 0.13846153846153847, 'terpenting': 0.015384615384615385, 'berkomunikasi': 0.015384615384615385, 'sulit': 0.015384615384615385, 'maksud': 0.06153846153846154, 'pikiran': 0.03076923076923077, 'berkomunik': 0.015384615384615385, 'asi': 0.015384615384615385, 'orang': 0.03076923076923077, 'mengerti': 0.015384615384615385, 'memiliki': 0.35384615384615387, 'kemampuan': 0.07692307692307693, 'berko': 0.015384615384615385, 'munikasi': 0.015384615384615385, 'diekspresikan': 0.03076923076923077, 'tangan': 0.06153846153846154, 'lengan': 0.03076923076923077, 'wajah': 0.06153846153846154, 'dimengerti': 0.03076923076923077, 'mata': 0.03076923076923077, 'Pembuatan': 0.015384615384615385, 'sistem': 0.15384615384615385, 'klasifikasi': 0.13846153846153847, 'asisten': 0.015384615384615385, 'virtual': 0.015384615384615385, 'deep': 0.046153846153846156, 'learning': 0.26153846153846155, 'tensorflow': 0.015384615384615385, 'Kesimpulan': 0.046153846153846156, 'penelitian': 0.16923076923076924, 'mendeteksi': 0.12307692307692308, 'dataset': 0.5538461538461539, 'bentuk': 0.09230769230769231, 'dunia': 0.015384615384615385, 'regional': 0.015384615384615385, 'lokasi': 0.015384615384615385, 'latar': 0.47692307692307695, 'mendukun': 0.015384615384615385, 'g': 0.015384615384615385, 'mengambil': 0.046153846153846156, 'gambar': 0.18461538461538463, 'sembarang': 0.015384615384615385, 'Penelitian': 0.07692307692307693, 'memfokuskan': 0.015384615384615385, 'pembuatan': 0.015384615384615385, 'aplikasinya': 0.015384615384615385, 'akurasi': 0.46153846153846156, 'performa': 0.07692307692307693, 'mendalam': 0.03076923076923077, 'mend': 0.015384615384615385, 'alami': 0.015384615384615385, 'model': 1.0, '-nya': 0.12307692307692308, 'deteksi': 0.015384615384615385, 'citra': 0.09230769230769231, 'Covid': 0.015384615384615385, '19': 0.015384615384615385, 'teta': 0.015384615384615385, 'pi': 0.015384615384615385, 'terbaik': 0.16923076923076924, 'dijadikan': 0.015384615384615385, 'penulis': 0.06153846153846154, 'referensi': 0.015384615384615385, 'elemen': 0.03076923076923077, 'diperhatikan': 0.03076923076923077, 'cahaya': 0.015384615384615385, 'pose': 0.07692307692307693, 'angle': 0.015384615384615385, 'posisi': 0.015384615384615385, 'kamera': 0.03076923076923077, 'da': 0.015384615384615385, 'n': 0.015384615384615385, 'mudah': 0.03076923076923077, 'hasil': 0.38461538461538464, 'sempurna': 0.03076923076923077, 'CNN': 0.18461538461538463, 'pembelajaran': 0.03076923076923077, 'fiturnya': 0.015384615384615385, 'kuat': 0.015384615384615385, 'bertahan': 0.015384615384615385, 'lingkungan': 0.015384615384615385, 'kompleks': 0.015384615384615385, 'diaplikasikan': 0.015384615384615385, 'kesimpulan': 0.015384615384615385, 'ketiga': 0.03076923076923077, 'X': 0.07692307692307693, '-Ray': 0.015384615384615385, 'CT': 0.015384615384615385, 'Scan': 0.015384615384615385, 'radiografi': 0.015384615384615385, 'dada': 0.015384615384615385, 'membantu': 0.046153846153846156, 'penyakit': 0.03076923076923077, 'men': 0.015384615384615385, 'ggunakan': 0.015384615384615385, 'Transfer': 0.06153846153846154, 'Learning': 0.2, 'PyTorch': 0.046153846153846156, 'memuaskan': 0.046153846153846156, '97,78': 0.015384615384615385, 'Hasil': 0.2153846153846154, 'menjadikan': 0.046153846153846156, 'tertarik': 0.015384615384615385, 'dicoba': 0.046153846153846156, 'aplikasi': 0.09230769230769231, 'rekognisi': 0.06153846153846154, 'isyara': 0.015384615384615385, 't.': 0.015384615384615385, 'penggunaan': 0.15384615384615385, 'Spatial': 0.4461538461538462, 'Transformer': 0.4461538461538462, 'optimisasi': 0.015384615384615385, 'stokastik': 0.03076923076923077, 'rambu': 0.015384615384615385, 'lintas': 0.015384615384615385, 'sebe': 0.015384615384615385, 'sar': 0.015384615384615385, '99,71': 0.015384615384615385, 'data': 0.6, 'uji': 0.16923076923076924, '12.630': 0.015384615384615385, 'mencoba': 0.07692307692307693, 'meningkatkan': 0.046153846153846156, 'mengusulkan': 0.015384615384615385, 'dikembangkan': 0.03076923076923077, 'reko': 0.015384615384615385, 'gnisi': 0.015384615384615385, 'digital': 0.07692307692307693, 'mengenali': 0.03076923076923077, 'Convolutional': 0.12307692307692308, 'Neural': 0.12307692307692308, 'Network': 0.13846153846153847, 'Deep': 0.046153846153846156, 'Machine': 0.015384615384615385, 'dimasukkan': 0.06153846153846154, 'luaran': 0.015384615384615385, 'sesuai': 0.046153846153846156, '2': 0.06153846153846154, 'METODE': 0.015384615384615385, 'PENELITIAN': 0.015384615384615385, '2.1': 0.015384615384615385, 'Data': 0.15384615384615385, 'training': 0.15384615384615385, 'sekunder': 0.06153846153846154, 'open': 0.015384615384615385, 'source': 0.015384615384615385, 'halaman': 0.015384615384615385, 'web': 0.07692307692307693, 'menyediakan': 0.03076923076923077, '-dataset': 0.03076923076923077, 'gratis': 0.015384615384615385, 'legal': 0.015384615384615385, 'tema': 0.015384615384615385, 'situs': 0.046153846153846156, 'set': 0.03076923076923077, 'bernama': 0.015384615384615385, 'Kaggle': 0.046153846153846156, 'background': 0.2923076923076923, 'hitam': 0.24615384615384617, 'putih': 0.23076923076923078, 'publik': 0.03076923076923077, '70': 0.015384615384615385, '21': 0.015384615384615385, 'internet': 0.03076923076923077, 'diambil': 0.09230769230769231, 'pribadi': 0.03076923076923077, 'Pengambilan': 0.015384615384615385, 'Mahardika': 0.06153846153846154, 'dkk': 0.06153846153846154, 'Sistem': 0.06153846153846154, 'Rekognisi': 0.06153846153846154, 'Citra': 0.06153846153846154, 'Digital': 0.06153846153846154, '1161': 0.015384615384615385, 'menguji': 0.046153846153846156, 'perbedaan': 0.03076923076923077, 'pengujian': 0.4307692307692308, 'berbeda': 0.06153846153846154, 'pengaruh': 0.09230769230769231, 'dimiliki': 0.015384615384615385, 'percobaan': 0.015384615384615385, 'permasalahan': 0.015384615384615385, 'gamb': 0.015384615384615385, 'ar': 0.015384615384615385, 'bervariasi': 0.015384615384615385, 'karpet': 0.06153846153846154, 'bermot': 0.015384615384615385, 'if': 0.015384615384615385, 'Gambar': 0.07692307692307693, '3': 0.09230769230769231, 'pemandangan': 0.07692307692307693, 'pagi': 0.015384615384615385, '54': 0.015384615384615385, '40': 0.015384615384615385, 'menggabungkan': 0.015384615384615385, 'keempat': 0.12307692307692308, 'validation': 0.09230769230769231, 'bunga': 0.03076923076923077, 'langit': 0.03076923076923077, 'merah': 0.03076923076923077, 'gunung': 0.03076923076923077, 'Penyusunan': 0.015384615384615385, 'alfabet': 0.1076923076923077, 'ditambah': 0.015384615384615385, 'unt': 0.015384615384615385, 'uk': 0.015384615384615385, '338': 0.015384615384615385, 'total': 0.1076923076923077, 'perancangan': 0.03076923076923077, 'diawali': 0.015384615384615385, 'pemrosesan': 0.03076923076923077, 'mengubah': 0.015384615384615385, 'mensi': 0.015384615384615385, 'mengkonversi': 0.015384615384615385, 'berbentuk': 0.015384615384615385, 'Tensor': 0.015384615384615385, 'input': 0.2, 'dibuatlah': 0.015384615384615385, 'arsitektur': 0.2153846153846154, 'Penentuan': 0.015384615384615385, 'Arsitektur': 0.046153846153846156, 'memasukan': 0.015384615384615385, 'lapisan': 0.26153846153846155, '-lapisan': 0.046153846153846156, 'neural': 0.06153846153846154, 'network': 0.06153846153846154, 'modul': 0.046153846153846156, 'tambahkan': 0.015384615384615385, 'utama': 0.1076923076923077, 'melewati': 0.046153846153846156, 'memasuki': 0.03076923076923077, 'ditentukan': 0.015384615384615385, 'proses': 0.16923076923076924, 'pelatihan': 0.18461538461538463, 'Training': 0.09230769230769231, 'tujuan': 0.046153846153846156, 'pengetahuan': 0.015384615384615385, 'dibutuhkannya': 0.015384615384615385, 'mengklasifikasikan': 0.03076923076923077, 'merekognisi': 0.03076923076923077, 'menentukan': 0.046153846153846156, 'ki': 0.015384615384615385, 'nerja': 0.015384615384615385, 'pekerjaan': 0.015384615384615385, 'mengklasifikasi': 0.015384615384615385, 'kinerja': 0.03076923076923077, 'perbaikan': 0.015384615384615385, 'Tweaking': 0.015384615384615385, 'tar': 0.015384615384615385, 'get': 0.015384615384615385, 'dicari': 0.015384615384615385, 'nilai': 0.24615384615384617, 'Alur': 0.015384615384615385, '1162': 0.015384615384615385, 'Jurnal': 0.046153846153846156, 'Teknologi': 0.046153846153846156, 'Informasi': 0.046153846153846156, 'Ilmu': 0.046153846153846156, 'Komputer': 0.046153846153846156, 'JTIIK': 0.046153846153846156, 'Vol': 0.046153846153846156, '11': 0.046153846153846156, 'No': 0.046153846153846156, '6': 0.12307692307692308, 'Desember': 0.046153846153846156, '2024': 0.046153846153846156, 'hlm.1159': 0.046153846153846156, '-1168': 0.046153846153846156, 'pretrained': 0.12307692307692308, 'weights': 0.15384615384615385, 'disediakan': 0.046153846153846156, 'library': 0.06153846153846154, 'Contoh': 0.03076923076923077, 'ResNet': 0.015384615384615385, 'AlexNet': 0.13846153846153847, 'EfficientNet': 0.3384615384615385, 'Model': 0.18461538461538463, 'dilatih': 0.06153846153846154, 'ImageNet': 0.015384615384615385, '-1k': 0.015384615384615385, 'penambahan': 0.015384615384615385, 'lapis': 0.015384615384615385, 'an': 0.015384615384615385, 'Localization': 0.1076923076923077, 'fully': 0.015384615384615385, 'connected': 0.015384615384615385, 'sampler': 0.015384615384615385, 'Penambahan': 0.015384615384615385, 'diposisikan': 0.015384615384615385, 'tepatnya': 0.015384615384615385, 'ditransformasi': 0.015384615384615385, 'lap': 0.015384615384615385, 'isan': 0.015384615384615385, 'DASAR': 0.015384615384615385, 'TEORI': 0.015384615384615385, '3.1': 0.015384615384615385, 'Isyarat': 0.015384615384615385, 'struktur': 0.015384615384615385, 'peraturan': 0.015384615384615385, 'kalimat': 0.015384615384615385, 'percakapan': 0.03076923076923077, 'dimana': 0.06153846153846154, 'beserta': 0.015384615384615385, 'jari': 0.015384615384615385, 'jarinya': 0.015384615384615385, 'membentuk': 0.015384615384615385, 'unik': 0.015384615384615385, 's': 0.015384615384615385, 'ehingga': 0.015384615384615385, 'dikenali': 0.015384615384615385, 'negara': 0.06153846153846154, 'American': 0.015384615384615385, 'Sign': 0.07692307692307693, 'Language': 0.07692307692307693, 'ASL': 0.015384615384615385, 'y': 0.16923076923076924, 'ang': 0.03076923076923077, 'populer': 0.046153846153846156, 'berasal': 0.03076923076923077, 'Amerika': 0.015384615384615385, 'Serikat': 0.015384615384615385, 'Inggris': 0.015384615384615385, 'British': 0.015384615384615385, 'BSL': 0.015384615384615385, 'Australian': 0.015384615384615385, 'Auslan': 0.015384615384615385, 'Italian': 0.015384615384615385, 'LIS': 0.015384615384615385, 'Japanese': 0.015384615384615385, 'JSL': 0.015384615384615385, '3.2': 0.015384615384615385, 'jaringan': 0.07692307692307693, 'saraf': 0.015384615384615385, 'neuron': 0.015384615384615385, 'sepenuhnya': 0.015384615384615385, 'tersambung': 0.015384615384615385, 'berisi': 0.015384615384615385, 'convolutional': 0.046153846153846156, 'sampling': 0.046153846153846156, 'sub': 0.015384615384615385, 'tersembunyi': 0.015384615384615385, 'convolution': 0.015384615384615385, 'diikuti': 0.015384615384615385, 'penghitung': 0.015384615384615385, 'pemerataan': 0.015384615384615385, 'ekstraksi': 0.015384615384615385, 'perhitungan': 0.03076923076923077, 'H(x': 0.03076923076923077, 'b': 0.06153846153846154, 'F(x': 0.03076923076923077, 'G(x': 0.06153846153846154, 'F(j': 0.03076923076923077, 'k': 0.1076923076923077, 'j': 0.09230769230769231, 'Keterangan': 0.046153846153846156, 'F': 0.03076923076923077, 'Filter': 0.015384615384615385, 'Lapisan': 0.03076923076923077, 'G': 0.046153846153846156, 'Input': 0.015384615384615385, 'feature': 0.18461538461538463, 'map': 0.23076923076923078, 'H': 0.03076923076923077, 'Output': 0.06153846153846154, 'Bias': 0.015384615384615385, 'x': 0.03076923076923077, 'Sumbu': 0.09230769230769231, 'filter': 0.03076923076923077, 'Y': 0.06153846153846154, 'Increment': 0.03076923076923077, 'sumbu': 0.06153846153846154, 'konvolusi': 0.046153846153846156, 'Kernel': 0.015384615384615385, 'pengali': 0.015384615384615385, 'dikalikan': 0.015384615384615385, 'kernel': 0.015384615384615385, 'hasilnya': 0.03076923076923077, 'dijumlahkan': 0.03076923076923077, 'ukuran': 0.015384615384615385, 'k.': 0.015384615384615385, 'penjumlahan': 0.046153846153846156, 'bias': 0.015384615384615385, 'output': 0.16923076923076924, 'Perhitungan': 0.07692307692307693, 'dilanjutkan': 0.015384615384615385, 'pixel': 0.046153846153846156, '3.3': 0.015384615384615385, 'salah': 0.03076923076923077, 'teknik': 0.03076923076923077, 'tahap': 0.015384615384615385, 'mengekstrak': 0.03076923076923077, 'tuning': 0.015384615384615385, 'memperbaiki': 0.015384615384615385, 'Keuntungan': 0.015384615384615385, 'terletak': 0.015384615384615385, 'penghematan': 0.03076923076923077, 'penjalanan': 0.015384615384615385, 'resource': 0.015384615384615385, 'me': 0.015384615384615385, 'nggunakan': 0.015384615384615385, 'Teknik': 0.015384615384615385, 'objek': 0.015384615384615385, '3.4': 0.015384615384615385, 'manipulasi': 0.015384615384615385, 'spasial': 0.03076923076923077, 'Modul': 0.015384615384615385, 'dibedakan': 0.015384615384615385, 'aktif': 0.015384615384615385, 'mentransformasikan': 0.015384615384615385, 'tergantung': 0.015384615384615385, 'pengawasan': 0.015384615384615385, 'tambahan': 0.015384615384615385, 'modifikasi': 0.015384615384615385, 'pengoptimalan': 0.015384615384615385, 'Tahapan': 0.015384615384615385, 'digambarkan': 0.015384615384615385, '1163': 0.015384615384615385, '7': 0.07692307692307693, 'mekanisme': 0.015384615384615385, 'dibagi': 0.015384615384615385, 'Sampling': 0.046153846153846156, 'Grid': 0.09230769230769231, 'Sampler': 0.06153846153846154, 'Jaringan': 0.015384615384615385, 'mengeluarkan': 0.015384615384615385, 'parameter': 0.07692307692307693, 'transformasi': 0.09230769230769231, 'Teta': 0.03076923076923077, 'θ': 0.09230769230769231, 'diterapkan': 0.03076923076923077, 'hidden': 0.015384615384615385, 'layer': 0.015384615384615385, 'sekumpulan': 0.015384615384615385, 'titik': 0.1076923076923077, 'sampelnya': 0.015384615384615385, 'menghasilkan': 0.03076923076923077, 'diubah': 0.015384615384615385, 'generator': 0.03076923076923077, 'grid': 0.06153846153846154, 'komponen': 0.03076923076923077, 'fungsi': 0.015384615384615385, 'eksklusif': 0.015384615384615385, 'invers': 0.015384615384615385, 'dihasilkan': 0.015384615384615385, 'Generator': 0.015384615384615385, 'Tujuan': 0.03076923076923077, '-sampling': 0.015384615384615385, '-titik': 0.03076923076923077, 'mengulangi': 0.015384615384615385, 'entri': 0.015384615384615385, 'pengambilan': 0.015384615384615385, 'sampel': 0.03076923076923077, 'interpolasi': 0.015384615384615385, 'bilinear': 0.015384615384615385, 'tahapan': 0.015384615384615385, 'diteruskan': 0.015384615384615385, 'setelahnya': 0.015384615384615385, 'xis': 0.046153846153846156, 'yis': 0.046153846153846156, 'τθ(Gi': 0.015384615384615385, 'Aθ(xit': 0.015384615384615385, 'yit': 0.06153846153846154, 'θ1,1θ1,2θ1,3': 0.015384615384615385, 'θ2,1θ2,3θ2,3': 0.015384615384615385, 'xit': 0.046153846153846156, 'τθ': 0.015384615384615385, 'Transformasi': 0.046153846153846156, 'Afin': 0.03076923076923077, '2D': 0.015384615384615385, 'Aθ': 0.06153846153846154, 'Gi': 0.03076923076923077, 'Feature': 0.015384615384615385, 'Map': 0.015384615384615385, 'Matriks': 0.015384615384615385, 'Sumber': 0.03076923076923077, 'Kordinat': 0.09230769230769231, 'Target': 0.03076923076923077, 'Luaran': 0.015384615384615385, 'target': 0.03076923076923077, 'kordinat': 0.03076923076923077, 'sumber': 0.015384615384615385, 'penentu': 0.015384615384615385, 'matriks': 0.015384615384615385, 'afin': 0.015384615384615385, 'didefinisikan': 0.015384615384615385, 'cropping': 0.015384615384615385, 'translation': 0.015384615384615385, 'rotation': 0.015384615384615385, 'scale': 0.015384615384615385, 'skew': 0.015384615384615385, 'membutuhkan': 0.03076923076923077, 'diproduksi': 0.015384615384615385, '3.5': 0.03076923076923077, 'Confusion': 0.046153846153846156, 'Matrix': 0.046153846153846156, 'pengukuran': 0.015384615384615385, 'machine': 0.015384615384615385, 'kelas': 0.03076923076923077, 'tabel': 0.015384615384615385, 'kombinasi': 0.07692307692307693, 'prediksi': 0.09230769230769231, 'Keempat': 0.03076923076923077, 'True': 0.16923076923076924, 'Positive': 0.16923076923076924, 'TP': 0.2153846153846154, 'False': 0.12307692307692308, 'FP': 0.1076923076923077, 'Negative': 0.1076923076923077, 'TN': 0.09230769230769231, 'Positif': 0.03076923076923077, 'Negatif': 0.03076923076923077, 'Prediksi': 0.03076923076923077, 'Tabel': 0.15384615384615385, 'metrik': 0.06153846153846154, '-metrik': 0.015384615384615385, 'mengevaluasi': 0.03076923076923077, 'Metrik': 0.03076923076923077, 'Accuracy': 0.03076923076923077, 'Precision': 0.07692307692307693, 'Recall': 0.07692307692307693, 'F1': 0.046153846153846156, 'Score': 0.046153846153846156, 'rumus': 0.015384615384615385, 'persamaan': 0.03076923076923077, 'FN': 0.07692307692307693, '4': 0.06153846153846154, '5': 0.046153846153846156, 'membagi': 0.046153846153846156, 'keefektifan': 0.046153846153846156, 'kesepakatan': 0.015384615384615385, 'label': 0.06153846153846154, 'positif': 0.06153846153846154, 'o': 0.015384615384615385, 'leh': 0.015384615384615385, '1164': 0.015384615384615385, 'mengidentifikasi': 0.015384615384615385, 'mengeta': 0.015384615384615385, 'hui': 0.015384615384615385, 'hubungan': 0.015384615384615385, 'dilabelkan': 0.015384615384615385, 'Flask': 0.046153846153846156, 'kerangka': 0.015384615384615385, 'kerja': 0.015384615384615385, 'alat': 0.015384615384615385, 'pustaka': 0.015384615384615385, 'teknologi': 0.015384615384615385, 'meru': 0.015384615384615385, 'pakan': 0.015384615384615385, 'python': 0.015384615384615385, 'berbasis': 0.015384615384615385, 'flask': 0.015384615384615385, 'diintegrasikan': 0.015384615384615385, 'HASIL': 0.015384615384615385, 'PEMBAHASAN': 0.015384615384615385, 'Pengujian': 0.3384615384615385, 'diuji': 0.18461538461538463, 'pengaturan': 0.07692307692307693, '-model': 0.015384615384615385, 'ResNet18': 0.1076923076923077, 'ResNet50': 0.1076923076923077, 'B4': 0.35384615384615387, 'Hyperparameter': 0.12307692307692308, 'Parameter': 0.015384615384615385, 'optimizer': 0.24615384615384617, 'rate': 0.2, 'SGD': 0.07692307692307693, 'RMSPr': 0.015384615384615385, 'op': 0.015384615384615385, 'Adam': 0.12307692307692308, 'scheduler': 0.2, 'menilai': 0.046153846153846156, 'hyperparameter': 0.03076923076923077, 'pen': 0.015384615384615385, 'gujian': 0.06153846153846154, 'menaikkan': 0.03076923076923077, 'coba': 0.09230769230769231, 'penggunaannya': 0.015384615384615385, 'meningkat': 0.015384615384615385, 'didapatkan': 0.03076923076923077, 'maksimum': 0.07692307692307693, 'real': 0.1076923076923077, 'time': 0.1076923076923077, 'export': 0.015384615384615385, 'nyata': 0.015384615384615385, 'webcam': 0.015384615384615385, 'variasi': 0.03076923076923077, 'pengujiannya': 0.015384615384615385, '-masing': 0.046153846153846156, 'polos': 0.06153846153846154, 'belak': 0.015384615384615385, 'abstrak': 0.13846153846153847, '-macam': 0.015384615384615385, 'warna': 0.03076923076923077, 'Uji': 0.015384615384615385, 'mengguna': 0.015384615384615385, 'gabungan': 0.046153846153846156, 'mencatat': 0.015384615384615385, 'jalannya': 0.015384615384615385, 'tr': 0.015384615384615385, 'aining': 0.015384615384615385, 'Khusus': 0.015384615384615385, 'epoch': 0.06153846153846154, 'konvergen': 0.046153846153846156, 'cepat': 0.015384615384615385, 'mencapai': 0.15384615384615385, '4.1': 0.015384615384615385, 'tipe': 0.03076923076923077, 'ResNet1': 0.015384615384615385, '8': 0.07692307692307693, 'kalangan': 0.015384615384615385, 'layak': 0.015384615384615385, 'membandingkan': 0.015384615384615385, 'trainable': 0.015384615384615385, 'mencegah': 0.015384615384615385, 'overfitting': 0.015384615384615385, '0.001': 0.1076923076923077, 'loss': 0.015384615384615385, 'Cross': 0.015384615384615385, 'Entropy': 0.015384615384615385, 'Akurasi': 0.23076923076923078, 'Train': 0.07692307692307693, 'Valid': 0.015384615384615385, 'ation': 0.015384615384615385, 'Test': 0.1076923076923077, '99,89': 0.046153846153846156, '100': 0.36923076923076925, '54,73': 0.03076923076923077, '3585s': 0.03076923076923077, '99,93': 0.03076923076923077, '57,39': 0.046153846153846156, '3350s': 0.03076923076923077, '99,83': 0.03076923076923077, '57,10': 0.03076923076923077, '4167s': 0.03076923076923077, 'Efficient': 0.015384615384615385, 'Net': 0.015384615384615385, '99,96': 0.12307692307692308, '78,10': 0.1076923076923077, '4924s': 0.06153846153846154, 'testing': 0.12307692307692308, 'tertinggi': 0.046153846153846156, 'kebenarannya': 0.015384615384615385, 'Effi': 0.015384615384615385, 'cientNet': 0.015384615384615385, 'terbesar': 0.03076923076923077, 'terendah': 0.015384615384615385, '0,13': 0.015384615384615385, 'merata': 0.015384615384615385, 'tercepat': 0.015384615384615385, 'jatuh': 0.015384615384615385, '3350': 0.015384615384615385, 'detik': 0.03076923076923077, '55': 0.015384615384615385, 'menit': 0.03076923076923077, 'terlama': 0.015384615384615385, '4924': 0.015384615384615385, 'jam': 0.015384615384615385, '22': 0.03076923076923077, 'dibanding': 0.015384615384615385, 'pelatihannya': 0.015384615384615385, 'memakan': 0.015384615384615385, '4.2': 0.015384615384615385, 'pengat': 0.015384615384615385, 'uran': 0.015384615384615385, '1165': 0.015384615384615385, 'mencari': 0.015384615384615385, '20': 0.015384615384615385, 'Rate': 0.07692307692307693, 'Opsi': 0.015384615384615385, 'RMSProp': 0.046153846153846156, 'Optimizer': 0.015384615384615385, 'Validation': 0.03076923076923077, '4,79': 0.015384615384615385, '3,85': 0.015384615384615385, '3,84': 0.015384615384615385, '4707s': 0.015384615384615385, '99,98': 0.015384615384615385, '4767s': 0.015384615384615385, 'Berdasarkan': 0.03076923076923077, 'berkembang': 0.015384615384615385, 'diduga': 0.046153846153846156, 'sifat': 0.015384615384615385, 'random': 0.015384615384615385, 'memilih': 0.015384615384615385, 'latih': 0.015384615384615385, 'step': 0.015384615384615385, 'dibandingkan': 0.09230769230769231, 'perkembangan': 0.015384615384615385, 'Epoch': 0.03076923076923077, 'Konvergen': 0.03076923076923077, 'LR': 0.03076923076923077, '98,83': 0.015384615384615385, '76,33': 0.015384615384615385, 'Scheduler': 0.06153846153846154, 'ke-8': 0.015384615384615385, 'fluktuatif': 0.046153846153846156, 'Exponential': 0.015384615384615385, 'torch': 0.03076923076923077, 'optim': 0.015384615384615385, '9': 0.046153846153846156, 'pe': 0.015384615384615385, 'ngujian': 0.015384615384615385, 'stabil': 0.015384615384615385, 'Perubahan': 0.015384615384615385, 'ter': 0.015384615384615385, 'hadap': 0.015384615384615385, 'teratur': 0.03076923076923077, 'konsisten': 0.015384615384615385, 'dibuktikan': 0.03076923076923077, 'Sel': 0.015384615384615385, 'ain': 0.015384615384615385, 'peng': 0.015384615384615385, 'gunaan': 0.015384615384615385, '4.3': 0.015384615384615385, 'Pen': 0.046153846153846156, 'Penggunaan': 0.03076923076923077, 'Pretrained': 0.12307692307692308, 'Weights': 0.015384615384615385, 'memanggil': 0.015384615384615385, 'pemanggilan': 0.015384615384615385, '1166': 0.015384615384615385, 'm': 0.015384615384615385, 'engetahui': 0.015384615384615385, '84,91': 0.015384615384615385, '3566s': 0.015384615384615385, '99,04': 0.015384615384615385, '75,44': 0.015384615384615385, '3345s': 0.015384615384615385, '99,52': 0.015384615384615385, '65,09': 0.015384615384615385, '4119s': 0.015384615384615385, '4870s': 0.015384615384615385, 'peningkatan': 0.1076923076923077, 'Peningkatan': 0.015384615384615385, '-beda': 0.015384615384615385, 'berkisar': 0.015384615384615385, 'angka': 0.03076923076923077, '30': 0.015384615384615385, '30,18': 0.015384615384615385, 'sebesa': 0.015384615384615385, 'r': 0.015384615384615385, '18,05': 0.015384615384615385, '7,99': 0.015384615384615385, '21,9': 0.015384615384615385, 'tingkat': 0.015384615384615385, 'kesulitan': 0.015384615384615385, '4.4': 0.015384615384615385, 'menambah': 0.015384615384615385, 'localization': 0.015384615384615385, 'Fully': 0.015384615384615385, 'Connected': 0.015384615384615385, 'optimiz': 0.015384615384615385, 'er': 0.015384615384615385, '86,09': 0.015384615384615385, '5950s': 0.015384615384615385, '6537s': 0.015384615384615385, '4.5': 0.015384615384615385, 'Real': 0.015384615384615385, '-Time': 0.015384615384615385, 'kondisi': 0.015384615384615385, 'tampilan': 0.046153846153846156, 'efektifan': 0.015384615384615385, 'digabungkan': 0.03076923076923077, 'keefektifannya': 0.015384615384615385, 'ya': 0.015384615384615385, 'ng': 0.015384615384615385, '-convert': 0.015384615384615385, 'single': 0.015384615384615385, 'channel': 0.015384615384615385, 'mempermudah': 0.015384615384615385, 'Dataset': 0.046153846153846156, 'Total': 0.12307692307692308, 'Latar': 0.07692307692307693, 'Putih': 0.03076923076923077, 'Hitam': 0.03076923076923077, 'Abstrak': 0.015384615384615385, '23': 0.06153846153846154, '13': 0.03076923076923077, '85': 0.03076923076923077, '88': 0.06153846153846154, '50': 0.06153846153846154, '16': 0.015384615384615385, '62': 0.03076923076923077, 'Karpet': 0.015384615384615385, '12': 0.07692307692307693, '35': 0.06153846153846154, '46': 0.03076923076923077, 'Pemandangan': 0.015384615384615385, '15': 0.03076923076923077, 'Gabungan': 0.015384615384615385, '26': 0.03076923076923077, '1167': 0.015384615384615385, 'te': 0.015384615384615385, 'rlalu': 0.015384615384615385, 'buruk': 0.06153846153846154, 'berlatar': 0.07692307692307693, 'be': 0.015384615384615385, 'lakang': 0.015384615384615385, 'terli': 0.015384615384615385, 'hat': 0.015384615384615385, 'diatas': 0.015384615384615385}\n"
     ]
    }
   ],
   "source": [
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. PENDAHULUAN Bahasa isyarat merupakan hal yang sangat penting bagi suatu kelompok masyarakat, yaitu masyarakat bisu atau tuli., Untuk masyarakat yang bisu atau tuli, bahasa isyarat adalah metode terpenting untuk berkomunikasi., Tanpa adanya bahasa isyarat, akan sulit bagi mereka yang bisu atau tuli untuk dapat menyatakan maksud atau pikiran mereka., Untuk dapat berkomunik asi dengan masyarakat bisu atau tuli, orang yang tidak bisu atau tuli memerlukan bahasa isyarat tersebut untuk dapat mengerti maksud atau pikiran mereka yang bisu atau tuli., Setiap orang harus memiliki kemampuan menggunakan bahasa isyarat, agar dapat berko munikasi dengan mereka yang bisu atau tuli., Bahasa isyarat diekspresikan menggunakan tangan, lengan, serta wajah dan dimengerti menggunakan mata., Pembuatan sistem klasifikasi bahasa isyarat sebelumnya pernah dilakukan oleh yang membuat asisten virtual untuk bahasa isyarat menggunakan deep learning dan tensorflow., Kesimpulan dari penelitian ini adalah untuk dapat mendeteksi bahasa isyarat, diperlukan dataset tertentu untuk setiap bentuk bahasa isyarat., Hal ini dikarenakan terdapat banyak bentuk bahasa isyarat di dunia, sehingga untuk dapat mendeteksi bahasa isyarat yang ada pada regional tertentu, diperlukan dataset bahasa isyarat dari lokasi tersebut., Selain itu, diperlukan pula latar belakang yang mendukun g ketika mengambil gambar, sehingga tidak dapat digunakan di sembarang tempat., Penelitian ini lebih memfokuskan terhadap pembuatan aplikasinya, sehingga tidak terlalu menunjukkan terhadap akurasi atau performa yang lebih mendalam., Penelitian lain yang mend alami performa dari model deep learning -nya yaitu oleh tentang klasifikasi wajah dan penelitian oleh tentang deteksi citra Covid - 19., Kedua penelitian ini tidak melakukan klasifikasi terhadap bahasa isyarat, teta pi metode untuk mendapatkan performa yang terbaik dijadikan penulis sebagai referensi., Kesimpulan dari penelitian kedua adalah untuk dapat mendeteksi wajah, ada sangat banyak elemen yang perlu diperhatikan seperti cahaya, pose, angle atau posisi kamera, da n lainnya., Tidak akan mudah untuk dapat mendapatkan hasil yang sempurna, tetapi CNN mampu mendapatkan hasil yang baik dikarenakan pembelajaran fiturnya yang kuat, sehingga mampu bertahan pada lingkungan yang kompleks., Hal yang sama juga dapat diaplikasikan terhadap bahasa isyarat, sebagaimana disebutkan pada kesimpulan penelitian pertama., Kesimpulan dari penelitian ketiga adalah X -Ray serta CT-Scan yang termasuk kepada radiografi dada sangatlah membantu untuk mendeteksi penyakit - penyakit, dan penelitian men ggunakan Transfer Learning dari PyTorch tadi mendapatkan hasil yang memuaskan, dengan akurasi sebesar 97,78., Hasil ini sangat memuaskan dan menjadikan penulis tertarik pada metode yang digunakan untuk dicoba diberikan pada aplikasi rekognisi bahasa isyara t. Penelitian terakhir adalah tentang penggunaan metode Spatial Transformer dan optimisasi stokastik pada rekognisi rambu lalu lintas oleh., Penelitian ini menggunakan metode Spatial Transformer dan mampu mendapatkan akurasi sebe sar 99,71 pada dataset dengan jumlah data uji sebanyak 12.630., Hasil ini menunjukkan kalau metode Spatial Transformer pantas untuk digunakan untuk mencoba meningkatkan akurasi dari penelitian., Oleh karena itu, penulis mengusulkan dikembangkan sistem reko gnisi citra digital untuk dapat mengenali bahasa isyarat tersebut., Dengan menggunakan metode Convolutional Neural Network (CNN), yang merupakan bagian dari Deep Learning atau Machine Learning dan dengan metode Spatial Transformer, sistem akan mengenali pose atau bentuk dari citra bahasa isyarat yang dimasukkan, dan memberikan luaran yang sesuai dengan maksud dari pose atau bentuk dari citra bahasa isyarat tersebut., 2. METODE PENELITIAN 2.1 Data Penelitian Data yang digunakan untuk training model adalah data sekunder yang didapat, secara open - source dari berbagai halaman web tertentu yang menyediakan dataset -dataset secara gratis dan legal., Untuk penelitian ini, digunakan dataset -dataset dengan tema bahasa isyarat., Adapun situs yang menyediakan set data tersebut bernama Kaggle., Data sekunder yang akan digunakan ada dua macam, yaitu data bahasa isyarat dengan background hitam dan data bahasa isyarat dengan background putih., Data dengan background hitam merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada data dengan background putih juga merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada hitam memiliki jumlah sebanyak 70 gambar, sedangkan dataset background putih memiliki jumlah sebanyak 21 gambar., Selain data sekunder dari internet, digunakan pula data yang diambil oleh penulis secara pribadi., Pengambilan data pribadi ini dilakukan untuk Mahardika, dkk, Sistem Rekognisi Citra Digital 1161 menguji adanya perbedaan hasil pada pengujian apabila menggunakan data dengan background yang berbeda dan mengetahui seberapa besar pengaruh yang dimiliki oleh background tersebut terhadap keseluruhan percobaan, sebagaimana permasalahan ini disebutkan sebelumnya oleh., Data gamb ar yang diambil akan memiliki pose dan bentuk bahasa isyarat yang sama dengan data sekunder dari internet tersebut, tetapi akan memiliki background yang bervariasi., Data yang diambil memiliki dua macam background, yaitu data dengan background karpet bermot if ditunjukkan pada Gambar 3 dan data dengan background pemandangan pagi ditunjukkan pada background karpet memiliki jumlah sebanyak 54 gambar, sedangkan dataset background pemandangan memiliki jumlah sebanyak 40 gambar., Data uji yang akan digunakan adalah dataset yang menggabungkan keempat dataset yang digunakan untuk training dan validation., Selain itu, ditambahkan pula tiga set gambar yang tidak berada dalam data training maupun validation, yaitu dataset dengan background bunga, dataset dengan background langit merah, dan dataset dengan background gunung., Penyusunan dataset uji per alfabet adalah satu gambar dari setiap dataset background hitam, putih, karpet, dan pemandangan ditambah tiga gambar dari setiap dataset background bunga, langit merah, dan gunung sebagaimana ditunjukkan pada gambar unt uk setiap alfabet, menjadikan 338 total gambar data uji., Pada perancangan model Convolutional Neural Network dari sistem rekognisi citra digital bahasa isyarat diawali dengan adanya pemrosesan awal dengan mengubah di mensi dari data dan juga mengkonversi data menjadi berbentuk Tensor agar dapat diberikan sebagai input kepada model CNN., Setelah dilakukan pemrosesan awal, dibuatlah arsitektur dari model CNN yang akan melakukan pembelajaran mendalam atau Deep Learning., Penentuan Arsitektur dari model CNN ini dilakukan dengan memasukan lapisan -lapisan, neural network yang terbaik untuk data yang digunakan., Dalam arsitektur model akan ditambahkan modul Spatial Transformer, yang di tambahkan sebelum bagian utama dari neural network., Data akan melewati lapisan -lapisan Spatial Transformer terlebih dahulu sebelum memasuki bagian neural network utama., Setelah arsitektur dari model CNN telah ditentukan, dilakukan proses pelatihan atau Training pada dataset., Training atau pelatihan dilakukan dengan tujuan memberikan model pengetahuan yang dibutuhkannya untuk dapat mengklasifikasikan dan merekognisi data digital., Terakhir, dilakukan pengujian dengan data uji untuk menentukan seberapa baik ki nerja model dalam pekerjaan mengklasifikasi dan merekognisi dataset digital tersebut., Apabila kinerja model masih kurang baik, maka perlu dilakukan perbaikan atau Tweaking pada model dengan tujuan mendapatkan hasil yang lebih baik., Pada penelitian ini, tar get yang dicari adalah nilai akurasi yang tinggi., Alur perancangan model ini dilakukan sebagaimana pada 1162 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 Arsitektur yang akan digunakan dalam penelitian sistem rekognisi citra digital bahasa isyarat menggunakan Convolutional Neural Network akan menggunakan berbagai pretrained weights yang telah disediakan oleh library PyTorch., Contoh model dan weights -nya yang disediakan oleh library PyTorch yaitu ResNet, AlexNet, atau EfficientNet., Model dan weights -nya sudah dilatih sebelumnya menggunakan dataset ImageNet -1k dengan tujuan membantu meningkatkan akurasi dari model., Selain menggunakan pretrained weights, arsitektur model yang akan digunakan juga akan memiliki penambahan Spatial Transformer berupa lapis an Localization, fully connected, dan sampler., Penambahan Spatial Transformer diposisikan sebelum bagian utama arsitektur, tepatnya di awal arsitektur., Data akan melewati lapisan Spatial Transformer terlebih dahulu untuk ditransformasi sebelum memasuki lap isan utama dari Convolutional Neural Network., 3. DASAR TEORI 3.1 Bahasa Isyarat Bahasa isyarat diekspresikan menggunakan tangan, lengan, serta wajah dan dimengerti menggunakan mata., Bahasa isyarat juga memiliki struktur dan peraturan untuk berbagai kata, kalimat, atau percakapan, sebagaimana bahasa lain pada umumnya., Sebagian besar percakapan pada bahasa isyarat dilakukan dengan menggunakan tangan, dimana tangan beserta jari-jarinya digunakan untuk membentuk pose atau bentuk yang unik, s ehingga dapat dikenali sebagai maksud tertentu., Pada negara tertentu, bahasa isyarat yang dikembangkan dapat berbeda dengan bahasa isyarat dari negara lain., Contoh dari bahasa isyarat yang ada pada suatu negara tertentu yaitu American Sign Language (ASL), y ang merupakan bahasa isyarat populer yang berasal dari Amerika Serikat., Selain itu, terdapat pula bahasa isyarat dari Inggris yaitu British Sign Language (BSL)., Selain kedua negara tersebut, terdapat Australian Sign Language (Auslan), Italian Sign Language (LIS), Japanese Sign Language (JSL), dan lainnya., 3.2 Convolutional Neural Network Convolutional Neural Network (CNN) adalah jaringan saraf neuron lapisan banyak yang tidak sepenuhnya tersambung., CNN berisi lapisan convolutional, lapisan sampling atau sub-sampling,, dan lapisan tersembunyi yang masih berupa lapisan convolutional atau sampling., Setiap lapisan convolution pada CNN diikuti dengan lapisan penghitung untuk dilakukan pemerataan dan ekstraksi., Adapun perhitungan yang dilakukan pada lapisan convolutional adalah sebagai berikut H(x,y) b F(x,y) G(x,y) b F(j,k) k ( ) j ( ) G(x j,y k) (1) Keterangan F Filter Lapisan G Input feature map H Output feature map b Bias x Sumbu X pada data dan filter y Sumbu Y pada data dan filter j Increment untuk sumbu X k Increment untuk sumbu Y Suatu input feature map G dengan nilai G(x,y) akan dimasukkan ke dalam lapisan konvolusi., Kernel F yang berada di dalam lapisan konvolusi memiliki nilai F(x,y) untuk menjadi pengali dari input tersebut., Untuk setiap j pada sumbu x dan setiap k pada sumbu y, nilai input G(x j,y k) akan dikalikan dengan nilai kernel F(j,k) dan hasilnya akan dijumlahkan sesuai dengan ukuran data input pada nilai j dan k. Hasil dari total penjumlahan tersebut akan dijumlahkan dengan nilai bias b untuk menjadi nilai output H(x,y)., Perhitungan akan dilanjutkan ke pixel selanjutnya pada input G hingga seluruh pixel pada output feature map H mendapatkan hasil., 3.3, Transfer Learning Transfer Learning merupakan salah satu teknik dari penggunaan Deep Learning, dimana model yang sebelumnya telah melewati tahap training digunakan kembali untuk mengekstrak dan tuning lebih lanjut pada model lain untuk memperbaiki akurasi., Keuntungan dari penggunaan teknik Transfer Learning terletak pada penghematan waktu penjalanan proses training serta penghematan resource dikarenakan me nggunakan data yang lebih sedikit., Teknik ini dapat digunakan untuk mendeteksi berbagai macam objek., 3.4 Spatial Transformer Spatial Transformer merupakan modul yang bisa ditambahkan ke dalam Convolutional Neural Network yang memungkinkan manipulasi spasial data di dalam jaringan., Modul yang dapat dibedakan ini dapat dimasukkan ke dalam arsitektur Convolutional Neural Network yang sudah ada, memberikan neural network kemampuan untuk secara aktif mentransformasikan feature map secara spasial, tergantung pada feature map itu sendiri tanpa pengawasan pelatihan tambahan atau modifikasi pada proses pengoptimalan., Tahapan dari Spatial Transformer digambarkan pada Mahardika, dkk, Sistem Rekognisi Citra Digital 1163 Pada Gambar 7, mekanisme Spatial Transformer dibagi menjadi tiga bagian, yaitu jaringan Localization, Sampling Grid, dan Sampler., Jaringan Localization mengambil feature map input dan mengeluarkan parameter transformasi Teta (θ) yang harus diterapkan pada feature map melalui sejumlah hidden layer., Hasil output jaringan Localization berupa parameter transformasi Teta ( θ) akan digunakan untuk membuat Sampling Grid, yang merupakan sekumpulan titik di mana map input harus diambil sampelnya untuk menghasilkan output yang telah diubah., Hal ini dilakukan oleh generator grid, yang merupakan komponen Spatial Transformer yang memiliki fungsi eksklusif untuk melakukan transformasi invers dari output., Terakhir, feature map dan Sampling Grid yang dihasilkan oleh Grid Generator diambil sebagai input untuk Sampler, komponen lain dari Spatial Transformer selain Grid generator., Tujuan dari Sampler adalah untuk menghasilkan output map yang di -sampling dari input pada titik -titik grid., Sampler mengulangi entri grid pengambilan sampel dan mengekstrak nilai pixel yang sesuai dari input map menggunakan interpolasi bilinear., Output dari ketiga tahapan Spatial Transformer tersebut kemudian akan diteruskan ke jaringan konvolusi setelahnya., xis yis τθ(Gi) Aθ(xit yit 1) θ1,1θ1,2θ1,3 θ2,1θ2,3θ2,3 (xit yit 1) (2) Keterangan τθ Transformasi Afin 2D Aθ Gi Grid dari Output Feature Map, Aθ Matriks Transformasi Afin θ xis Sumber Kordinat Sumbu X yis Sumber Kordinat Sumbu Y xit Target Kordinat Sumbu X yit Target Kordinat Sumbu Y θ Luaran Localization Kordinat ( xit,yit), adalah target kordinat pada titik -titik grid (Gi) dan berasal dari output feature map., Kordinat ( xis,yis) adalah sumber kordinat dari input feature map yang menentukan titik sampel., Output dari lapisan Localization yaitu θ menjadi penentu transformasi target, dan mungkin saja mengambil berbagai transformasi., Aθ adalah matriks transformasi afin θ., Transformasi yang didefinisikan adalah seperti cropping, translation, rotation, scale, dan skew untuk diterapkan pada input feature map, dan hanya membutuhkan 6 parameter (6 elemen Aθ) yang diproduksi oleh lapisan Localization. 3.5., Confusion Matrix Confusion Matrix adalah salah satu metode pengukuran kinerja untuk masalah klasifikasi dalam machine learning, di mana output -nya dapat berupa dua kelas atau lebih., Confusion Matrix dapat berupa tabel dengan empat macam kombinasi berbeda dari nilai prediksi dan nilai sebenarnya., Keempat macam kombinasi tersebut adalah True Positive (TP), False Positive (FP), True Negative (TN), dan False Negative (FP)., Positif Sebenarnya Negatif Sebenarnya Positif Prediksi True Positive False Positive Negatif Prediksi False Negative True Negative Keempat kombinasi yang ditunjukkan pada Tabel 1 dapat digunakan untuk melakukan perhitungan metrik -metrik, untuk mengevaluasi hasil prediksi sistem., Metrik yang digunakan untuk mengevaluasi yaitu Accuracy atau akurasi, Precision, Recall, dan F1-Score., Adapun rumus dari setiap metrik tersebut ditunjukkan pada persamaan - persamaan berikut Accuracy TP TN TP FP TN FN (3) Precision TP TP FP (4) Recall TP TP FN (5) F1 Score 2 Precision Recall Precision Recall (6) Keterangan TP True Positive TN True Negative FP False Positive FN False Negative Perhitungan akurasi dilakukan dengan membagi seluruh prediksi yang benar ( TP TN) oleh keseluruhan data ( TP FP TN FN) dan digunakan untuk mengetahui keefektifan secara menyeluruh dari sistem., Perhitungan Precision digunakan untuk mengetahui kesepakatan kelas label data dengan label positif yang diberikan o leh sistem, dengan cara membagi nilai True Positive (TP) dan penjumlahan True Positive dan False Positive (TP FP)., Perhitungan Recall digunakan untuk 1164 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 mengetahui keefektifan dari sistem untuk mengidentifikasi label yang positif, dilakukan dengan membagi nilai True Positive (TP) dengan penjumlahan True Positive dan False Negative (TP FN)., Perhitungan F1-Score digunakan untuk mengeta hui hubungan antara data dengan label positif dan data yang dilabelkan positif oleh sistem., 3.5, Flask Flask adalah sebuah kerangka kerja aplikasi web yang memberikan alat, pustaka, dan teknologi untuk membuat aplikasi web., Flask meru pakan modul python untuk membuat aplikasi berbasis web yang cukup mudah untuk digunakan., Dengan menggunakan flask, suatu model deep learning dapat diintegrasikan ke dalam aplikasi web untuk dapat digunakan., 4. HASIL DAN PEMBAHASAN Pengujian pertama yang akan diuji adalah pengaturan arsitektur CNN dengan model, -model yang memiliki pretrained weights., Adapun model - model yang akan diuji yaitu ResNet18 dan ResNet50, AlexNet, dan EfficientNet B4., Selain arsitektur CNN, hal lain yang akan diuji adalah Hyperparameter dari proses pelatihan., Parameter yang akan diuji adalah optimizer dan learning rate., Berbagai optimizer yang akan diuji seperti SGD, RMSPr op, dan Adam., Sedangkan untuk learning rate, pengujian hanya akan menguji penggunaan learning rate scheduler untuk menilai keefektifan scheduler dalam membantu proses training., Setelah didapat model dan pengaturan hyperparameter yang terbaik, dilakukan pen gujian penggunaan pretrained weights dari arsitektur model untuk mencoba menaikkan hasil akurasi., Spatial Transformer juga akan diuji coba untuk melihat apakah penggunaannya mampu membuat akurasi meningkat., Terakhir, setelah didapatkan hasil yang maksimum dari kombinasi pengaturan yang terbaik, dilakukan uji coba secara real-time., Pengujian secara real-time dilakukan dengan melakukan export terhadap model dengan hasil yang terbaik, lalu diuji dengan gambar nyata yang diambil menggunakan kamera atau webcam., Pengujian secara real-time juga akan memiliki variasi terhadap pengujiannya, dimana masing -masing dari keempat dataset akan diuji coba melakukan klasifikasi secara real-time terhadap tiga macam latar belakang, yaitu latar belakang putih polos, latar belak ang hitam polos, dan latar belakang abstrak atau bermacam -macam warna., Uji coba latar belakang abstrak dilakukan untuk melihat pengaruh dari variasi warna pada latar belakang., Setelah melihat performa dari masing - masing dataset, dilakukan uji coba mengguna kan dataset gabungan dari keempat dataset untuk mencoba mendapatkan hasil yang terbaik., Pengujian model, hyperparameter, pretrained weights, dan Spatial Transformer akan menggunakan akurasi sebagai metrik utama dengan mencatat juga waktu jalannya proses tr aining., Khusus untuk learning rate, ditambahkan metrik berupa epoch hingga konvergen untuk menilai seberapa cepat model mampu mencapai titik konvergen pada proses pelatihan., 4.1 Pengujian Arsitektur Model Dalam pengujian ini digunakan empat tipe model., ResNet1 8 cukup populer di kalangan dataset kecil, tetapi juga layak digunakan pada dataset besar., Selain ResNet18, model populer lain yang juga digunakan adalah AlexNet., ResNet50 juga digunakan untuk membandingkan dengan tipe sebelumnya., Terakhir, EfficientNet B4 digunakan karena jumlah trainable parameter -nya yang tinggi, tetapi tidak terlalu besar untuk mencegah overfitting., Pengujian dilakukan dengan menggunakan Hyperparameter yang sama, yaitu optimizer Adam, learning rate 0.001, dan loss Cross Entropy., Pengujian ini tidak menggunakan Spatial Transformer., Hasil dari pengujian ditunjukkan pada Model Akurasi Waktu Training Train Valid ation Test ResNet18 99,89 100 54,73 3585s AlexNet 99,93 100 57,39 3350s ResNet50 99,83 100 57,10 4167s Efficient Net B4 99,96 100 78,10 4924s Hasil pengujian pada Tabel 2 menunjukkan bahwa model dengan arsitektur EfficientNet B4 memiliki akurasi testing yang tertinggi sebesar 78,10., Hasil ini menunjukkan bahwa model EfficientNet B4 mampu mendeteksi alfabet dalam data uji hingga didapatkan 78,10 kebenarannya., Selain memiliki akurasi testing yang tertinggi, akurasi training dan validation dari model Effi cientNet B4 juga yang terbesar, yaitu sebesar 99,96 untuk training dan 100 untuk validation., Seluruh model mendapatkan akurasi training yang tidak begitu jauh dari satu sama lain, dengan perbedaan antara hasil terendah dan tertinggi hanya sebesar 0,13., Akurasi validation tampak merata untuk keempat arsitektur yang diuji., Waktu pelatihan tercepat jatuh kepada model AlexNet dengan waktu 3350 detik atau hanya 55 menit dan terlama pada model EfficientNet B4 dengan waktu 4924 detik atau 1 jam 22 menit., Hasil ini menunjukkan bahwa model EfficientNet B4 memiliki kemampuan terbaik dalam prediksi data uji dibanding model lainnya, walau waktu pelatihannya memakan waktu paling lama., 4.2 Pengujian Hyperparameter Pengujian Hyperparameter dilakukan dengan menentukan pengat uran Hyperparameter yang dapat Mahardika, dkk, Sistem Rekognisi Citra Digital 1165 memberikan hasil yang terbaik, dan pengaturan Hyperparameter yang akan diuji yaitu optimizer dan penggunaan learning rate scheduler., Untuk model pengujian digunakan model EfficientNet B4 untuk mencari kombinasi Hyperparameter yang terbaik., Jumlah epoch yang digunakan adalah 20, dan Learning Rate yang digunakan yaitu 0.001., Pengujian optimizer dilakukan dengan mencoba satu per satu optimizer yang dapat digunakan., Opsi optimizer yang akan dicoba yaitu Adam, SGD, dan RMSProp., Pengujian ini juga tidak menggunakan Spatial Transformer., Hasil dari pengujian ditunjukkan pada Optimizer Akurasi Waktu Training Train Validation Test Adam 99,96 100 78,10 4924s SGD 4,79 3,85 3,84 4707s RMSProp 99,98 100 57,39 4767s Berdasarkan hasil pengujian Tabel 3, dapat dilihat bahwa model yang menggunakan optimizer SGD terlihat tidak berkembang., Akurasi yang didapat terlihat tidak mampu mencapai 5, baik akurasi training, validation, maupun testing., Hal ini diduga karena optimizer SGD memiliki sifat yang stokastik atau random dalam memilih data latih untuk setiap step, sehingga membutuhkan lebih banyak epoch dibandingkan dengan optimizer lain., Model dengan optimizer RMSProp terlihat cukup baik, akan tetapi akurasi testing -nya tidak sebaik dengan model yang menggunakan optimizer Adam., Hasil ini diduga dikarenakan optimizer Adam merupakan hasil perkembangan gabungan dari kedua optimizer., Setelah optimizer, pengujian Hyperparameter selanjutnya adalah penggunaan learning rate scheduler., Learning Rate Akurasi Epoch mencapai Konvergen Train Test LR 0.001 98,83, 76,33 Belum Konvergen LR 0.001 Scheduler 99,96 78,10, Epoch ke-8 Pengujian learning rate scheduler dilakukan dengan menguji performa dari pelatihan apabila penggunaan scheduler diberikan., Metrik utama yang akan diperhatikan adalah jumlah epoch yang diperlukan dari model hingga mencapai titik konvergen, atau titik dimana akurasi pelatihan tidak lagi fluktuatif., Untuk nilai learning rate yang akan digunakan yaitu 0.001, dan learning rate scheduler yang digunakan adalah Exponential Learning Rate Scheduler dari library torch optim., Sebagaimana ditunjukkan pada Tabel 4, Gambar 8, dan Gambar 9, pe ngujian penggunaan Learning Rate Scheduler pada model CNN tampak memiliki pengaruh terhadap proses pelatihan maupun hasil dari output model tersebut., Dengan adanya Learning Rate Scheduler, proses pelatihan model terlihat menjadi lebih stabil., Perubahan ter hadap nilai learning rate menjadikan proses pelatihan menjadi lebih teratur dan tidak fluktuatif, sebagaimana dapat dilihat pada model yang dilatih masih belum mampu memberikan hasil yang konsisten., Hal ini memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler., Gambar 8 menunjukkan bahwa pengujian yang tidak menggunakan scheduler tampak fluktuatif dan tidak teratur., Sel ain itu, hal ini juga memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler sebagaimana ditunjukkan pada maupun testing, peng gunaan scheduler terlihat mampu menaikkan akurasi pada model yang dilatih 4.3., Pen gujian Penggunaan Pretrained Weights Pengujian penggunaan pretrained weights dilakukan dengan menggunakan parameter pretrained True ketika memanggil model menggunakan library torch untuk menggunakan weights yang sebelumnya telah dilatih dan disediakan pada pemanggilan model., Model yang akan digunakan sama seperti pengujian sebelumnya, yaitu ResNet18, AlexNet, ResNet50 dan EfficientNet B4., 1166 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 Tujuan pengujian adalah untuk m engetahui seberapa besar pengaruh pretrained weights pada proses pelatihan dan hasilnya., Pengujian menggunakan optimizer Adam dan learning rate 0.001 serta scheduler -nya., Pengujian ini tidak menggunakan Spatial Transformer., Model Akurasi Waktu Training Train Validation Test ResNet18 99,89 100 54,73 3585s ResNet18 Pretrained 100 100 84,91 3566s AlexNet 99,93 100 57,39 3350s AlexNet Pretrained 99,96 99,04 75,44 3345s ResNet50 99,83 100 57,10 4167s ResNet50, Pretrained 99,89 99,52 65,09 4119s, EfficientNet B4 99,96 100 78,10 4924s EfficientNet B4 Pretrained 99,96 100 100 4870s Berdasarkan hasil pengujian yang ditunjukkan pada Tabel 5, dapat dilihat bahwa terdapat peningkatan pada akurasi testing untuk seluruh model., Peningkatan tersebut berbeda -beda pada setiap model, berkisar antara angka 8 hingga 30., Model ResNet18 mendapatkan peningkatan akurasi testing yang paling besar, yaitu 30,18., Model AlexNet juga mendapatkan peningkatan, yaitu sebesa r 18,05., Model ResNet50 mendapatkan peningkatan paling kecil, yaitu hanya sebesar 7,99., Terakhir, model EfficientNet B4 mendapatkan peningkatan sebesar 21,9 dan mampu mencapai akurasi maksimum, yaitu 100., Hasil ini menunjukkan bahwa model EfficientNet B4 sudah mampu mendeteksi seluruh data uji secara sempurna diduga karena tingkat kesulitan untuk mendeteksi data uji tidak begitu tinggi., Dari keempat model, dapat dilihat bahwa model EfficientNet B4 masih memiliki akurasi terbesar, bahkan mampu mencapai angka maksimum., Hal ini menunjukkan bahwa model EfficientNet B4 merupakan model yang terbaik dari keempat model yang diuji dalam mengklasifikasikan dataset yang diberikan., 4.4., Pen gujian Penggunaan Spatial Transformer Pengujian ini dilakukan dengan menambah kan lapisan localization dan lapisan Fully Connected yang merupakan bagian dari Spatial Transformer Network., Lapisan -lapisan, ini ditambahkan tepat sebelum dimasukkan ke model EfficientNet B4 yang menjadi arsitektur utama., Pengujian akan menggunakan optimiz er Adam dan learning rate 0.001 serta scheduler -nya., Model Akurasi Train Akurasi Test Waktu Training EfficientNet B4 99,96 78,10 4924s, EfficientNet B4 dengan Spatial Transformer 100 86,09 5950s, EfficientNet B4 Pretrained dengan Spatial Transformer 100 100 6537s, Dari hasil pengujian yang ditunjukkan pada Tabel 6, terlihat terdapat peningkatan akurasi Test pada model EfficientNet B4 dengan Spatial Transformer, yaitu sebesar 8., Akurasi yang didapat apabila EfficientNet B4 Pretrained menggunakan Spatial Transformer mampu mencapai akurasi maksimum pada data Test, yaitu sebesar 100., Adanya peningkatan akurasi menunjukkan bahwa Spatial Transformer memiliki kemampuan untuk meningkatkan kemampuan dari model dalam klasifikasi, sehingga pantas untuk digunakan untuk model akhir., Model akhir ini mampu mendapatkan nilai maksimum dari data testing, sehingga siap untuk diuji coba secara real-time., 4.5., Pen gujian Secara Real -Time Pengujian secara real-time dilakukan dengan mencoba dataset satu per satu terhadap suatu kondisi atau tampilan latar belakang tertentu dan menilai ke - efektifan masing -masing data terhadap masing - masing tampilan latar belakang, yaitu latar belakang putih, hitam, dan abstrak., Setelah itu, keempat dataset akan digabungkan menjadi satu untuk dicoba melihat keefektifannya terhadap masing -masing tampilan latar belakang., Model yang digunakan adalah model dengan pengaturan serta arsitektur ya ng terbaik, yaitu EfficientNet B4 Pretrained dengan Spatial Transformer., Data gambar akan di -convert menjadi single channel agar mempermudah prediksi melalui aplikasi., Dataset Total Benar Akurasi Latar Belakang Pengujian Putih Hitam Abstrak Latar Belakang Putih Total Benar 22 23 13 Akurasi 85 88 50 Latar Belakang Hitam Total Benar 13 16 6 Akurasi 50 62 23 Latar Belakang Karpet Total Benar 9 12 3 Akurasi 35 46 12 Latar Belakang Pemandangan Total Benar 9 4 3 Akurasi 35 15 12 Gabungan Total Benar 26 26 23 Akurasi 100 100 88, Tabel 7 menunjukkan bahwa akurasi yang didapat menggunakan dataset latar belakang hitam terlihat masih kurang baik., Dataset masih mampu melakukan klasifikasi pada latar belakang pengujian Mahardika, dkk, Sistem Rekognisi Citra Digital 1167 yang polos, seperti latar belakang putih dan hitam., Total prediksi yang benar masih mampu mencapai 50 dari seluruh alfabet pada latar belakang putih dan sebesar 62 pada latar belakang hitam., Hasil pengujian pada latar belakang abstrak terlihat hanya sebesar 23., Dapat juga dilihat pada Tabel 7 bahwa dataset dengan latar belakang putih mampu melakukan klasifikasi dengan baik pada latar belakang pengujian putih dan hitam polos, tetapi tidak te rlalu buruk pada klasifikasi dengan background abstrak., Total benar yang didapat pada latar belakang putih sebesar 85 dan latar belakang hitam 88 dari seluruh alfabet., Hasil pengujian pada latar belakang abstrak hanya sebesar 50, tetapi hasil ini, masih lebih, baik jika dibandingkan dengan dataset berlatar belakang hitam., Hasil pengujian dataset berlatar belakang pemandangan terlihat kurang baik., Pada latar belakang putih, total benar yang didapat hanya sebesar 35 dari seluruh alfabet, hasil yang lebih buruk jika dibandingkan dengan kedua dataset di pengujian sebelumnya., Tetapi, pengujian pada latar belakang hitam terlihat lebih buruk, hanya sebesar 15., Pengujian pada latar belakang abstrak terlihat tidak jauh, yaitu hanya sebesar 12., Dataset berlatar be lakang karpet yang ditunjukkan pada Tabel 7 terlihat lebih baik daripada pengujian pada dataset berlatar belakang pemandangan, tetapi masih kurang jika dibandingkan dengan dataset berlatar belakang hitam dan putih., Pengujian pada latar belakang putih terli hat mendapatkan total benar sebesar 35, dan pengujian pada latar belakang hitam terlihat mendapatkan total benar sebesar 46 dari seluruh alfabet., Tetapi, pengujian pada latar belakang abstrak masih terlihat buruk, yaitu hanya 12., Setelah keempat dataset diatas digabungkan, terlihat hasil pengujian secara real-time yang didapat cukup memuaskan., Sebagaimana ditunjukkan pada Tabel 7, hasil pengujian dataset gabungan pada latar belakang putih terlihat mencapai 100 total benar., Pengujian pada latar belakang hitam juga mencapai 100 total benar., Terakhir, pengujian pada latar belakang abstrak juga terlihat baik, yaitu sebesar 88.]\n"
     ]
    }
   ],
   "source": [
    "sentence_tokens = [sent for sent in doc.sents]\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores = {}\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.text.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1. PENDAHULUAN Bahasa isyarat merupakan hal yang sangat penting bagi suatu kelompok masyarakat, yaitu masyarakat bisu atau tuli.: 1.4000000000000001,\n",
       " Untuk masyarakat yang bisu atau tuli, bahasa isyarat adalah metode terpenting untuk berkomunikasi.: 1.4,\n",
       " Tanpa adanya bahasa isyarat, akan sulit bagi mereka yang bisu atau tuli untuk dapat menyatakan maksud atau pikiran mereka.: 1.2769230769230773,\n",
       " Untuk dapat berkomunik asi dengan masyarakat bisu atau tuli, orang yang tidak bisu atau tuli memerlukan bahasa isyarat tersebut untuk dapat mengerti maksud atau pikiran mereka yang bisu atau tuli.: 1.830769230769231,\n",
       " Setiap orang harus memiliki kemampuan menggunakan bahasa isyarat, agar dapat berko munikasi dengan mereka yang bisu atau tuli.: 1.6615384615384616,\n",
       " Bahasa isyarat diekspresikan menggunakan tangan, lengan, serta wajah dan dimengerti menggunakan mata.: 1.2000000000000002,\n",
       " Pembuatan sistem klasifikasi bahasa isyarat sebelumnya pernah dilakukan oleh yang membuat asisten virtual untuk bahasa isyarat menggunakan deep learning dan tensorflow.: 2.569230769230769,\n",
       " Kesimpulan dari penelitian ini adalah untuk dapat mendeteksi bahasa isyarat, diperlukan dataset tertentu untuk setiap bentuk bahasa isyarat.: 2.8615384615384616,\n",
       " Hal ini dikarenakan terdapat banyak bentuk bahasa isyarat di dunia, sehingga untuk dapat mendeteksi bahasa isyarat yang ada pada regional tertentu, diperlukan dataset bahasa isyarat dari lokasi tersebut.: 3.676923076923077,\n",
       " Selain itu, diperlukan pula latar belakang yang mendukun g ketika mengambil gambar, sehingga tidak dapat digunakan di sembarang tempat.: 0.7538461538461538,\n",
       " Penelitian ini lebih memfokuskan terhadap pembuatan aplikasinya, sehingga tidak terlalu menunjukkan terhadap akurasi atau performa yang lebih mendalam.: 0.7846153846153846,\n",
       " Penelitian lain yang mend alami performa dari model deep learning -nya yaitu oleh tentang klasifikasi wajah dan penelitian oleh tentang deteksi citra Covid - 19.: 2.1999999999999997,\n",
       " Kedua penelitian ini tidak melakukan klasifikasi terhadap bahasa isyarat, teta pi metode untuk mendapatkan performa yang terbaik dijadikan penulis sebagai referensi.: 1.769230769230769,\n",
       " Kesimpulan dari penelitian kedua adalah untuk dapat mendeteksi wajah, ada sangat banyak elemen yang perlu diperhatikan seperti cahaya, pose, angle atau posisi kamera, da n lainnya.: 0.6153846153846154,\n",
       " Tidak akan mudah untuk dapat mendapatkan hasil yang sempurna, tetapi CNN mampu mendapatkan hasil yang baik dikarenakan pembelajaran fiturnya yang kuat, sehingga mampu bertahan pada lingkungan yang kompleks.: 0.9384615384615382,\n",
       " Hal yang sama juga dapat diaplikasikan terhadap bahasa isyarat, sebagaimana disebutkan pada kesimpulan penelitian pertama.: 1.153846153846154,\n",
       " Kesimpulan dari penelitian ketiga adalah X -Ray serta CT-Scan yang termasuk kepada radiografi dada sangatlah membantu untuk mendeteksi penyakit - penyakit, dan penelitian men ggunakan Transfer Learning dari PyTorch tadi mendapatkan hasil yang memuaskan, dengan akurasi sebesar 97,78.: 1.876923076923077,\n",
       " Hasil ini sangat memuaskan dan menjadikan penulis tertarik pada metode yang digunakan untuk dicoba diberikan pada aplikasi rekognisi bahasa isyara t. Penelitian terakhir adalah tentang penggunaan metode Spatial Transformer dan optimisasi stokastik pada rekognisi rambu lalu lintas oleh.: 1.9846153846153844,\n",
       " Penelitian ini menggunakan metode Spatial Transformer dan mampu mendapatkan akurasi sebe sar 99,71 pada dataset dengan jumlah data uji sebanyak 12.630.: 2.1538461538461537,\n",
       " Hasil ini menunjukkan kalau metode Spatial Transformer pantas untuk digunakan untuk mencoba meningkatkan akurasi dari penelitian.: 1.276923076923077,\n",
       " Oleh karena itu, penulis mengusulkan dikembangkan sistem reko gnisi citra digital untuk dapat mengenali bahasa isyarat tersebut.: 1.4461538461538463,\n",
       " Dengan menggunakan metode Convolutional Neural Network (CNN): 0.3076923076923077,\n",
       " yang merupakan bagian dari Deep Learning atau Machine Learning dan dengan metode Spatial Transformer, sistem akan mengenali pose atau bentuk dari citra bahasa isyarat yang dimasukkan, dan memberikan luaran yang sesuai dengan maksud dari pose atau bentuk dari citra bahasa isyarat tersebut.: 3.5230769230769234,\n",
       " 2. METODE PENELITIAN 2.1 Data Penelitian Data yang digunakan untuk training model adalah data sekunder yang didapat: 3.569230769230769,\n",
       " secara open - source dari berbagai halaman web tertentu yang menyediakan dataset -dataset secara gratis dan legal.: 0.7692307692307692,\n",
       " Untuk penelitian ini, digunakan dataset -dataset dengan tema bahasa isyarat.: 1.7230769230769232,\n",
       " Adapun situs yang menyediakan set data tersebut bernama Kaggle.: 0.723076923076923,\n",
       " Data sekunder yang akan digunakan ada dua macam, yaitu data bahasa isyarat dengan background hitam dan data bahasa isyarat dengan background putih.: 4.830769230769231,\n",
       " Data dengan background hitam merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada data dengan background putih juga merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada hitam memiliki jumlah sebanyak 70 gambar, sedangkan dataset background putih memiliki jumlah sebanyak 21 gambar.: 6.046153846153845,\n",
       " Selain data sekunder dari internet, digunakan pula data yang diambil oleh penulis secara pribadi.: 1.476923076923077,\n",
       " Pengambilan data pribadi ini dilakukan untuk Mahardika, dkk, Sistem Rekognisi Citra Digital 1161 menguji adanya perbedaan hasil pada pengujian apabila menggunakan data dengan background yang berbeda dan mengetahui seberapa besar pengaruh yang dimiliki oleh background tersebut terhadap keseluruhan percobaan, sebagaimana permasalahan ini disebutkan sebelumnya oleh.: 3.3846153846153837,\n",
       " Data gamb ar yang diambil akan memiliki pose dan bentuk bahasa isyarat yang sama dengan data sekunder dari internet tersebut, tetapi akan memiliki background yang bervariasi.: 3.553846153846154,\n",
       " Data yang diambil memiliki dua macam background, yaitu data dengan background karpet bermot if ditunjukkan pada Gambar 3 dan data dengan background pemandangan pagi ditunjukkan pada background karpet memiliki jumlah sebanyak 54 gambar, sedangkan dataset background pemandangan memiliki jumlah sebanyak 40 gambar.: 5.9692307692307685,\n",
       " Data uji yang akan digunakan adalah dataset yang menggabungkan keempat dataset yang digunakan untuk training dan validation.: 2.2615384615384615,\n",
       " Selain itu, ditambahkan pula tiga set gambar yang tidak berada dalam data training maupun validation, yaitu dataset dengan background bunga, dataset dengan background langit merah, dan dataset dengan background gunung.: 3.7230769230769223,\n",
       " Penyusunan dataset uji per alfabet adalah satu gambar dari setiap dataset background hitam, putih, karpet, dan pemandangan ditambah tiga gambar dari setiap dataset background bunga, langit merah, dan gunung sebagaimana ditunjukkan pada gambar unt uk setiap alfabet, menjadikan 338 total gambar data uji.: 5.092307692307692,\n",
       " Pada perancangan model Convolutional Neural Network dari sistem rekognisi citra digital bahasa isyarat diawali dengan adanya pemrosesan awal dengan mengubah di mensi dari data dan juga mengkonversi data menjadi berbentuk Tensor agar dapat diberikan sebagai input kepada model CNN.: 5.046153846153846,\n",
       " Setelah dilakukan pemrosesan awal, dibuatlah arsitektur dari model CNN yang akan melakukan pembelajaran mendalam atau Deep Learning.: 1.6307692307692305,\n",
       " Penentuan Arsitektur dari model CNN ini dilakukan dengan memasukan lapisan -lapisan: 1.5384615384615385,\n",
       " neural network yang terbaik untuk data yang digunakan.: 0.8923076923076922,\n",
       " Dalam arsitektur model akan ditambahkan modul Spatial Transformer, yang di tambahkan sebelum bagian utama dari neural network.: 1.5076923076923079,\n",
       " Data akan melewati lapisan -lapisan Spatial Transformer terlebih dahulu sebelum memasuki bagian neural network utama.: 1.2153846153846153,\n",
       " Setelah arsitektur dari model CNN telah ditentukan, dilakukan proses pelatihan atau Training pada dataset.: 2.292307692307692,\n",
       " Training atau pelatihan dilakukan dengan tujuan memberikan model pengetahuan yang dibutuhkannya untuk dapat mengklasifikasikan dan merekognisi data digital.: 2.1538461538461537,\n",
       " Terakhir, dilakukan pengujian dengan data uji untuk menentukan seberapa baik ki nerja model dalam pekerjaan mengklasifikasi dan merekognisi dataset digital tersebut.: 2.969230769230769,\n",
       " Apabila kinerja model masih kurang baik, maka perlu dilakukan perbaikan atau Tweaking pada model dengan tujuan mendapatkan hasil yang lebih baik.: 2.4769230769230766,\n",
       " Pada penelitian ini, tar get yang dicari adalah nilai akurasi yang tinggi.: 0.9230769230769231,\n",
       " Alur perancangan model ini dilakukan sebagaimana pada 1162 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 Arsitektur yang akan digunakan dalam penelitian sistem rekognisi citra digital bahasa isyarat menggunakan Convolutional Neural Network akan menggunakan berbagai pretrained weights yang telah disediakan oleh library PyTorch.: 3.6461538461538456,\n",
       " Contoh model dan weights -nya yang disediakan oleh library PyTorch yaitu ResNet, AlexNet, atau EfficientNet.: 1.3846153846153846,\n",
       " Model dan weights -nya sudah dilatih sebelumnya menggunakan dataset ImageNet -1k dengan tujuan membantu meningkatkan akurasi dari model.: 3.5076923076923077,\n",
       " Selain menggunakan pretrained weights, arsitektur model yang akan digunakan juga akan memiliki penambahan Spatial Transformer berupa lapis an Localization, fully connected, dan sampler.: 1.9538461538461536,\n",
       " Penambahan Spatial Transformer diposisikan sebelum bagian utama arsitektur, tepatnya di awal arsitektur.: 0.5846153846153846,\n",
       " Data akan melewati lapisan Spatial Transformer terlebih dahulu untuk ditransformasi sebelum memasuki lap isan utama dari Convolutional Neural Network.: 1.2615384615384615,\n",
       " 3. DASAR TEORI 3.1 Bahasa Isyarat Bahasa isyarat diekspresikan menggunakan tangan, lengan, serta wajah dan dimengerti menggunakan mata.: 2.2615384615384606,\n",
       " Bahasa isyarat juga memiliki struktur dan peraturan untuk berbagai kata, kalimat, atau percakapan, sebagaimana bahasa lain pada umumnya.: 1.8461538461538463,\n",
       " Sebagian besar percakapan pada bahasa isyarat dilakukan dengan menggunakan tangan, dimana tangan beserta jari-jarinya digunakan untuk membentuk pose atau bentuk yang unik, s ehingga dapat dikenali sebagai maksud tertentu.: 1.5230769230769228,\n",
       " Pada negara tertentu, bahasa isyarat yang dikembangkan dapat berbeda dengan bahasa isyarat dari negara lain.: 2.1230769230769226,\n",
       " Contoh dari bahasa isyarat yang ada pada suatu negara tertentu yaitu American Sign Language (ASL): 1.0153846153846153,\n",
       " y ang merupakan bahasa isyarat populer yang berasal dari Amerika Serikat.: 1.2307692307692308,\n",
       " Selain itu, terdapat pula bahasa isyarat dari Inggris yaitu British Sign Language (BSL).: 0.9538461538461539,\n",
       " Selain kedua negara tersebut, terdapat Australian Sign Language (Auslan), Italian Sign Language (LIS), Japanese Sign Language (JSL), dan lainnya.: 0.06153846153846154,\n",
       " 3.2 Convolutional Neural Network Convolutional Neural Network (CNN) adalah jaringan saraf neuron lapisan banyak yang tidak sepenuhnya tersambung.: 0.7538461538461538,\n",
       " CNN berisi lapisan convolutional, lapisan sampling atau sub-sampling,: 0.6923076923076923,\n",
       " dan lapisan tersembunyi yang masih berupa lapisan convolutional atau sampling.: 0.630769230769231,\n",
       " Setiap lapisan convolution pada CNN diikuti dengan lapisan penghitung untuk dilakukan pemerataan dan ekstraksi.: 0.5999999999999999,\n",
       " Adapun perhitungan yang dilakukan pada lapisan convolutional adalah sebagai berikut H(x,y) b F(x,y) G(x,y) b F(j,k) k ( ) j ( ) G(x j,y k) (1) Keterangan F Filter Lapisan G Input feature map H Output feature map b Bias x Sumbu X pada data dan filter y Sumbu Y pada data dan filter j Increment untuk sumbu X k Increment untuk sumbu Y Suatu input feature map G dengan nilai G(x,y) akan dimasukkan ke dalam lapisan konvolusi.: 7.046153846153844,\n",
       " Kernel F yang berada di dalam lapisan konvolusi memiliki nilai F(x,y) untuk menjadi pengali dari input tersebut.: 1.3076923076923077,\n",
       " Untuk setiap j pada sumbu x dan setiap k pada sumbu y, nilai input G(x j,y k) akan dikalikan dengan nilai kernel F(j,k) dan hasilnya akan dijumlahkan sesuai dengan ukuran data input pada nilai j dan k. Hasil dari total penjumlahan tersebut akan dijumlahkan dengan nilai bias b untuk menjadi nilai output H(x,y).: 4.476923076923078,\n",
       " Perhitungan akan dilanjutkan ke pixel selanjutnya pada input G hingga seluruh pixel pada output feature map H mendapatkan hasil.: 1.323076923076923,\n",
       " 3.3: 0.015384615384615385,\n",
       " Transfer Learning Transfer Learning merupakan salah satu teknik dari penggunaan Deep Learning, dimana model yang sebelumnya telah melewati tahap training digunakan kembali untuk mengekstrak dan tuning lebih lanjut pada model lain untuk memperbaiki akurasi.: 3.846153846153846,\n",
       " Keuntungan dari penggunaan teknik Transfer Learning terletak pada penghematan waktu penjalanan proses training serta penghematan resource dikarenakan me nggunakan data yang lebih sedikit.: 1.5076923076923077,\n",
       " Teknik ini dapat digunakan untuk mendeteksi berbagai macam objek.: 0.16923076923076924,\n",
       " 3.4 Spatial Transformer Spatial Transformer merupakan modul yang bisa ditambahkan ke dalam Convolutional Neural Network yang memungkinkan manipulasi spasial data di dalam jaringan.: 0.9538461538461538,\n",
       " Modul yang dapat dibedakan ini dapat dimasukkan ke dalam arsitektur Convolutional Neural Network yang sudah ada, memberikan neural network kemampuan untuk secara aktif mentransformasikan feature map secara spasial, tergantung pada feature map itu sendiri tanpa pengawasan pelatihan tambahan atau modifikasi pada proses pengoptimalan.: 2.03076923076923,\n",
       " Tahapan dari Spatial Transformer digambarkan pada Mahardika, dkk, Sistem Rekognisi Citra Digital 1163 Pada Gambar 7, mekanisme Spatial Transformer dibagi menjadi tiga bagian, yaitu jaringan Localization, Sampling Grid, dan Sampler.: 0.9999999999999998,\n",
       " Jaringan Localization mengambil feature map input dan mengeluarkan parameter transformasi Teta (θ) yang harus diterapkan pada feature map melalui sejumlah hidden layer.: 1.5230769230769228,\n",
       " Hasil output jaringan Localization berupa parameter transformasi Teta ( θ) akan digunakan untuk membuat Sampling Grid, yang merupakan sekumpulan titik di mana map input harus diambil sampelnya untuk menghasilkan output yang telah diubah.: 1.9076923076923074,\n",
       " Hal ini dilakukan oleh generator grid, yang merupakan komponen Spatial Transformer yang memiliki fungsi eksklusif untuk melakukan transformasi invers dari output.: 0.7846153846153847,\n",
       " Terakhir, feature map dan Sampling Grid yang dihasilkan oleh Grid Generator diambil sebagai input untuk Sampler, komponen lain dari Spatial Transformer selain Grid generator.: 1.0615384615384613,\n",
       " Tujuan dari Sampler adalah untuk menghasilkan output map yang di -sampling dari input pada titik -titik grid.: 0.9076923076923077,\n",
       " Sampler mengulangi entri grid pengambilan sampel dan mengekstrak nilai pixel yang sesuai dari input map menggunakan interpolasi bilinear.: 0.9846153846153847,\n",
       " Output dari ketiga tahapan Spatial Transformer tersebut kemudian akan diteruskan ke jaringan konvolusi setelahnya.: 0.36923076923076925,\n",
       " xis yis τθ(Gi) Aθ(xit yit 1) θ1,1θ1,2θ1,3 θ2,1θ2,3θ2,3 (xit yit 1) (2) Keterangan τθ Transformasi Afin 2D Aθ Gi Grid dari Output Feature Map: 1.307692307692308,\n",
       " Aθ Matriks Transformasi Afin θ xis Sumber Kordinat Sumbu X yis Sumber Kordinat Sumbu Y xit Target Kordinat Sumbu X yit Target Kordinat Sumbu Y θ Luaran Localization Kordinat ( xit,yit): 1.5384615384615388,\n",
       " adalah target kordinat pada titik -titik grid (Gi) dan berasal dari output feature map.: 0.8769230769230769,\n",
       " Kordinat ( xis,yis) adalah sumber kordinat dari input feature map yang menentukan titik sampel.: 0.9692307692307695,\n",
       " Output dari lapisan Localization yaitu θ menjadi penentu transformasi target, dan mungkin saja mengambil berbagai transformasi.: 0.8153846153846155,\n",
       " Aθ adalah matriks transformasi afin θ.: 0.2153846153846154,\n",
       " Transformasi yang didefinisikan adalah seperti cropping, translation, rotation, scale, dan skew untuk diterapkan pada input feature map, dan hanya membutuhkan 6 parameter (6 elemen Aθ) yang diproduksi oleh lapisan Localization. 3.5.: 1.5384615384615383,\n",
       " Confusion Matrix Confusion Matrix adalah salah satu metode pengukuran kinerja untuk masalah klasifikasi dalam machine learning, di mana output -nya dapat berupa dua kelas atau lebih.: 0.9538461538461539,\n",
       " Confusion Matrix dapat berupa tabel dengan empat macam kombinasi berbeda dari nilai prediksi dan nilai sebenarnya.: 0.7384615384615385,\n",
       " Keempat macam kombinasi tersebut adalah True Positive (TP), False Positive (FP), True Negative (TN), dan False Negative (FP).: 0.2,\n",
       " Positif Sebenarnya Negatif Sebenarnya Positif Prediksi True Positive False Positive Negatif Prediksi False Negative True Negative Keempat kombinasi yang ditunjukkan pada Tabel 1 dapat digunakan untuk melakukan perhitungan metrik -metrik: 0.723076923076923,\n",
       " untuk mengevaluasi hasil prediksi sistem.: 0.6615384615384615,\n",
       " Metrik yang digunakan untuk mengevaluasi yaitu Accuracy atau akurasi, Precision, Recall, dan F1-Score.: 0.5538461538461539,\n",
       " Adapun rumus dari setiap metrik tersebut ditunjukkan pada persamaan - persamaan berikut Accuracy TP TN TP FP TN FN (3) Precision TP TP FP (4) Recall TP TP FN (5) F1 Score 2 Precision Recall Precision Recall (6) Keterangan TP True Positive TN True Negative FP False Positive FN False Negative Perhitungan akurasi dilakukan dengan membagi seluruh prediksi yang benar ( TP TN) oleh keseluruhan data ( TP FP TN FN) dan digunakan untuk mengetahui keefektifan secara menyeluruh dari sistem.: 1.953846153846154,\n",
       " Perhitungan Precision digunakan untuk mengetahui kesepakatan kelas label data dengan label positif yang diberikan o leh sistem, dengan cara membagi nilai True Positive (TP) dan penjumlahan True Positive dan False Positive (TP FP).: 1.3846153846153846,\n",
       " Perhitungan Recall digunakan untuk 1164 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 mengetahui keefektifan dari sistem untuk mengidentifikasi label yang positif, dilakukan dengan membagi nilai True Positive (TP) dengan penjumlahan True Positive dan False Negative (TP FN).: 1.0461538461538462,\n",
       " Perhitungan F1-Score digunakan untuk mengeta hui hubungan antara data dengan label positif dan data yang dilabelkan positif oleh sistem.: 1.6307692307692307,\n",
       " 3.5: 0.03076923076923077,\n",
       " Flask Flask adalah sebuah kerangka kerja aplikasi web yang memberikan alat, pustaka, dan teknologi untuk membuat aplikasi web.: 0.4461538461538462,\n",
       " Flask meru pakan modul python untuk membuat aplikasi berbasis web yang cukup mudah untuk digunakan.: 0.3230769230769231,\n",
       " Dengan menggunakan flask, suatu model deep learning dapat diintegrasikan ke dalam aplikasi web untuk dapat digunakan.: 1.5076923076923074,\n",
       " 4. HASIL DAN PEMBAHASAN Pengujian pertama yang akan diuji adalah pengaturan arsitektur CNN dengan model: 2.353846153846154,\n",
       " -model yang memiliki pretrained weights.: 0.6461538461538462,\n",
       " Adapun model - model yang akan diuji yaitu ResNet18 dan ResNet50, AlexNet, dan EfficientNet B4.: 2.184615384615385,\n",
       " Selain arsitektur CNN, hal lain yang akan diuji adalah Hyperparameter dari proses pelatihan.: 0.7846153846153847,\n",
       " Parameter yang akan diuji adalah optimizer dan learning rate.: 0.9692307692307691,\n",
       " Berbagai optimizer yang akan diuji seperti SGD, RMSPr op, dan Adam.: 0.4461538461538462,\n",
       " Sedangkan untuk learning rate, pengujian hanya akan menguji penggunaan learning rate scheduler untuk menilai keefektifan scheduler dalam membantu proses training.: 2.4153846153846152,\n",
       " Setelah didapat model dan pengaturan hyperparameter yang terbaik, dilakukan pen gujian penggunaan pretrained weights dari arsitektur model untuk mencoba menaikkan hasil akurasi.: 3.953846153846154,\n",
       " Spatial Transformer juga akan diuji coba untuk melihat apakah penggunaannya mampu membuat akurasi meningkat.: 0.7692307692307692,\n",
       " Terakhir, setelah didapatkan hasil yang maksimum dari kombinasi pengaturan yang terbaik, dilakukan uji coba secara real-time.: 1.2923076923076926,\n",
       " Pengujian secara real-time dilakukan dengan melakukan export terhadap model dengan hasil yang terbaik, lalu diuji dengan gambar nyata yang diambil menggunakan kamera atau webcam.: 2.738461538461539,\n",
       " Pengujian secara real-time juga akan memiliki variasi terhadap pengujiannya, dimana masing -masing dari keempat dataset akan diuji coba melakukan klasifikasi secara real-time terhadap tiga macam latar belakang, yaitu latar belakang putih polos, latar belak ang hitam polos, dan latar belakang abstrak atau bermacam -macam warna.: 5.200000000000001,\n",
       " Uji coba latar belakang abstrak dilakukan untuk melihat pengaruh dari variasi warna pada latar belakang.: 1.5076923076923077,\n",
       " Setelah melihat performa dari masing - masing dataset, dilakukan uji coba mengguna kan dataset gabungan dari keempat dataset untuk mencoba mendapatkan hasil yang terbaik.: 2.8153846153846156,\n",
       " Pengujian model, hyperparameter, pretrained weights, dan Spatial Transformer akan menggunakan akurasi sebagai metrik utama dengan mencatat juga waktu jalannya proses tr aining.: 2.5999999999999996,\n",
       " Khusus untuk learning rate, ditambahkan metrik berupa epoch hingga konvergen untuk menilai seberapa cepat model mampu mencapai titik konvergen pada proses pelatihan.: 2.3538461538461535,\n",
       " 4.1 Pengujian Arsitektur Model Dalam pengujian ini digunakan empat tipe model.: 3.123076923076923,\n",
       " ResNet1 8 cukup populer di kalangan dataset kecil, tetapi juga layak digunakan pada dataset besar.: 1.2615384615384615,\n",
       " Selain ResNet18, model populer lain yang juga digunakan adalah AlexNet.: 1.0461538461538462,\n",
       " ResNet50 juga digunakan untuk membandingkan dengan tipe sebelumnya.: 0.046153846153846156,\n",
       " Terakhir, EfficientNet B4 digunakan karena jumlah trainable parameter -nya yang tinggi, tetapi tidak terlalu besar untuk mencegah overfitting.: 0.24615384615384617,\n",
       " Pengujian dilakukan dengan menggunakan Hyperparameter yang sama, yaitu optimizer Adam, learning rate 0.001, dan loss Cross Entropy.: 1.2923076923076924,\n",
       " Pengujian ini tidak menggunakan Spatial Transformer.: 0.4307692307692308,\n",
       " Hasil dari pengujian ditunjukkan pada Model Akurasi Waktu Training Train Valid ation Test ResNet18 99,89 100 54,73 3585s AlexNet 99,93 100 57,39 3350s ResNet50 99,83 100 57,10 4167s Efficient Net B4 99,96 100 78,10 4924s Hasil pengujian pada Tabel 2 menunjukkan bahwa model dengan arsitektur EfficientNet B4 memiliki akurasi testing yang tertinggi sebesar 78,10.: 7.7230769230769205,\n",
       " Hasil ini menunjukkan bahwa model EfficientNet B4 mampu mendeteksi alfabet dalam data uji hingga didapatkan 78,10 kebenarannya.: 2.5384615384615383,\n",
       " Selain memiliki akurasi testing yang tertinggi, akurasi training dan validation dari model Effi cientNet B4 juga yang terbesar, yaitu sebesar 99,96 untuk training dan 100 untuk validation.: 3.4615384615384617,\n",
       " Seluruh model mendapatkan akurasi training yang tidak begitu jauh dari satu sama lain, dengan perbedaan antara hasil terendah dan tertinggi hanya sebesar 0,13.: 2.1076923076923073,\n",
       " Akurasi validation tampak merata untuk keempat arsitektur yang diuji.: 1.0923076923076924,\n",
       " Waktu pelatihan tercepat jatuh kepada model AlexNet dengan waktu 3350 detik atau hanya 55 menit dan terlama pada model EfficientNet B4 dengan waktu 4924 detik atau 1 jam 22 menit.: 2.538461538461538,\n",
       " Hasil ini menunjukkan bahwa model EfficientNet B4 memiliki kemampuan terbaik dalam prediksi data uji dibanding model lainnya, walau waktu pelatihannya memakan waktu paling lama.: 3.8923076923076922,\n",
       " 4.2 Pengujian Hyperparameter Pengujian Hyperparameter dilakukan dengan menentukan pengat uran Hyperparameter yang dapat Mahardika, dkk, Sistem Rekognisi Citra Digital 1165 memberikan hasil yang terbaik, dan pengaturan Hyperparameter yang akan diuji yaitu optimizer dan penggunaan learning rate scheduler.: 3.4153846153846152,\n",
       " Untuk model pengujian digunakan model EfficientNet B4 untuk mencari kombinasi Hyperparameter yang terbaik.: 2.723076923076923,\n",
       " Jumlah epoch yang digunakan adalah 20, dan Learning Rate yang digunakan yaitu 0.001.: 0.6461538461538463,\n",
       " Pengujian optimizer dilakukan dengan mencoba satu per satu optimizer yang dapat digunakan.: 1.0,\n",
       " Opsi optimizer yang akan dicoba yaitu Adam, SGD, dan RMSProp.: 0.2923076923076923,\n",
       " Pengujian ini juga tidak menggunakan Spatial Transformer.: 0.4307692307692308,\n",
       " Hasil dari pengujian ditunjukkan pada Optimizer Akurasi Waktu Training Train Validation Test Adam 99,96 100 78,10 4924s SGD 4,79 3,85 3,84 4707s RMSProp 99,98 100 57,39 4767s Berdasarkan hasil pengujian Tabel 3, dapat dilihat bahwa model yang menggunakan optimizer SGD terlihat tidak berkembang.: 5.1230769230769235,\n",
       " Akurasi yang didapat terlihat tidak mampu mencapai 5, baik akurasi training, validation, maupun testing.: 1.4923076923076923,\n",
       " Hal ini diduga karena optimizer SGD memiliki sifat yang stokastik atau random dalam memilih data latih untuk setiap step, sehingga membutuhkan lebih banyak epoch dibandingkan dengan optimizer lain.: 1.7846153846153845,\n",
       " Model dengan optimizer RMSProp terlihat cukup baik, akan tetapi akurasi testing -nya tidak sebaik dengan model yang menggunakan optimizer Adam.: 3.2,\n",
       " Hasil ini diduga dikarenakan optimizer Adam merupakan hasil perkembangan gabungan dari kedua optimizer.: 1.3692307692307693,\n",
       " Setelah optimizer, pengujian Hyperparameter selanjutnya adalah penggunaan learning rate scheduler.: 1.523076923076923,\n",
       " Learning Rate Akurasi Epoch mencapai Konvergen Train Test LR 0.001 98,83: 1.3076923076923077,\n",
       " 76,33 Belum Konvergen LR 0.001 Scheduler 99,96 78,10: 0.6000000000000001,\n",
       " Epoch ke-8 Pengujian learning rate scheduler dilakukan dengan menguji performa dari pelatihan apabila penggunaan scheduler diberikan.: 1.8307692307692307,\n",
       " Metrik utama yang akan diperhatikan adalah jumlah epoch yang diperlukan dari model hingga mencapai titik konvergen, atau titik dimana akurasi pelatihan tidak lagi fluktuatif.: 2.430769230769231,\n",
       " Untuk nilai learning rate yang akan digunakan yaitu 0.001, dan learning rate scheduler yang digunakan adalah Exponential Learning Rate Scheduler dari library torch optim.: 2.246153846153846,\n",
       " Sebagaimana ditunjukkan pada Tabel 4, Gambar 8, dan Gambar 9, pe ngujian penggunaan Learning Rate Scheduler pada model CNN tampak memiliki pengaruh terhadap proses pelatihan maupun hasil dari output model tersebut.: 4.769230769230769,\n",
       " Dengan adanya Learning Rate Scheduler, proses pelatihan model terlihat menjadi lebih stabil.: 2.0307692307692307,\n",
       " Perubahan ter hadap nilai learning rate menjadikan proses pelatihan menjadi lebih teratur dan tidak fluktuatif, sebagaimana dapat dilihat pada model yang dilatih masih belum mampu memberikan hasil yang konsisten.: 2.6769230769230767,\n",
       " Hal ini memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler.: 2.784615384615385,\n",
       " Gambar 8 menunjukkan bahwa pengujian yang tidak menggunakan scheduler tampak fluktuatif dan tidak teratur.: 0.9692307692307692,\n",
       " Sel ain itu, hal ini juga memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler sebagaimana ditunjukkan pada maupun testing, peng gunaan scheduler terlihat mampu menaikkan akurasi pada model yang dilatih 4.3.: 4.723076923076924,\n",
       " Pen gujian Penggunaan Pretrained Weights Pengujian penggunaan pretrained weights dilakukan dengan menggunakan parameter pretrained True ketika memanggil model menggunakan library torch untuk menggunakan weights yang sebelumnya telah dilatih dan disediakan pada pemanggilan model.: 3.953846153846153,\n",
       " Model yang akan digunakan sama seperti pengujian sebelumnya, yaitu ResNet18, AlexNet, ResNet50 dan EfficientNet B4.: 1.4307692307692308,\n",
       " 1166 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 Tujuan pengujian adalah untuk m engetahui seberapa besar pengaruh pretrained weights pada proses pelatihan dan hasilnya.: 1.5999999999999996,\n",
       " Pengujian menggunakan optimizer Adam dan learning rate 0.001 serta scheduler -nya.: 1.5692307692307692,\n",
       " Pengujian ini tidak menggunakan Spatial Transformer.: 0.4307692307692308,\n",
       " Model Akurasi Waktu Training Train Validation Test ResNet18 99,89 100 54,73 3585s ResNet18 Pretrained 100 100 84,91 3566s AlexNet 99,93 100 57,39 3350s AlexNet Pretrained 99,96 99,04 75,44 3345s ResNet50 99,83 100 57,10 4167s ResNet50: 4.307692307692307,\n",
       " Pretrained 99,89 99,52 65,09 4119s: 0.2153846153846154,\n",
       " EfficientNet B4 99,96 100 78,10 4924s EfficientNet B4 Pretrained 99,96 100 100 4870s Berdasarkan hasil pengujian yang ditunjukkan pada Tabel 5, dapat dilihat bahwa terdapat peningkatan pada akurasi testing untuk seluruh model.: 4.230769230769231,\n",
       " Peningkatan tersebut berbeda -beda pada setiap model, berkisar antara angka 8 hingga 30.: 1.323076923076923,\n",
       " Model ResNet18 mendapatkan peningkatan akurasi testing yang paling besar, yaitu 30,18.: 1.7076923076923078,\n",
       " Model AlexNet juga mendapatkan peningkatan, yaitu sebesa r 18,05.: 1.1538461538461537,\n",
       " Model ResNet50 mendapatkan peningkatan paling kecil, yaitu hanya sebesar 7,99.: 1.123076923076923,\n",
       " Terakhir, model EfficientNet B4 mendapatkan peningkatan sebesar 21,9 dan mampu mencapai akurasi maksimum, yaitu 100.: 2.184615384615385,\n",
       " Hasil ini menunjukkan bahwa model EfficientNet B4 sudah mampu mendeteksi seluruh data uji secara sempurna diduga karena tingkat kesulitan untuk mendeteksi data uji tidak begitu tinggi.: 3.2769230769230764,\n",
       " Dari keempat model, dapat dilihat bahwa model EfficientNet B4 masih memiliki akurasi terbesar, bahkan mampu mencapai angka maksimum.: 3.230769230769231,\n",
       " Hal ini menunjukkan bahwa model EfficientNet B4 merupakan model yang terbaik dari keempat model yang diuji dalam mengklasifikasikan dataset yang diberikan.: 4.061538461538461,\n",
       " 4.4.: 0.015384615384615385,\n",
       " Pen gujian Penggunaan Spatial Transformer Pengujian ini dilakukan dengan menambah kan lapisan localization dan lapisan Fully Connected yang merupakan bagian dari Spatial Transformer Network.: 1.3076923076923075,\n",
       " Lapisan -lapisan: 0.3076923076923077,\n",
       " ini ditambahkan tepat sebelum dimasukkan ke model EfficientNet B4 yang menjadi arsitektur utama.: 1.3846153846153846,\n",
       " Pengujian akan menggunakan optimiz er Adam dan learning rate 0.001 serta scheduler -nya.: 1.353846153846154,\n",
       " Model Akurasi Train Akurasi Test Waktu Training EfficientNet B4 99,96 78,10 4924s: 2.3692307692307697,\n",
       " EfficientNet B4 dengan Spatial Transformer 100 86,09 5950s: 0.4,\n",
       " EfficientNet B4 Pretrained dengan Spatial Transformer 100 100 6537s: 0.8769230769230769,\n",
       " Dari hasil pengujian yang ditunjukkan pada Tabel 6, terlihat terdapat peningkatan akurasi Test pada model EfficientNet B4 dengan Spatial Transformer, yaitu sebesar 8.: 2.6,\n",
       " Akurasi yang didapat apabila EfficientNet B4 Pretrained menggunakan Spatial Transformer mampu mencapai akurasi maksimum pada data Test, yaitu sebesar 100.: 2.246153846153846,\n",
       " Adanya peningkatan akurasi menunjukkan bahwa Spatial Transformer memiliki kemampuan untuk meningkatkan kemampuan dari model dalam klasifikasi, sehingga pantas untuk digunakan untuk model akhir.: 3.2615384615384615,\n",
       " Model akhir ini mampu mendapatkan nilai maksimum dari data testing, sehingga siap untuk diuji coba secara real-time.: 2.5384615384615388,\n",
       " 4.5.: 0.015384615384615385,\n",
       " Pen gujian Secara Real -Time Pengujian secara real-time dilakukan dengan mencoba dataset satu per satu terhadap suatu kondisi atau tampilan latar belakang tertentu dan menilai ke - efektifan masing -masing data terhadap masing - masing tampilan latar belakang, yaitu latar belakang putih, hitam, dan abstrak.: 4.323076923076923,\n",
       " Setelah itu, keempat dataset akan digabungkan menjadi satu untuk dicoba melihat keefektifannya terhadap masing -masing tampilan latar belakang.: 1.3384615384615386,\n",
       " Model yang digunakan adalah model dengan pengaturan serta arsitektur ya ng terbaik, yaitu EfficientNet B4 Pretrained dengan Spatial Transformer.: 2.6153846153846154,\n",
       " Data gambar akan di -convert menjadi single channel agar mempermudah prediksi melalui aplikasi.: 1.0307692307692307,\n",
       " Dataset Total Benar Akurasi Latar Belakang Pengujian Putih Hitam Abstrak Latar Belakang Putih Total Benar 22 23 13 Akurasi 85 88 50 Latar Belakang Hitam Total Benar 13 16 6 Akurasi 50 62 23 Latar Belakang Karpet Total Benar 9 12 3 Akurasi 35 46 12 Latar Belakang Pemandangan Total Benar 9 4 3 Akurasi 35 15 12 Gabungan Total Benar 26 26 23 Akurasi 100 100 88: 10.338461538461534,\n",
       " Tabel 7 menunjukkan bahwa akurasi yang didapat menggunakan dataset latar belakang hitam terlihat masih kurang baik.: 1.830769230769231,\n",
       " Dataset masih mampu melakukan klasifikasi pada latar belakang pengujian Mahardika, dkk, Sistem Rekognisi Citra Digital 1167 yang polos, seperti latar belakang putih dan hitam.: 3.0769230769230775,\n",
       " Total prediksi yang benar masih mampu mencapai 50 dari seluruh alfabet pada latar belakang putih dan sebesar 62 pada latar belakang hitam.: 1.9846153846153847,\n",
       " Hasil pengujian pada latar belakang abstrak terlihat hanya sebesar 23.: 1.4923076923076923,\n",
       " Dapat juga dilihat pada Tabel 7 bahwa dataset dengan latar belakang putih mampu melakukan klasifikasi dengan baik pada latar belakang pengujian putih dan hitam polos, tetapi tidak te rlalu buruk pada klasifikasi dengan background abstrak.: 3.5999999999999996,\n",
       " Total benar yang didapat pada latar belakang putih sebesar 85 dan latar belakang hitam 88 dari seluruh alfabet.: 1.7384615384615385,\n",
       " Hasil pengujian pada latar belakang abstrak hanya sebesar 50, tetapi hasil ini: 1.876923076923077,\n",
       " baik jika dibandingkan dengan dataset berlatar belakang hitam.: 0.9692307692307693,\n",
       " Hasil pengujian dataset berlatar belakang pemandangan terlihat kurang baik.: 1.523076923076923,\n",
       " Pada latar belakang putih, total benar yang didapat hanya sebesar 35 dari seluruh alfabet, hasil yang lebih buruk jika dibandingkan dengan kedua dataset di pengujian sebelumnya.: 2.5076923076923077,\n",
       " Tetapi, pengujian pada latar belakang hitam terlihat lebih buruk, hanya sebesar 15.: 1.2461538461538462,\n",
       " Pengujian pada latar belakang abstrak terlihat tidak jauh, yaitu hanya sebesar 12.: 1.123076923076923,\n",
       " Dataset berlatar be lakang karpet yang ditunjukkan pada Tabel 7 terlihat lebih baik daripada pengujian pada dataset berlatar belakang pemandangan, tetapi masih kurang jika dibandingkan dengan dataset berlatar belakang hitam dan putih.: 3.1538461538461537,\n",
       " Pengujian pada latar belakang putih terli hat mendapatkan total benar sebesar 35, dan pengujian pada latar belakang hitam terlihat mendapatkan total benar sebesar 46 dari seluruh alfabet.: 2.7384615384615385,\n",
       " Tetapi, pengujian pada latar belakang abstrak masih terlihat buruk, yaitu hanya 12.: 1.1846153846153846,\n",
       " Setelah keempat dataset diatas digabungkan, terlihat hasil pengujian secara real-time yang didapat cukup memuaskan.: 1.8000000000000003,\n",
       " Sebagaimana ditunjukkan pada Tabel 7, hasil pengujian dataset gabungan pada latar belakang putih terlihat mencapai 100 total benar.: 2.8461538461538463,\n",
       " Pengujian pada latar belakang hitam juga mencapai 100 total benar.: 1.784615384615385,\n",
       " Terakhir, pengujian pada latar belakang abstrak juga terlihat baik, yaitu sebesar 88.: 1.1076923076923078}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_length = int(len(sentence_tokens)*0.3)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset Total Benar Akurasi Latar Belakang Pengujian Putih Hitam Abstrak Latar Belakang Putih Total Benar 22 23 13 Akurasi 85 88 50 Latar Belakang Hitam Total Benar 13 16 6 Akurasi 50 62 23 Latar Belakang Karpet Total Benar 9 12 3 Akurasi 35 46 12 Latar Belakang Pemandangan Total Benar 9 4 3 Akurasi 35 15 12 Gabungan Total Benar 26 26 23 Akurasi 100 100 88, Hasil dari pengujian ditunjukkan pada Model Akurasi Waktu Training Train Valid ation Test ResNet18 99,89 100 54,73 3585s AlexNet 99,93 100 57,39 3350s ResNet50 99,83 100 57,10 4167s Efficient Net B4 99,96 100 78,10 4924s Hasil pengujian pada Tabel 2 menunjukkan bahwa model dengan arsitektur EfficientNet B4 memiliki akurasi testing yang tertinggi sebesar 78,10., Adapun perhitungan yang dilakukan pada lapisan convolutional adalah sebagai berikut H(x,y) b F(x,y) G(x,y) b F(j,k) k ( ) j ( ) G(x j,y k) (1) Keterangan F Filter Lapisan G Input feature map H Output feature map b Bias x Sumbu X pada data dan filter y Sumbu Y pada data dan filter j Increment untuk sumbu X k Increment untuk sumbu Y Suatu input feature map G dengan nilai G(x,y) akan dimasukkan ke dalam lapisan konvolusi., Data dengan background hitam merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada data dengan background putih juga merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada hitam memiliki jumlah sebanyak 70 gambar, sedangkan dataset background putih memiliki jumlah sebanyak 21 gambar., Data yang diambil memiliki dua macam background, yaitu data dengan background karpet bermot if ditunjukkan pada Gambar 3 dan data dengan background pemandangan pagi ditunjukkan pada background karpet memiliki jumlah sebanyak 54 gambar, sedangkan dataset background pemandangan memiliki jumlah sebanyak 40 gambar., Pengujian secara real-time juga akan memiliki variasi terhadap pengujiannya, dimana masing -masing dari keempat dataset akan diuji coba melakukan klasifikasi secara real-time terhadap tiga macam latar belakang, yaitu latar belakang putih polos, latar belak ang hitam polos, dan latar belakang abstrak atau bermacam -macam warna., Hasil dari pengujian ditunjukkan pada Optimizer Akurasi Waktu Training Train Validation Test Adam 99,96 100 78,10 4924s SGD 4,79 3,85 3,84 4707s RMSProp 99,98 100 57,39 4767s Berdasarkan hasil pengujian Tabel 3, dapat dilihat bahwa model yang menggunakan optimizer SGD terlihat tidak berkembang., Penyusunan dataset uji per alfabet adalah satu gambar dari setiap dataset background hitam, putih, karpet, dan pemandangan ditambah tiga gambar dari setiap dataset background bunga, langit merah, dan gunung sebagaimana ditunjukkan pada gambar unt uk setiap alfabet, menjadikan 338 total gambar data uji., Pada perancangan model Convolutional Neural Network dari sistem rekognisi citra digital bahasa isyarat diawali dengan adanya pemrosesan awal dengan mengubah di mensi dari data dan juga mengkonversi data menjadi berbentuk Tensor agar dapat diberikan sebagai input kepada model CNN., Data sekunder yang akan digunakan ada dua macam, yaitu data bahasa isyarat dengan background hitam dan data bahasa isyarat dengan background putih., Sebagaimana ditunjukkan pada Tabel 4, Gambar 8, dan Gambar 9, pe ngujian penggunaan Learning Rate Scheduler pada model CNN tampak memiliki pengaruh terhadap proses pelatihan maupun hasil dari output model tersebut., Sel ain itu, hal ini juga memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler sebagaimana ditunjukkan pada maupun testing, peng gunaan scheduler terlihat mampu menaikkan akurasi pada model yang dilatih 4.3., Untuk setiap j pada sumbu x dan setiap k pada sumbu y, nilai input G(x j,y k) akan dikalikan dengan nilai kernel F(j,k) dan hasilnya akan dijumlahkan sesuai dengan ukuran data input pada nilai j dan k. Hasil dari total penjumlahan tersebut akan dijumlahkan dengan nilai bias b untuk menjadi nilai output H(x,y)., Pen gujian Secara Real -Time Pengujian secara real-time dilakukan dengan mencoba dataset satu per satu terhadap suatu kondisi atau tampilan latar belakang tertentu dan menilai ke - efektifan masing -masing data terhadap masing - masing tampilan latar belakang, yaitu latar belakang putih, hitam, dan abstrak., Model Akurasi Waktu Training Train Validation Test ResNet18 99,89 100 54,73 3585s ResNet18 Pretrained 100 100 84,91 3566s AlexNet 99,93 100 57,39 3350s AlexNet Pretrained 99,96 99,04 75,44 3345s ResNet50 99,83 100 57,10 4167s ResNet50, EfficientNet B4 99,96 100 78,10 4924s EfficientNet B4 Pretrained 99,96 100 100 4870s Berdasarkan hasil pengujian yang ditunjukkan pada Tabel 5, dapat dilihat bahwa terdapat peningkatan pada akurasi testing untuk seluruh model., Hal ini menunjukkan bahwa model EfficientNet B4 merupakan model yang terbaik dari keempat model yang diuji dalam mengklasifikasikan dataset yang diberikan., Setelah didapat model dan pengaturan hyperparameter yang terbaik, dilakukan pen gujian penggunaan pretrained weights dari arsitektur model untuk mencoba menaikkan hasil akurasi., Pen gujian Penggunaan Pretrained Weights Pengujian penggunaan pretrained weights dilakukan dengan menggunakan parameter pretrained True ketika memanggil model menggunakan library torch untuk menggunakan weights yang sebelumnya telah dilatih dan disediakan pada pemanggilan model., Hasil ini menunjukkan bahwa model EfficientNet B4 memiliki kemampuan terbaik dalam prediksi data uji dibanding model lainnya, walau waktu pelatihannya memakan waktu paling lama., Transfer Learning Transfer Learning merupakan salah satu teknik dari penggunaan Deep Learning, dimana model yang sebelumnya telah melewati tahap training digunakan kembali untuk mengekstrak dan tuning lebih lanjut pada model lain untuk memperbaiki akurasi., Selain itu, ditambahkan pula tiga set gambar yang tidak berada dalam data training maupun validation, yaitu dataset dengan background bunga, dataset dengan background langit merah, dan dataset dengan background gunung., Hal ini dikarenakan terdapat banyak bentuk bahasa isyarat di dunia, sehingga untuk dapat mendeteksi bahasa isyarat yang ada pada regional tertentu, diperlukan dataset bahasa isyarat dari lokasi tersebut., Alur perancangan model ini dilakukan sebagaimana pada 1162 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 Arsitektur yang akan digunakan dalam penelitian sistem rekognisi citra digital bahasa isyarat menggunakan Convolutional Neural Network akan menggunakan berbagai pretrained weights yang telah disediakan oleh library PyTorch., Dapat juga dilihat pada Tabel 7 bahwa dataset dengan latar belakang putih mampu melakukan klasifikasi dengan baik pada latar belakang pengujian putih dan hitam polos, tetapi tidak te rlalu buruk pada klasifikasi dengan background abstrak., 2. METODE PENELITIAN 2.1 Data Penelitian Data yang digunakan untuk training model adalah data sekunder yang didapat, Data gamb ar yang diambil akan memiliki pose dan bentuk bahasa isyarat yang sama dengan data sekunder dari internet tersebut, tetapi akan memiliki background yang bervariasi., yang merupakan bagian dari Deep Learning atau Machine Learning dan dengan metode Spatial Transformer, sistem akan mengenali pose atau bentuk dari citra bahasa isyarat yang dimasukkan, dan memberikan luaran yang sesuai dengan maksud dari pose atau bentuk dari citra bahasa isyarat tersebut., Model dan weights -nya sudah dilatih sebelumnya menggunakan dataset ImageNet -1k dengan tujuan membantu meningkatkan akurasi dari model., Selain memiliki akurasi testing yang tertinggi, akurasi training dan validation dari model Effi cientNet B4 juga yang terbesar, yaitu sebesar 99,96 untuk training dan 100 untuk validation., 4.2 Pengujian Hyperparameter Pengujian Hyperparameter dilakukan dengan menentukan pengat uran Hyperparameter yang dapat Mahardika, dkk, Sistem Rekognisi Citra Digital 1165 memberikan hasil yang terbaik, dan pengaturan Hyperparameter yang akan diuji yaitu optimizer dan penggunaan learning rate scheduler., Pengambilan data pribadi ini dilakukan untuk Mahardika, dkk, Sistem Rekognisi Citra Digital 1161 menguji adanya perbedaan hasil pada pengujian apabila menggunakan data dengan background yang berbeda dan mengetahui seberapa besar pengaruh yang dimiliki oleh background tersebut terhadap keseluruhan percobaan, sebagaimana permasalahan ini disebutkan sebelumnya oleh., Hasil ini menunjukkan bahwa model EfficientNet B4 sudah mampu mendeteksi seluruh data uji secara sempurna diduga karena tingkat kesulitan untuk mendeteksi data uji tidak begitu tinggi., Adanya peningkatan akurasi menunjukkan bahwa Spatial Transformer memiliki kemampuan untuk meningkatkan kemampuan dari model dalam klasifikasi, sehingga pantas untuk digunakan untuk model akhir., Dari keempat model, dapat dilihat bahwa model EfficientNet B4 masih memiliki akurasi terbesar, bahkan mampu mencapai angka maksimum., Model dengan optimizer RMSProp terlihat cukup baik, akan tetapi akurasi testing -nya tidak sebaik dengan model yang menggunakan optimizer Adam., Dataset berlatar be lakang karpet yang ditunjukkan pada Tabel 7 terlihat lebih baik daripada pengujian pada dataset berlatar belakang pemandangan, tetapi masih kurang jika dibandingkan dengan dataset berlatar belakang hitam dan putih., 4.1 Pengujian Arsitektur Model Dalam pengujian ini digunakan empat tipe model., Dataset masih mampu melakukan klasifikasi pada latar belakang pengujian Mahardika, dkk, Sistem Rekognisi Citra Digital 1167 yang polos, seperti latar belakang putih dan hitam., Terakhir, dilakukan pengujian dengan data uji untuk menentukan seberapa baik ki nerja model dalam pekerjaan mengklasifikasi dan merekognisi dataset digital tersebut., Kesimpulan dari penelitian ini adalah untuk dapat mendeteksi bahasa isyarat, diperlukan dataset tertentu untuk setiap bentuk bahasa isyarat., Sebagaimana ditunjukkan pada Tabel 7, hasil pengujian dataset gabungan pada latar belakang putih terlihat mencapai 100 total benar., Setelah melihat performa dari masing - masing dataset, dilakukan uji coba mengguna kan dataset gabungan dari keempat dataset untuk mencoba mendapatkan hasil yang terbaik., Hal ini memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler., Pengujian secara real-time dilakukan dengan melakukan export terhadap model dengan hasil yang terbaik, lalu diuji dengan gambar nyata yang diambil menggunakan kamera atau webcam., Pengujian pada latar belakang putih terli hat mendapatkan total benar sebesar 35, dan pengujian pada latar belakang hitam terlihat mendapatkan total benar sebesar 46 dari seluruh alfabet., Untuk model pengujian digunakan model EfficientNet B4 untuk mencari kombinasi Hyperparameter yang terbaik., Perubahan ter hadap nilai learning rate menjadikan proses pelatihan menjadi lebih teratur dan tidak fluktuatif, sebagaimana dapat dilihat pada model yang dilatih masih belum mampu memberikan hasil yang konsisten., Model yang digunakan adalah model dengan pengaturan serta arsitektur ya ng terbaik, yaitu EfficientNet B4 Pretrained dengan Spatial Transformer., Dari hasil pengujian yang ditunjukkan pada Tabel 6, terlihat terdapat peningkatan akurasi Test pada model EfficientNet B4 dengan Spatial Transformer, yaitu sebesar 8., Pengujian model, hyperparameter, pretrained weights, dan Spatial Transformer akan menggunakan akurasi sebagai metrik utama dengan mencatat juga waktu jalannya proses tr aining., Pembuatan sistem klasifikasi bahasa isyarat sebelumnya pernah dilakukan oleh yang membuat asisten virtual untuk bahasa isyarat menggunakan deep learning dan tensorflow., Model akhir ini mampu mendapatkan nilai maksimum dari data testing, sehingga siap untuk diuji coba secara real-time., Hasil ini menunjukkan bahwa model EfficientNet B4 mampu mendeteksi alfabet dalam data uji hingga didapatkan 78,10 kebenarannya., Waktu pelatihan tercepat jatuh kepada model AlexNet dengan waktu 3350 detik atau hanya 55 menit dan terlama pada model EfficientNet B4 dengan waktu 4924 detik atau 1 jam 22 menit., Pada latar belakang putih, total benar yang didapat hanya sebesar 35 dari seluruh alfabet, hasil yang lebih buruk jika dibandingkan dengan kedua dataset di pengujian sebelumnya., Apabila kinerja model masih kurang baik, maka perlu dilakukan perbaikan atau Tweaking pada model dengan tujuan mendapatkan hasil yang lebih baik., Metrik utama yang akan diperhatikan adalah jumlah epoch yang diperlukan dari model hingga mencapai titik konvergen, atau titik dimana akurasi pelatihan tidak lagi fluktuatif., Sedangkan untuk learning rate, pengujian hanya akan menguji penggunaan learning rate scheduler untuk menilai keefektifan scheduler dalam membantu proses training., Model Akurasi Train Akurasi Test Waktu Training EfficientNet B4 99,96 78,10 4924s, 4. HASIL DAN PEMBAHASAN Pengujian pertama yang akan diuji adalah pengaturan arsitektur CNN dengan model, Khusus untuk learning rate, ditambahkan metrik berupa epoch hingga konvergen untuk menilai seberapa cepat model mampu mencapai titik konvergen pada proses pelatihan., Setelah arsitektur dari model CNN telah ditentukan, dilakukan proses pelatihan atau Training pada dataset.]\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary = [word.text for word in summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dataset Total Benar Akurasi Latar Belakang Pengujian Putih Hitam Abstrak Latar Belakang Putih Total Benar 22 23 13 Akurasi 85 88 50 Latar Belakang Hitam Total Benar 13 16 6 Akurasi 50 62 23 Latar Belakang Karpet Total Benar 9 12 3 Akurasi 35 46 12 Latar Belakang Pemandangan Total Benar 9 4 3 Akurasi 35 15 12 Gabungan Total Benar 26 26 23 Akurasi 100 100 88', 'Hasil dari pengujian ditunjukkan pada Model Akurasi Waktu Training Train Valid ation Test ResNet18 99,89 100 54,73 3585s AlexNet 99,93 100 57,39 3350s ResNet50 99,83 100 57,10 4167s Efficient Net B4 99,96 100 78,10 4924s Hasil pengujian pada Tabel 2 menunjukkan bahwa model dengan arsitektur EfficientNet B4 memiliki akurasi testing yang tertinggi sebesar 78,10.', 'Adapun perhitungan yang dilakukan pada lapisan convolutional adalah sebagai berikut H(x,y) b F(x,y) G(x,y) b F(j,k) k ( ) j ( ) G(x j,y k) (1) Keterangan F Filter Lapisan G Input feature map H Output feature map b Bias x Sumbu X pada data dan filter y Sumbu Y pada data dan filter j Increment untuk sumbu X k Increment untuk sumbu Y Suatu input feature map G dengan nilai G(x,y) akan dimasukkan ke dalam lapisan konvolusi.', 'Data dengan background hitam merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada data dengan background putih juga merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada hitam memiliki jumlah sebanyak 70 gambar, sedangkan dataset background putih memiliki jumlah sebanyak 21 gambar.', 'Data yang diambil memiliki dua macam background, yaitu data dengan background karpet bermot if ditunjukkan pada Gambar 3 dan data dengan background pemandangan pagi ditunjukkan pada background karpet memiliki jumlah sebanyak 54 gambar, sedangkan dataset background pemandangan memiliki jumlah sebanyak 40 gambar.', 'Pengujian secara real-time juga akan memiliki variasi terhadap pengujiannya, dimana masing -masing dari keempat dataset akan diuji coba melakukan klasifikasi secara real-time terhadap tiga macam latar belakang, yaitu latar belakang putih polos, latar belak ang hitam polos, dan latar belakang abstrak atau bermacam -macam warna.', 'Hasil dari pengujian ditunjukkan pada Optimizer Akurasi Waktu Training Train Validation Test Adam 99,96 100 78,10 4924s SGD 4,79 3,85 3,84 4707s RMSProp 99,98 100 57,39 4767s Berdasarkan hasil pengujian Tabel 3, dapat dilihat bahwa model yang menggunakan optimizer SGD terlihat tidak berkembang.', 'Penyusunan dataset uji per alfabet adalah satu gambar dari setiap dataset background hitam, putih, karpet, dan pemandangan ditambah tiga gambar dari setiap dataset background bunga, langit merah, dan gunung sebagaimana ditunjukkan pada gambar unt uk setiap alfabet, menjadikan 338 total gambar data uji.', 'Pada perancangan model Convolutional Neural Network dari sistem rekognisi citra digital bahasa isyarat diawali dengan adanya pemrosesan awal dengan mengubah di mensi dari data dan juga mengkonversi data menjadi berbentuk Tensor agar dapat diberikan sebagai input kepada model CNN.', 'Data sekunder yang akan digunakan ada dua macam, yaitu data bahasa isyarat dengan background hitam dan data bahasa isyarat dengan background putih.', 'Sebagaimana ditunjukkan pada Tabel 4, Gambar 8, dan Gambar 9, pe ngujian penggunaan Learning Rate Scheduler pada model CNN tampak memiliki pengaruh terhadap proses pelatihan maupun hasil dari output model tersebut.', 'Sel ain itu, hal ini juga memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler sebagaimana ditunjukkan pada maupun testing, peng gunaan scheduler terlihat mampu menaikkan akurasi pada model yang dilatih 4.3.', 'Untuk setiap j pada sumbu x dan setiap k pada sumbu y, nilai input G(x j,y k) akan dikalikan dengan nilai kernel F(j,k) dan hasilnya akan dijumlahkan sesuai dengan ukuran data input pada nilai j dan k. Hasil dari total penjumlahan tersebut akan dijumlahkan dengan nilai bias b untuk menjadi nilai output H(x,y).', 'Pen gujian Secara Real -Time Pengujian secara real-time dilakukan dengan mencoba dataset satu per satu terhadap suatu kondisi atau tampilan latar belakang tertentu dan menilai ke - efektifan masing -masing data terhadap masing - masing tampilan latar belakang, yaitu latar belakang putih, hitam, dan abstrak.', 'Model Akurasi Waktu Training Train Validation Test ResNet18 99,89 100 54,73 3585s ResNet18 Pretrained 100 100 84,91 3566s AlexNet 99,93 100 57,39 3350s AlexNet Pretrained 99,96 99,04 75,44 3345s ResNet50 99,83 100 57,10 4167s ResNet50', 'EfficientNet B4 99,96 100 78,10 4924s EfficientNet B4 Pretrained 99,96 100 100 4870s Berdasarkan hasil pengujian yang ditunjukkan pada Tabel 5, dapat dilihat bahwa terdapat peningkatan pada akurasi testing untuk seluruh model.', 'Hal ini menunjukkan bahwa model EfficientNet B4 merupakan model yang terbaik dari keempat model yang diuji dalam mengklasifikasikan dataset yang diberikan.', 'Setelah didapat model dan pengaturan hyperparameter yang terbaik, dilakukan pen gujian penggunaan pretrained weights dari arsitektur model untuk mencoba menaikkan hasil akurasi.', 'Pen gujian Penggunaan Pretrained Weights Pengujian penggunaan pretrained weights dilakukan dengan menggunakan parameter pretrained True ketika memanggil model menggunakan library torch untuk menggunakan weights yang sebelumnya telah dilatih dan disediakan pada pemanggilan model.', 'Hasil ini menunjukkan bahwa model EfficientNet B4 memiliki kemampuan terbaik dalam prediksi data uji dibanding model lainnya, walau waktu pelatihannya memakan waktu paling lama.', 'Transfer Learning Transfer Learning merupakan salah satu teknik dari penggunaan Deep Learning, dimana model yang sebelumnya telah melewati tahap training digunakan kembali untuk mengekstrak dan tuning lebih lanjut pada model lain untuk memperbaiki akurasi.', 'Selain itu, ditambahkan pula tiga set gambar yang tidak berada dalam data training maupun validation, yaitu dataset dengan background bunga, dataset dengan background langit merah, dan dataset dengan background gunung.', 'Hal ini dikarenakan terdapat banyak bentuk bahasa isyarat di dunia, sehingga untuk dapat mendeteksi bahasa isyarat yang ada pada regional tertentu, diperlukan dataset bahasa isyarat dari lokasi tersebut.', 'Alur perancangan model ini dilakukan sebagaimana pada 1162 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 Arsitektur yang akan digunakan dalam penelitian sistem rekognisi citra digital bahasa isyarat menggunakan Convolutional Neural Network akan menggunakan berbagai pretrained weights yang telah disediakan oleh library PyTorch.', 'Dapat juga dilihat pada Tabel 7 bahwa dataset dengan latar belakang putih mampu melakukan klasifikasi dengan baik pada latar belakang pengujian putih dan hitam polos, tetapi tidak te rlalu buruk pada klasifikasi dengan background abstrak.', '2. METODE PENELITIAN 2.1 Data Penelitian Data yang digunakan untuk training model adalah data sekunder yang didapat', 'Data gamb ar yang diambil akan memiliki pose dan bentuk bahasa isyarat yang sama dengan data sekunder dari internet tersebut, tetapi akan memiliki background yang bervariasi.', 'yang merupakan bagian dari Deep Learning atau Machine Learning dan dengan metode Spatial Transformer, sistem akan mengenali pose atau bentuk dari citra bahasa isyarat yang dimasukkan, dan memberikan luaran yang sesuai dengan maksud dari pose atau bentuk dari citra bahasa isyarat tersebut.', 'Model dan weights -nya sudah dilatih sebelumnya menggunakan dataset ImageNet -1k dengan tujuan membantu meningkatkan akurasi dari model.', 'Selain memiliki akurasi testing yang tertinggi, akurasi training dan validation dari model Effi cientNet B4 juga yang terbesar, yaitu sebesar 99,96 untuk training dan 100 untuk validation.', '4.2 Pengujian Hyperparameter Pengujian Hyperparameter dilakukan dengan menentukan pengat uran Hyperparameter yang dapat Mahardika, dkk, Sistem Rekognisi Citra Digital 1165 memberikan hasil yang terbaik, dan pengaturan Hyperparameter yang akan diuji yaitu optimizer dan penggunaan learning rate scheduler.', 'Pengambilan data pribadi ini dilakukan untuk Mahardika, dkk, Sistem Rekognisi Citra Digital 1161 menguji adanya perbedaan hasil pada pengujian apabila menggunakan data dengan background yang berbeda dan mengetahui seberapa besar pengaruh yang dimiliki oleh background tersebut terhadap keseluruhan percobaan, sebagaimana permasalahan ini disebutkan sebelumnya oleh.', 'Hasil ini menunjukkan bahwa model EfficientNet B4 sudah mampu mendeteksi seluruh data uji secara sempurna diduga karena tingkat kesulitan untuk mendeteksi data uji tidak begitu tinggi.', 'Adanya peningkatan akurasi menunjukkan bahwa Spatial Transformer memiliki kemampuan untuk meningkatkan kemampuan dari model dalam klasifikasi, sehingga pantas untuk digunakan untuk model akhir.', 'Dari keempat model, dapat dilihat bahwa model EfficientNet B4 masih memiliki akurasi terbesar, bahkan mampu mencapai angka maksimum.', 'Model dengan optimizer RMSProp terlihat cukup baik, akan tetapi akurasi testing -nya tidak sebaik dengan model yang menggunakan optimizer Adam.', 'Dataset berlatar be lakang karpet yang ditunjukkan pada Tabel 7 terlihat lebih baik daripada pengujian pada dataset berlatar belakang pemandangan, tetapi masih kurang jika dibandingkan dengan dataset berlatar belakang hitam dan putih.', '4.1 Pengujian Arsitektur Model Dalam pengujian ini digunakan empat tipe model.', 'Dataset masih mampu melakukan klasifikasi pada latar belakang pengujian Mahardika, dkk, Sistem Rekognisi Citra Digital 1167 yang polos, seperti latar belakang putih dan hitam.', 'Terakhir, dilakukan pengujian dengan data uji untuk menentukan seberapa baik ki nerja model dalam pekerjaan mengklasifikasi dan merekognisi dataset digital tersebut.', 'Kesimpulan dari penelitian ini adalah untuk dapat mendeteksi bahasa isyarat, diperlukan dataset tertentu untuk setiap bentuk bahasa isyarat.', 'Sebagaimana ditunjukkan pada Tabel 7, hasil pengujian dataset gabungan pada latar belakang putih terlihat mencapai 100 total benar.', 'Setelah melihat performa dari masing - masing dataset, dilakukan uji coba mengguna kan dataset gabungan dari keempat dataset untuk mencoba mendapatkan hasil yang terbaik.', 'Hal ini memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler.', 'Pengujian secara real-time dilakukan dengan melakukan export terhadap model dengan hasil yang terbaik, lalu diuji dengan gambar nyata yang diambil menggunakan kamera atau webcam.', 'Pengujian pada latar belakang putih terli hat mendapatkan total benar sebesar 35, dan pengujian pada latar belakang hitam terlihat mendapatkan total benar sebesar 46 dari seluruh alfabet.', 'Untuk model pengujian digunakan model EfficientNet B4 untuk mencari kombinasi Hyperparameter yang terbaik.', 'Perubahan ter hadap nilai learning rate menjadikan proses pelatihan menjadi lebih teratur dan tidak fluktuatif, sebagaimana dapat dilihat pada model yang dilatih masih belum mampu memberikan hasil yang konsisten.', 'Model yang digunakan adalah model dengan pengaturan serta arsitektur ya ng terbaik, yaitu EfficientNet B4 Pretrained dengan Spatial Transformer.', 'Dari hasil pengujian yang ditunjukkan pada Tabel 6, terlihat terdapat peningkatan akurasi Test pada model EfficientNet B4 dengan Spatial Transformer, yaitu sebesar 8.', 'Pengujian model, hyperparameter, pretrained weights, dan Spatial Transformer akan menggunakan akurasi sebagai metrik utama dengan mencatat juga waktu jalannya proses tr aining.', 'Pembuatan sistem klasifikasi bahasa isyarat sebelumnya pernah dilakukan oleh yang membuat asisten virtual untuk bahasa isyarat menggunakan deep learning dan tensorflow.', 'Model akhir ini mampu mendapatkan nilai maksimum dari data testing, sehingga siap untuk diuji coba secara real-time.', 'Hasil ini menunjukkan bahwa model EfficientNet B4 mampu mendeteksi alfabet dalam data uji hingga didapatkan 78,10 kebenarannya.', 'Waktu pelatihan tercepat jatuh kepada model AlexNet dengan waktu 3350 detik atau hanya 55 menit dan terlama pada model EfficientNet B4 dengan waktu 4924 detik atau 1 jam 22 menit.', 'Pada latar belakang putih, total benar yang didapat hanya sebesar 35 dari seluruh alfabet, hasil yang lebih buruk jika dibandingkan dengan kedua dataset di pengujian sebelumnya.', 'Apabila kinerja model masih kurang baik, maka perlu dilakukan perbaikan atau Tweaking pada model dengan tujuan mendapatkan hasil yang lebih baik.', 'Metrik utama yang akan diperhatikan adalah jumlah epoch yang diperlukan dari model hingga mencapai titik konvergen, atau titik dimana akurasi pelatihan tidak lagi fluktuatif.', 'Sedangkan untuk learning rate, pengujian hanya akan menguji penggunaan learning rate scheduler untuk menilai keefektifan scheduler dalam membantu proses training.', 'Model Akurasi Train Akurasi Test Waktu Training EfficientNet B4 99,96 78,10 4924s', '4. HASIL DAN PEMBAHASAN Pengujian pertama yang akan diuji adalah pengaturan arsitektur CNN dengan model', 'Khusus untuk learning rate, ditambahkan metrik berupa epoch hingga konvergen untuk menilai seberapa cepat model mampu mencapai titik konvergen pada proses pelatihan.', 'Setelah arsitektur dari model CNN telah ditentukan, dilakukan proses pelatihan atau Training pada dataset.']\n"
     ]
    }
   ],
   "source": [
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = ' '.join(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset Total Benar Akurasi Latar Belakang Pengujian Putih Hitam Abstrak Latar Belakang Putih Total Benar 22 23 13 Akurasi 85 88 50 Latar Belakang Hitam Total Benar 13 16 6 Akurasi 50 62 23 Latar Belakang Karpet Total Benar 9 12 3 Akurasi 35 46 12 Latar Belakang Pemandangan Total Benar 9 4 3 Akurasi 35 15 12 Gabungan Total Benar 26 26 23 Akurasi 100 100 88 Hasil dari pengujian ditunjukkan pada Model Akurasi Waktu Training Train Valid ation Test ResNet18 99,89 100 54,73 3585s AlexNet 99,93 100 57,39 3350s ResNet50 99,83 100 57,10 4167s Efficient Net B4 99,96 100 78,10 4924s Hasil pengujian pada Tabel 2 menunjukkan bahwa model dengan arsitektur EfficientNet B4 memiliki akurasi testing yang tertinggi sebesar 78,10. Adapun perhitungan yang dilakukan pada lapisan convolutional adalah sebagai berikut H(x,y) b F(x,y) G(x,y) b F(j,k) k ( ) j ( ) G(x j,y k) (1) Keterangan F Filter Lapisan G Input feature map H Output feature map b Bias x Sumbu X pada data dan filter y Sumbu Y pada data dan filter j Increment untuk sumbu X k Increment untuk sumbu Y Suatu input feature map G dengan nilai G(x,y) akan dimasukkan ke dalam lapisan konvolusi. Data dengan background hitam merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada data dengan background putih juga merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada hitam memiliki jumlah sebanyak 70 gambar, sedangkan dataset background putih memiliki jumlah sebanyak 21 gambar. Data yang diambil memiliki dua macam background, yaitu data dengan background karpet bermot if ditunjukkan pada Gambar 3 dan data dengan background pemandangan pagi ditunjukkan pada background karpet memiliki jumlah sebanyak 54 gambar, sedangkan dataset background pemandangan memiliki jumlah sebanyak 40 gambar. Pengujian secara real-time juga akan memiliki variasi terhadap pengujiannya, dimana masing -masing dari keempat dataset akan diuji coba melakukan klasifikasi secara real-time terhadap tiga macam latar belakang, yaitu latar belakang putih polos, latar belak ang hitam polos, dan latar belakang abstrak atau bermacam -macam warna. Hasil dari pengujian ditunjukkan pada Optimizer Akurasi Waktu Training Train Validation Test Adam 99,96 100 78,10 4924s SGD 4,79 3,85 3,84 4707s RMSProp 99,98 100 57,39 4767s Berdasarkan hasil pengujian Tabel 3, dapat dilihat bahwa model yang menggunakan optimizer SGD terlihat tidak berkembang. Penyusunan dataset uji per alfabet adalah satu gambar dari setiap dataset background hitam, putih, karpet, dan pemandangan ditambah tiga gambar dari setiap dataset background bunga, langit merah, dan gunung sebagaimana ditunjukkan pada gambar unt uk setiap alfabet, menjadikan 338 total gambar data uji. Pada perancangan model Convolutional Neural Network dari sistem rekognisi citra digital bahasa isyarat diawali dengan adanya pemrosesan awal dengan mengubah di mensi dari data dan juga mengkonversi data menjadi berbentuk Tensor agar dapat diberikan sebagai input kepada model CNN. Data sekunder yang akan digunakan ada dua macam, yaitu data bahasa isyarat dengan background hitam dan data bahasa isyarat dengan background putih. Sebagaimana ditunjukkan pada Tabel 4, Gambar 8, dan Gambar 9, pe ngujian penggunaan Learning Rate Scheduler pada model CNN tampak memiliki pengaruh terhadap proses pelatihan maupun hasil dari output model tersebut. Sel ain itu, hal ini juga memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler sebagaimana ditunjukkan pada maupun testing, peng gunaan scheduler terlihat mampu menaikkan akurasi pada model yang dilatih 4.3. Untuk setiap j pada sumbu x dan setiap k pada sumbu y, nilai input G(x j,y k) akan dikalikan dengan nilai kernel F(j,k) dan hasilnya akan dijumlahkan sesuai dengan ukuran data input pada nilai j dan k. Hasil dari total penjumlahan tersebut akan dijumlahkan dengan nilai bias b untuk menjadi nilai output H(x,y). Pen gujian Secara Real -Time Pengujian secara real-time dilakukan dengan mencoba dataset satu per satu terhadap suatu kondisi atau tampilan latar belakang tertentu dan menilai ke - efektifan masing -masing data terhadap masing - masing tampilan latar belakang, yaitu latar belakang putih, hitam, dan abstrak. Model Akurasi Waktu Training Train Validation Test ResNet18 99,89 100 54,73 3585s ResNet18 Pretrained 100 100 84,91 3566s AlexNet 99,93 100 57,39 3350s AlexNet Pretrained 99,96 99,04 75,44 3345s ResNet50 99,83 100 57,10 4167s ResNet50 EfficientNet B4 99,96 100 78,10 4924s EfficientNet B4 Pretrained 99,96 100 100 4870s Berdasarkan hasil pengujian yang ditunjukkan pada Tabel 5, dapat dilihat bahwa terdapat peningkatan pada akurasi testing untuk seluruh model. Hal ini menunjukkan bahwa model EfficientNet B4 merupakan model yang terbaik dari keempat model yang diuji dalam mengklasifikasikan dataset yang diberikan. Setelah didapat model dan pengaturan hyperparameter yang terbaik, dilakukan pen gujian penggunaan pretrained weights dari arsitektur model untuk mencoba menaikkan hasil akurasi. Pen gujian Penggunaan Pretrained Weights Pengujian penggunaan pretrained weights dilakukan dengan menggunakan parameter pretrained True ketika memanggil model menggunakan library torch untuk menggunakan weights yang sebelumnya telah dilatih dan disediakan pada pemanggilan model. Hasil ini menunjukkan bahwa model EfficientNet B4 memiliki kemampuan terbaik dalam prediksi data uji dibanding model lainnya, walau waktu pelatihannya memakan waktu paling lama. Transfer Learning Transfer Learning merupakan salah satu teknik dari penggunaan Deep Learning, dimana model yang sebelumnya telah melewati tahap training digunakan kembali untuk mengekstrak dan tuning lebih lanjut pada model lain untuk memperbaiki akurasi. Selain itu, ditambahkan pula tiga set gambar yang tidak berada dalam data training maupun validation, yaitu dataset dengan background bunga, dataset dengan background langit merah, dan dataset dengan background gunung. Hal ini dikarenakan terdapat banyak bentuk bahasa isyarat di dunia, sehingga untuk dapat mendeteksi bahasa isyarat yang ada pada regional tertentu, diperlukan dataset bahasa isyarat dari lokasi tersebut. Alur perancangan model ini dilakukan sebagaimana pada 1162 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 Arsitektur yang akan digunakan dalam penelitian sistem rekognisi citra digital bahasa isyarat menggunakan Convolutional Neural Network akan menggunakan berbagai pretrained weights yang telah disediakan oleh library PyTorch. Dapat juga dilihat pada Tabel 7 bahwa dataset dengan latar belakang putih mampu melakukan klasifikasi dengan baik pada latar belakang pengujian putih dan hitam polos, tetapi tidak te rlalu buruk pada klasifikasi dengan background abstrak. 2. METODE PENELITIAN 2.1 Data Penelitian Data yang digunakan untuk training model adalah data sekunder yang didapat Data gamb ar yang diambil akan memiliki pose dan bentuk bahasa isyarat yang sama dengan data sekunder dari internet tersebut, tetapi akan memiliki background yang bervariasi. yang merupakan bagian dari Deep Learning atau Machine Learning dan dengan metode Spatial Transformer, sistem akan mengenali pose atau bentuk dari citra bahasa isyarat yang dimasukkan, dan memberikan luaran yang sesuai dengan maksud dari pose atau bentuk dari citra bahasa isyarat tersebut. Model dan weights -nya sudah dilatih sebelumnya menggunakan dataset ImageNet -1k dengan tujuan membantu meningkatkan akurasi dari model. Selain memiliki akurasi testing yang tertinggi, akurasi training dan validation dari model Effi cientNet B4 juga yang terbesar, yaitu sebesar 99,96 untuk training dan 100 untuk validation. 4.2 Pengujian Hyperparameter Pengujian Hyperparameter dilakukan dengan menentukan pengat uran Hyperparameter yang dapat Mahardika, dkk, Sistem Rekognisi Citra Digital 1165 memberikan hasil yang terbaik, dan pengaturan Hyperparameter yang akan diuji yaitu optimizer dan penggunaan learning rate scheduler. Pengambilan data pribadi ini dilakukan untuk Mahardika, dkk, Sistem Rekognisi Citra Digital 1161 menguji adanya perbedaan hasil pada pengujian apabila menggunakan data dengan background yang berbeda dan mengetahui seberapa besar pengaruh yang dimiliki oleh background tersebut terhadap keseluruhan percobaan, sebagaimana permasalahan ini disebutkan sebelumnya oleh. Hasil ini menunjukkan bahwa model EfficientNet B4 sudah mampu mendeteksi seluruh data uji secara sempurna diduga karena tingkat kesulitan untuk mendeteksi data uji tidak begitu tinggi. Adanya peningkatan akurasi menunjukkan bahwa Spatial Transformer memiliki kemampuan untuk meningkatkan kemampuan dari model dalam klasifikasi, sehingga pantas untuk digunakan untuk model akhir. Dari keempat model, dapat dilihat bahwa model EfficientNet B4 masih memiliki akurasi terbesar, bahkan mampu mencapai angka maksimum. Model dengan optimizer RMSProp terlihat cukup baik, akan tetapi akurasi testing -nya tidak sebaik dengan model yang menggunakan optimizer Adam. Dataset berlatar be lakang karpet yang ditunjukkan pada Tabel 7 terlihat lebih baik daripada pengujian pada dataset berlatar belakang pemandangan, tetapi masih kurang jika dibandingkan dengan dataset berlatar belakang hitam dan putih. 4.1 Pengujian Arsitektur Model Dalam pengujian ini digunakan empat tipe model. Dataset masih mampu melakukan klasifikasi pada latar belakang pengujian Mahardika, dkk, Sistem Rekognisi Citra Digital 1167 yang polos, seperti latar belakang putih dan hitam. Terakhir, dilakukan pengujian dengan data uji untuk menentukan seberapa baik ki nerja model dalam pekerjaan mengklasifikasi dan merekognisi dataset digital tersebut. Kesimpulan dari penelitian ini adalah untuk dapat mendeteksi bahasa isyarat, diperlukan dataset tertentu untuk setiap bentuk bahasa isyarat. Sebagaimana ditunjukkan pada Tabel 7, hasil pengujian dataset gabungan pada latar belakang putih terlihat mencapai 100 total benar. Setelah melihat performa dari masing - masing dataset, dilakukan uji coba mengguna kan dataset gabungan dari keempat dataset untuk mencoba mendapatkan hasil yang terbaik. Hal ini memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler. Pengujian secara real-time dilakukan dengan melakukan export terhadap model dengan hasil yang terbaik, lalu diuji dengan gambar nyata yang diambil menggunakan kamera atau webcam. Pengujian pada latar belakang putih terli hat mendapatkan total benar sebesar 35, dan pengujian pada latar belakang hitam terlihat mendapatkan total benar sebesar 46 dari seluruh alfabet. Untuk model pengujian digunakan model EfficientNet B4 untuk mencari kombinasi Hyperparameter yang terbaik. Perubahan ter hadap nilai learning rate menjadikan proses pelatihan menjadi lebih teratur dan tidak fluktuatif, sebagaimana dapat dilihat pada model yang dilatih masih belum mampu memberikan hasil yang konsisten. Model yang digunakan adalah model dengan pengaturan serta arsitektur ya ng terbaik, yaitu EfficientNet B4 Pretrained dengan Spatial Transformer. Dari hasil pengujian yang ditunjukkan pada Tabel 6, terlihat terdapat peningkatan akurasi Test pada model EfficientNet B4 dengan Spatial Transformer, yaitu sebesar 8. Pengujian model, hyperparameter, pretrained weights, dan Spatial Transformer akan menggunakan akurasi sebagai metrik utama dengan mencatat juga waktu jalannya proses tr aining. Pembuatan sistem klasifikasi bahasa isyarat sebelumnya pernah dilakukan oleh yang membuat asisten virtual untuk bahasa isyarat menggunakan deep learning dan tensorflow. Model akhir ini mampu mendapatkan nilai maksimum dari data testing, sehingga siap untuk diuji coba secara real-time. Hasil ini menunjukkan bahwa model EfficientNet B4 mampu mendeteksi alfabet dalam data uji hingga didapatkan 78,10 kebenarannya. Waktu pelatihan tercepat jatuh kepada model AlexNet dengan waktu 3350 detik atau hanya 55 menit dan terlama pada model EfficientNet B4 dengan waktu 4924 detik atau 1 jam 22 menit. Pada latar belakang putih, total benar yang didapat hanya sebesar 35 dari seluruh alfabet, hasil yang lebih buruk jika dibandingkan dengan kedua dataset di pengujian sebelumnya. Apabila kinerja model masih kurang baik, maka perlu dilakukan perbaikan atau Tweaking pada model dengan tujuan mendapatkan hasil yang lebih baik. Metrik utama yang akan diperhatikan adalah jumlah epoch yang diperlukan dari model hingga mencapai titik konvergen, atau titik dimana akurasi pelatihan tidak lagi fluktuatif. Sedangkan untuk learning rate, pengujian hanya akan menguji penggunaan learning rate scheduler untuk menilai keefektifan scheduler dalam membantu proses training. Model Akurasi Train Akurasi Test Waktu Training EfficientNet B4 99,96 78,10 4924s 4. HASIL DAN PEMBAHASAN Pengujian pertama yang akan diuji adalah pengaturan arsitektur CNN dengan model Khusus untuk learning rate, ditambahkan metrik berupa epoch hingga konvergen untuk menilai seberapa cepat model mampu mencapai titik konvergen pada proses pelatihan. Setelah arsitektur dari model CNN telah ditentukan, dilakukan proses pelatihan atau Training pada dataset.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Dataset Total Benar Akurasi Latar Belakang Pengujian Putih Hitam Abstrak Latar Belakang Putih Total Benar 22 23 13 Akurasi 85 88 50 Latar Belakang Hitam Total Benar 13 16 6 Akurasi 50 62 23 Latar Belakang Karpet Total Benar 9 12 3 Akurasi 35 46 12 Latar Belakang Pemandangan Total Benar 9 4 3 Akurasi 35 15 12 Gabungan Total Benar 26 26 23 Akurasi 100 100 88 Hasil dari pengujian ditunjukkan pada Model Akurasi Waktu Training Train Valid ation Test ResNet18 99,89 100 54,73 3585s AlexNet 99,93 100 57,39 3350s ResNet50 99,83 100 57,10 4167s Efficient Net B4 99,96 100 78,10 4924s Hasil pengujian pada Tabel 2 menunjukkan bahwa model dengan arsitektur EfficientNet B4 memiliki akurasi testing yang tertinggi sebesar 78,10. Adapun perhitungan yang dilakukan pada lapisan convolutional adalah sebagai berikut H(x,y) b F(x,y) G(x,y) b F(j,k) k ( ) j ( ) G(x j,y k) (1) Keterangan F Filter Lapisan G Input feature map H Output feature map b Bias x Sumbu X pada data dan filter y Sumbu Y pada data dan filter j Increment untuk sumbu X k Increment untuk sumbu Y Suatu input feature map G dengan nilai G(x,y) akan dimasukkan ke dalam lapisan konvolusi. Data dengan background hitam merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada data dengan background putih juga merupakan data publik dari situs Kaggle sebagaimana ditunjukkan pada hitam memiliki jumlah sebanyak 70 gambar, sedangkan dataset background putih memiliki jumlah sebanyak 21 gambar. Data yang diambil memiliki dua macam background, yaitu data dengan background karpet bermot if ditunjukkan pada Gambar 3 dan data dengan background pemandangan pagi ditunjukkan pada background karpet memiliki jumlah sebanyak 54 gambar, sedangkan dataset background pemandangan memiliki jumlah sebanyak 40 gambar. Pengujian secara real-time juga akan memiliki variasi terhadap pengujiannya, dimana masing -masing dari keempat dataset akan diuji coba melakukan klasifikasi secara real-time terhadap tiga macam latar belakang, yaitu latar belakang putih polos, latar belak ang hitam polos, dan latar belakang abstrak atau bermacam -macam warna. Hasil dari pengujian ditunjukkan pada Optimizer Akurasi Waktu Training Train Validation Test Adam 99,96 100 78,10 4924s SGD 4,79 3,85 3,84 4707s RMSProp 99,98 100 57,39 4767s Berdasarkan hasil pengujian Tabel 3, dapat dilihat bahwa model yang menggunakan optimizer SGD terlihat tidak berkembang. Penyusunan dataset uji per alfabet adalah satu gambar dari setiap dataset background hitam, putih, karpet, dan pemandangan ditambah tiga gambar dari setiap dataset background bunga, langit merah, dan gunung sebagaimana ditunjukkan pada gambar unt uk setiap alfabet, menjadikan 338 total gambar data uji. Pada perancangan model Convolutional Neural Network dari sistem rekognisi citra digital bahasa isyarat diawali dengan adanya pemrosesan awal dengan mengubah di mensi dari data dan juga mengkonversi data menjadi berbentuk Tensor agar dapat diberikan sebagai input kepada model CNN. Data sekunder yang akan digunakan ada dua macam, yaitu data bahasa isyarat dengan background hitam dan data bahasa isyarat dengan background putih. Sebagaimana ditunjukkan pada Tabel 4, Gambar 8, dan Gambar 9, pe ngujian penggunaan Learning Rate Scheduler pada model CNN tampak memiliki pengaruh terhadap proses pelatihan maupun hasil dari output model tersebut. Sel ain itu, hal ini juga memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler sebagaimana ditunjukkan pada maupun testing, peng gunaan scheduler terlihat mampu menaikkan akurasi pada model yang dilatih 4.3. Untuk setiap j pada sumbu x dan setiap k pada sumbu y, nilai input G(x j,y k) akan dikalikan dengan nilai kernel F(j,k) dan hasilnya akan dijumlahkan sesuai dengan ukuran data input pada nilai j dan k. Hasil dari total penjumlahan tersebut akan dijumlahkan dengan nilai bias b untuk menjadi nilai output H(x,y). Pen gujian Secara Real -Time Pengujian secara real-time dilakukan dengan mencoba dataset satu per satu terhadap suatu kondisi atau tampilan latar belakang tertentu dan menilai ke - efektifan masing -masing data terhadap masing - masing tampilan latar belakang, yaitu latar belakang putih, hitam, dan abstrak. Model Akurasi Waktu Training Train Validation Test ResNet18 99,89 100 54,73 3585s ResNet18 Pretrained 100 100 84,91 3566s AlexNet 99,93 100 57,39 3350s AlexNet Pretrained 99,96 99,04 75,44 3345s ResNet50 99,83 100 57,10 4167s ResNet50 EfficientNet B4 99,96 100 78,10 4924s EfficientNet B4 Pretrained 99,96 100 100 4870s Berdasarkan hasil pengujian yang ditunjukkan pada Tabel 5, dapat dilihat bahwa terdapat peningkatan pada akurasi testing untuk seluruh model. Hal ini menunjukkan bahwa model EfficientNet B4 merupakan model yang terbaik dari keempat model yang diuji dalam mengklasifikasikan dataset yang diberikan. Setelah didapat model dan pengaturan hyperparameter yang terbaik, dilakukan pen gujian penggunaan pretrained weights dari arsitektur model untuk mencoba menaikkan hasil akurasi. Pen gujian Penggunaan Pretrained Weights Pengujian penggunaan pretrained weights dilakukan dengan menggunakan parameter pretrained True ketika memanggil model menggunakan library torch untuk menggunakan weights yang sebelumnya telah dilatih dan disediakan pada pemanggilan model. Hasil ini menunjukkan bahwa model EfficientNet B4 memiliki kemampuan terbaik dalam prediksi data uji dibanding model lainnya, walau waktu pelatihannya memakan waktu paling lama. Transfer Learning Transfer Learning merupakan salah satu teknik dari penggunaan Deep Learning, dimana model yang sebelumnya telah melewati tahap training digunakan kembali untuk mengekstrak dan tuning lebih lanjut pada model lain untuk memperbaiki akurasi. Selain itu, ditambahkan pula tiga set gambar yang tidak berada dalam data training maupun validation, yaitu dataset dengan background bunga, dataset dengan background langit merah, dan dataset dengan background gunung. Hal ini dikarenakan terdapat banyak bentuk bahasa isyarat di dunia, sehingga untuk dapat mendeteksi bahasa isyarat yang ada pada regional tertentu, diperlukan dataset bahasa isyarat dari lokasi tersebut. Alur perancangan model ini dilakukan sebagaimana pada 1162 Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 11, No. 6, Desember 2024, hlm.1159 -1168 Arsitektur yang akan digunakan dalam penelitian sistem rekognisi citra digital bahasa isyarat menggunakan Convolutional Neural Network akan menggunakan berbagai pretrained weights yang telah disediakan oleh library PyTorch. Dapat juga dilihat pada Tabel 7 bahwa dataset dengan latar belakang putih mampu melakukan klasifikasi dengan baik pada latar belakang pengujian putih dan hitam polos, tetapi tidak te rlalu buruk pada klasifikasi dengan background abstrak. 2. METODE PENELITIAN 2.1 Data Penelitian Data yang digunakan untuk training model adalah data sekunder yang didapat Data gamb ar yang diambil akan memiliki pose dan bentuk bahasa isyarat yang sama dengan data sekunder dari internet tersebut, tetapi akan memiliki background yang bervariasi. yang merupakan bagian dari Deep Learning atau Machine Learning dan dengan metode Spatial Transformer, sistem akan mengenali pose atau bentuk dari citra bahasa isyarat yang dimasukkan, dan memberikan luaran yang sesuai dengan maksud dari pose atau bentuk dari citra bahasa isyarat tersebut. Model dan weights -nya sudah dilatih sebelumnya menggunakan dataset ImageNet -1k dengan tujuan membantu meningkatkan akurasi dari model. Selain memiliki akurasi testing yang tertinggi, akurasi training dan validation dari model Effi cientNet B4 juga yang terbesar, yaitu sebesar 99,96 untuk training dan 100 untuk validation. 4.2 Pengujian Hyperparameter Pengujian Hyperparameter dilakukan dengan menentukan pengat uran Hyperparameter yang dapat Mahardika, dkk, Sistem Rekognisi Citra Digital 1165 memberikan hasil yang terbaik, dan pengaturan Hyperparameter yang akan diuji yaitu optimizer dan penggunaan learning rate scheduler. Pengambilan data pribadi ini dilakukan untuk Mahardika, dkk, Sistem Rekognisi Citra Digital 1161 menguji adanya perbedaan hasil pada pengujian apabila menggunakan data dengan background yang berbeda dan mengetahui seberapa besar pengaruh yang dimiliki oleh background tersebut terhadap keseluruhan percobaan, sebagaimana permasalahan ini disebutkan sebelumnya oleh. Hasil ini menunjukkan bahwa model EfficientNet B4 sudah mampu mendeteksi seluruh data uji secara sempurna diduga karena tingkat kesulitan untuk mendeteksi data uji tidak begitu tinggi. Adanya peningkatan akurasi menunjukkan bahwa Spatial Transformer memiliki kemampuan untuk meningkatkan kemampuan dari model dalam klasifikasi, sehingga pantas untuk digunakan untuk model akhir. Dari keempat model, dapat dilihat bahwa model EfficientNet B4 masih memiliki akurasi terbesar, bahkan mampu mencapai angka maksimum. Model dengan optimizer RMSProp terlihat cukup baik, akan tetapi akurasi testing -nya tidak sebaik dengan model yang menggunakan optimizer Adam. Dataset berlatar be lakang karpet yang ditunjukkan pada Tabel 7 terlihat lebih baik daripada pengujian pada dataset berlatar belakang pemandangan, tetapi masih kurang jika dibandingkan dengan dataset berlatar belakang hitam dan putih. 4.1 Pengujian Arsitektur Model Dalam pengujian ini digunakan empat tipe model. Dataset masih mampu melakukan klasifikasi pada latar belakang pengujian Mahardika, dkk, Sistem Rekognisi Citra Digital 1167 yang polos, seperti latar belakang putih dan hitam. Terakhir, dilakukan pengujian dengan data uji untuk menentukan seberapa baik ki nerja model dalam pekerjaan mengklasifikasi dan merekognisi dataset digital tersebut. Kesimpulan dari penelitian ini adalah untuk dapat mendeteksi bahasa isyarat, diperlukan dataset tertentu untuk setiap bentuk bahasa isyarat. Sebagaimana ditunjukkan pada Tabel 7, hasil pengujian dataset gabungan pada latar belakang putih terlihat mencapai 100 total benar. Setelah melihat performa dari masing - masing dataset, dilakukan uji coba mengguna kan dataset gabungan dari keempat dataset untuk mencoba mendapatkan hasil yang terbaik. Hal ini memiliki pengaruh terhadap hasil output, dibuktikan dengan akurasi yang didapat terlihat lebih kecil dibandingkan dengan model yang menggunakan scheduler. Pengujian secara real-time dilakukan dengan melakukan export terhadap model dengan hasil yang terbaik, lalu diuji dengan gambar nyata yang diambil menggunakan kamera atau webcam. Pengujian pada latar belakang putih terli hat mendapatkan total benar sebesar 35, dan pengujian pada latar belakang hitam terlihat mendapatkan total benar sebesar 46 dari seluruh alfabet. Untuk model pengujian digunakan model EfficientNet B4 untuk mencari kombinasi Hyperparameter yang terbaik. Perubahan ter hadap nilai learning rate menjadikan proses pelatihan menjadi lebih teratur dan tidak fluktuatif, sebagaimana dapat dilihat pada model yang dilatih masih belum mampu memberikan hasil yang konsisten. Model yang digunakan adalah model dengan pengaturan serta arsitektur ya ng terbaik, yaitu EfficientNet B4 Pretrained dengan Spatial Transformer. Dari hasil pengujian yang ditunjukkan pada Tabel 6, terlihat terdapat peningkatan akurasi Test pada model EfficientNet B4 dengan Spatial Transformer, yaitu sebesar 8. Pengujian model, hyperparameter, pretrained weights, dan Spatial Transformer akan menggunakan akurasi sebagai metrik utama dengan mencatat juga waktu jalannya proses tr aining. Pembuatan sistem klasifikasi bahasa isyarat sebelumnya pernah dilakukan oleh yang membuat asisten virtual untuk bahasa isyarat menggunakan deep learning dan tensorflow. Model akhir ini mampu mendapatkan nilai maksimum dari data testing, sehingga siap untuk diuji coba secara real-time. Hasil ini menunjukkan bahwa model EfficientNet B4 mampu mendeteksi alfabet dalam data uji hingga didapatkan 78,10 kebenarannya. Waktu pelatihan tercepat jatuh kepada model AlexNet dengan waktu 3350 detik atau hanya 55 menit dan terlama pada model EfficientNet B4 dengan waktu 4924 detik atau 1 jam 22 menit. Pada latar belakang putih, total benar yang didapat hanya sebesar 35 dari seluruh alfabet, hasil yang lebih buruk jika dibandingkan dengan kedua dataset di pengujian sebelumnya. Apabila kinerja model masih kurang baik, maka perlu dilakukan perbaikan atau Tweaking pada model dengan tujuan mendapatkan hasil yang lebih baik. Metrik utama yang akan diperhatikan adalah jumlah epoch yang diperlukan dari model hingga mencapai titik konvergen, atau titik dimana akurasi pelatihan tidak lagi fluktuatif. Sedangkan untuk learning rate, pengujian hanya akan menguji penggunaan learning rate scheduler untuk menilai keefektifan scheduler dalam membantu proses training. Model Akurasi Train Akurasi Test Waktu Training EfficientNet B4 99,96 78,10 4924s 4. HASIL DAN PEMBAHASAN Pengujian pertama yang akan diuji adalah pengaturan arsitektur CNN dengan model Khusus untuk learning rate, ditambahkan metrik berupa epoch hingga konvergen untuk menilai seberapa cepat model mampu mencapai titik konvergen pada proses pelatihan. Setelah arsitektur dari model CNN telah ditentukan, dilakukan proses pelatihan atau Training pada dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13218"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
